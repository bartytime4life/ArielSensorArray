{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60b8e907",
   "metadata": {},
   "source": [
    "# ðŸ›°ï¸ SpectraMind V50 â€” Physicsâ€‘Informed Modeling & Symbolic Constraints (Notebook 06)\n",
    "\n",
    "**Purpose.** Add *physicsâ€‘informed, symbolic constraints* to the SpectraMind V50 pipeline and run diagnostics for\n",
    "constraint violations and cycleâ€‘consistency. The notebook adheres to the CLIâ€‘first, Hydraâ€‘safe workflow used in 00â€“05.\n",
    "\n",
    "**Sections**\n",
    "1. Preâ€‘flight & environment capture\n",
    "2. Compose Hydra overrides for symbolic losses\n",
    "3. Train with symbolic constraints\n",
    "4. Symbolic diagnostics (rule ranking/overlays)\n",
    "5. Cycleâ€‘consistency (simulate Î¼ â†’ validate)\n",
    "6. Artifacts & next steps\n",
    "\n",
    "> Degrades gracefully: if the `spectramind` CLI is not available, the notebook switches to **DRYâ€‘RUN** and still produces configs/logs/placeholder artifacts to keep the workflow reproducible.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cae0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â–‘â–‘ Preâ€‘flight: environment, run IDs, paths, CLI detection â–‘â–‘\n",
    "import os, sys, json, platform, shutil, subprocess, datetime, pathlib\n",
    "\n",
    "RUN_TS = datetime.datetime.utcnow().strftime(\"%Y%m%dT%H%M%SZ\")\n",
    "RUN_ID = f\"physics_informed_{RUN_TS}\"\n",
    "ROOT_OUT = \"/mnt/data/physics_informed\"\n",
    "ARTIFACTS = os.path.join(ROOT_OUT, RUN_ID)\n",
    "LOGS = os.path.join(ARTIFACTS, \"logs\")\n",
    "CFG_OUT = os.path.join(ARTIFACTS, \"configs\")\n",
    "DIAG_OUT = os.path.join(ARTIFACTS, \"diagnostics\")\n",
    "SIM_OUT = os.path.join(ARTIFACTS, \"simulation\")\n",
    "for p in (ROOT_OUT, ARTIFACTS, LOGS, CFG_OUT, DIAG_OUT, SIM_OUT):\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "\n",
    "def which(cmd: str):\n",
    "    return shutil.which(cmd) is not None\n",
    "\n",
    "CLI_PRESENT = which(\"spectramind\")\n",
    "DRY_RUN = not CLI_PRESENT\n",
    "\n",
    "def git_cmd(args):\n",
    "    try:\n",
    "        out = subprocess.check_output([\"git\", *args], stderr=subprocess.STDOUT, timeout=5).decode().strip()\n",
    "        return out\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "env = {\n",
    "    \"python\": sys.version.replace(\"\\n\",\" \"),\n",
    "    \"platform\": platform.platform(),\n",
    "    \"cli_present\": CLI_PRESENT,\n",
    "    \"dry_run\": DRY_RUN,\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"paths\": {\"artifacts\": ARTIFACTS, \"logs\": LOGS, \"configs\": CFG_OUT, \"diagnostics\": DIAG_OUT, \"simulation\": SIM_OUT},\n",
    "    \"git\": {\n",
    "        \"commit\": git_cmd([\"rev-parse\", \"HEAD\"]),\n",
    "        \"branch\": git_cmd([\"rev-parse\", \"--abbrev-ref\", \"HEAD\"]),\n",
    "        \"status\": git_cmd([\"status\", \"--porcelain\"]),\n",
    "    },\n",
    "}\n",
    "with open(os.path.join(ARTIFACTS, \"env.json\"), \"w\") as f:\n",
    "    json.dump(env, f, indent=2)\n",
    "\n",
    "print(\"=== SpectraMind V50 â€” Notebook 06 ===\")\n",
    "print(json.dumps(env, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f46116",
   "metadata": {},
   "source": [
    "## Configuration knobs (Hydra overrides)\n",
    "\n",
    "**Symbolic losses** enabled here:\n",
    "- `nonnegativity` â€” penalize negative flux/Î¼\n",
    "- `smoothness` â€” L2 gradient/curvature prior on Î¼\n",
    "- `fft_coherence` â€” spectral structure coherence\n",
    "- `molecular_priors` â€” optional rule pack (Hâ‚‚O/COâ‚‚/CHâ‚„ bands)\n",
    "\n",
    "> Start with small weights and increase gradually while monitoring GLL and violation dashboards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e736a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, os\n",
    "\n",
    "overrides = {\n",
    "    \"loss.symbolic.enable\": \"true\",\n",
    "    \"loss.symbolic.weights.nonnegativity\": \"1.0\",\n",
    "    \"loss.symbolic.weights.smoothness\": \"0.05\",\n",
    "    \"loss.symbolic.weights.fft_coherence\": \"0.10\",\n",
    "    \"loss.symbolic.molecular_priors.enable\": \"true\",\n",
    "    \"loss.symbolic.molecular_priors.pack\": \"default_v1\",\n",
    "    \"diagnostics.symbolic.top_k\": \"12\",\n",
    "    \"training.max_epochs\": \"12\",\n",
    "    \"training.batch_size\": \"16\",\n",
    "    \"data\": \"ariel_nominal\",\n",
    "    \"model\": \"v50\",\n",
    "    \"training.seed\": \"1337\",\n",
    "}\n",
    "\n",
    "cfg_file = os.path.join(CFG_OUT, \"symbolic_overrides.json\")\n",
    "with open(cfg_file, \"w\") as f:\n",
    "    json.dump(overrides, f, indent=2)\n",
    "\n",
    "print(\"Saved overrides ->\", cfg_file)\n",
    "print(json.dumps(overrides, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da76dd05",
   "metadata": {},
   "source": [
    "## Helper: robust CLI runner (uses DRYâ€‘RUN when CLI not present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bffdc263",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shlex, subprocess, time\n",
    "\n",
    "def run_cli(cmd_list, log_name=\"run\"):\n",
    "    log_path = os.path.join(LOGS, f\"{log_name}.log\")\n",
    "    err_path = os.path.join(LOGS, f\"{log_name}.err\")\n",
    "    start = time.time()\n",
    "    result = {\"cmd\": cmd_list, \"dry_run\": DRY_RUN, \"returncode\": 0, \"stdout\": \"\", \"stderr\": \"\"}\n",
    "    if DRY_RUN:\n",
    "        msg = f\"[DRY-RUN] Would execute: {' '.join(shlex.quote(c) for c in cmd_list)}\\n\"\n",
    "        result[\"stdout\"] = msg\n",
    "        with open(log_path, \"w\") as f: f.write(msg)\n",
    "        with open(err_path, \"w\") as f: f.write(\"\")\n",
    "        placeholder = os.path.join(ARTIFACTS, \"dry_run_placeholder.txt\")\n",
    "        with open(placeholder, \"a\") as f: f.write(msg)\n",
    "        return result\n",
    "\n",
    "    with open(log_path, \"wb\") as out, open(err_path, \"wb\") as err:\n",
    "        try:\n",
    "            proc = subprocess.Popen(cmd_list, stdout=out, stderr=err, env=os.environ.copy())\n",
    "            proc.wait()\n",
    "            result[\"returncode\"] = proc.returncode\n",
    "        except Exception as e:\n",
    "            result[\"returncode\"] = 99\n",
    "            with open(err_path, \"ab\") as errf:\n",
    "                errf.write(str(e).encode())\n",
    "\n",
    "    try:\n",
    "        result[\"stdout\"] = open(log_path, \"r\").read()\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        result[\"stderr\"] = open(err_path, \"r\").read()\n",
    "    except Exception:\n",
    "        pass\n",
    "    result[\"elapsed_sec\"] = round(time.time() - start, 3)\n",
    "    print(f\"[rc={result['returncode']}] logs: {log_path}\")\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa88b396",
   "metadata": {},
   "source": [
    "## Train with physicsâ€‘informed symbolic constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dfcf42",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = [\n",
    "    \"spectramind\", \"train\",\n",
    "    \"--config-name\", \"config_v50.yaml\",\n",
    "    \"+outputs.root_dir=\" + ARTIFACTS,\n",
    "]\n",
    "for k, v in overrides.items():\n",
    "    cmd.append(f\"+{k}={v}\")\n",
    "cmd += [\"+training.fast_mode=true\"]  # if supported\n",
    "\n",
    "res_train = run_cli(cmd, log_name=\"01_train_symbolic\")\n",
    "print(res_train[\"stdout\"][:500])\n",
    "if res_train[\"returncode\"] not in (0, None):\n",
    "    print(\"Training non-zero return code:\", res_train[\"returncode\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370fa3da",
   "metadata": {},
   "source": [
    "## Symbolic diagnostics & rule ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f698dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd_diag = [\n",
    "    \"spectramind\", \"diagnose\", \"symbolic-rank\",\n",
    "    \"--top-k\", overrides.get(\"diagnostics.symbolic.top_k\", \"12\"),\n",
    "    \"--export\", DIAG_OUT,\n",
    "]\n",
    "res_diag = run_cli(cmd_diag, log_name=\"02_diagnose_symbolic_rank\")\n",
    "print(res_diag[\"stdout\"][:500])\n",
    "\n",
    "cmd_dash = [\n",
    "    \"spectramind\", \"diagnose\", \"dashboard\",\n",
    "    \"--out\", os.path.join(DIAG_OUT, \"diagnostic_report_v1.html\"),\n",
    "    \"--show-logic-graph\",\n",
    "]\n",
    "res_dash = run_cli(cmd_dash, log_name=\"03_diagnose_dashboard\")\n",
    "print(res_dash[\"stdout\"][:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "072cac9f",
   "metadata": {},
   "source": [
    "## Cycleâ€‘consistency: simulate â†’ validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfc5934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare a tiny placeholder Î¼ CSV if none exists (DRY-RUN friendly)\n",
    "mu_csv = os.path.join(ARTIFACTS, \"pred_mu.csv\")\n",
    "if not os.path.exists(mu_csv):\n",
    "    import csv\n",
    "    with open(mu_csv, \"w\", newline=\"\") as f:\n",
    "        w = csv.writer(f)\n",
    "        w.writerow([\"planet_id\"] + [f\"mu_{i:03d}\" for i in range(283)])\n",
    "        for pid in [\"P0001\",\"P0002\",\"P0003\"]:\n",
    "            row = [pid] + [0.0]*283\n",
    "            w.writerow(row)\n",
    "\n",
    "cmd_sim = [\"spectramind\", \"simulate-lightcurve-from-mu\", \"--mu-csv\", mu_csv, \"--out\", SIM_OUT]\n",
    "res_sim = run_cli(cmd_sim, log_name=\"04_simulate_from_mu\")\n",
    "print(res_sim[\"stdout\"][:500])\n",
    "\n",
    "cmd_cc = [\"spectramind\", \"validate\", \"cycle-consistency\",\n",
    "          \"--sim-dir\", SIM_OUT, \"--mu-ref\", mu_csv,\n",
    "          \"--out\", os.path.join(DIAG_OUT, \"cycle_consistency.json\")]\n",
    "res_cc = run_cli(cmd_cc, log_name=\"05_cycle_consistency\")\n",
    "print(res_cc[\"stdout\"][:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b419c28",
   "metadata": {},
   "source": [
    "## Browse produced artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59fefc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def tree(path, prefix=\"\"):\n",
    "    items = sorted(os.listdir(path))\n",
    "    lines = []\n",
    "    for i, name in enumerate(items):\n",
    "        full = os.path.join(path, name)\n",
    "        connector = \"â””â”€â”€ \" if i == len(items)-1 else \"â”œâ”€â”€ \"\n",
    "        lines.append(prefix + connector + name)\n",
    "        if os.path.isdir(full):\n",
    "            extension = \"    \" if i == len(items)-1 else \"â”‚   \"\n",
    "            lines.extend(tree(full, prefix + extension))\n",
    "    return lines\n",
    "\n",
    "print(\"ARTIFACTS TREE:\", ARTIFACTS)\n",
    "print(\"\\n\".join(tree(ARTIFACTS)))\n",
    "dash_path = os.path.join(DIAG_OUT, \"diagnostic_report_v1.html\")\n",
    "print(\"\\nDashboard:\", dash_path if os.path.exists(dash_path) else \"(not found)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a212cc0",
   "metadata": {},
   "source": [
    "## Pipeline sketch (Mermaid)\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "  A[Calibrated data] --> B[Train with symbolic losses]\n",
    "  B --> C[Predict Î¼, Ïƒ]\n",
    "  C --> D[Symbolic diagnostics<br/>rule ranking & overlays]\n",
    "  C --> E[Simulate lightcurves from Î¼]\n",
    "  E --> F[Cycleâ€‘consistency validation]\n",
    "  D --> G[Dashboard / Reports]\n",
    "  F --> G\n",
    "```\n",
    "\n",
    "## Next steps\n",
    "- Sweep symbolic weights via `spectramind ablate` and compare GLL vs. violation score.\n",
    "- Enable moleculeâ€‘specific prior packs where available; monitor perâ€‘band improvements.\n",
    "- Integrate outputs into your unified HTML report and CI for regression checks.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
