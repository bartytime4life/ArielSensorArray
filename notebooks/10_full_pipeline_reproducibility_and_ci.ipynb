{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9a53c33",
   "metadata": {},
   "source": [
    "# ðŸ” SpectraMind V50 â€” Full Pipeline Reproducibility & CI (Notebook 10)\n",
    "\n",
    "**Goal.** Execute the **entire pipeline endâ€‘toâ€‘end** in a controlled, CLIâ€‘first flow; capture **exact config + data + code provenance**; and emit a **reproducibility manifest** compatible with CI.\n",
    "\n",
    "**What this notebook does**\n",
    "1. Preâ€‘flight & environment capture (CLI/DVC detection, git info, run ID)\n",
    "2. DVC quick status (cache/stage checks) with graceful fallback\n",
    "3. Endâ€‘toâ€‘end pipeline run (calibrate â†’ train â†’ diagnose â†’ submit) with **DRYâ€‘RUN fallback** if `spectramind` is not available\n",
    "4. Create a **reproducibility manifest** (commit hash, config snapshot if available, artifact hashes)\n",
    "5. CI smokeâ€‘test hooks (idempotent rerun check; basic integrity assertions)\n",
    "6. Artifact tree + next steps\n",
    "\n",
    "> As in earlier notebooks, everything is **CLIâ€‘first, Hydraâ€‘safe**, and will **degrade gracefully** if local tools are not present.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4196b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â–‘â–‘ Pre-flight: detect tools, set paths, capture git/env â–‘â–‘\n",
    "import os, sys, json, shutil, subprocess, datetime, pathlib\n",
    "\n",
    "RUN_TS = datetime.datetime.utcnow().strftime(\"%Y%m%dT%H%M%SZ\")\n",
    "RUN_ID = f\"full_pipeline_ci_{RUN_TS}\"\n",
    "ROOT_OUT = \"/mnt/data/full_pipeline_ci\"\n",
    "ARTIFACTS = os.path.join(ROOT_OUT, RUN_ID)\n",
    "LOGS = os.path.join(ARTIFACTS, \"logs\")\n",
    "CFG_OUT = os.path.join(ARTIFACTS, \"configs\")\n",
    "DIAG_OUT = os.path.join(ARTIFACTS, \"diagnostics\")\n",
    "SUBMIT_OUT = os.path.join(ARTIFACTS, \"submission\")\n",
    "for p in (ROOT_OUT, ARTIFACTS, LOGS, CFG_OUT, DIAG_OUT, SUBMIT_OUT):\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "\n",
    "def which(cmd:str)->bool: return shutil.which(cmd) is not None\n",
    "CLI_PRESENT = which(\"spectramind\")\n",
    "DVC_PRESENT = which(\"dvc\")\n",
    "\n",
    "def git_cmd(args):\n",
    "    try:\n",
    "        out = subprocess.check_output([\"git\", *args], stderr=subprocess.STDOUT, timeout=5).decode().strip()\n",
    "        return out\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "env = {\n",
    "    \"python\": sys.version.replace(\"\\n\",\" \"),\n",
    "    \"platform\": sys.platform,\n",
    "    \"cli_present\": CLI_PRESENT,\n",
    "    \"dvc_present\": DVC_PRESENT,\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"paths\": {\"artifacts\": ARTIFACTS, \"logs\": LOGS, \"configs\": CFG_OUT, \"diagnostics\": DIAG_OUT, \"submission\": SUBMIT_OUT},\n",
    "    \"git\": {\n",
    "        \"commit\": git_cmd([\"rev-parse\", \"HEAD\"]),\n",
    "        \"branch\": git_cmd([\"rev-parse\", \"--abbrev-ref\", \"HEAD\"]),\n",
    "        \"status\": git_cmd([\"status\", \"--porcelain\"]),\n",
    "        \"remote\": git_cmd([\"remote\", \"-v\"]),\n",
    "    },\n",
    "}\n",
    "with open(os.path.join(ARTIFACTS, \"env.json\"), \"w\") as f:\n",
    "    json.dump(env, f, indent=2)\n",
    "\n",
    "print(\"=== Pre-flight ===\")\n",
    "print(json.dumps(env, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd91a84",
   "metadata": {},
   "source": [
    "## DVC quick status (graceful fallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972d9b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, pathlib, json, os\n",
    "\n",
    "dvc_info = {\"present\": DVC_PRESENT, \"version\": None, \"status\": None}\n",
    "if DVC_PRESENT:\n",
    "    try:\n",
    "        ver = subprocess.check_output([\"dvc\", \"--version\"], timeout=10).decode().strip()\n",
    "        dvc_info[\"version\"] = ver\n",
    "    except Exception as e:\n",
    "        dvc_info[\"version\"] = f\"error: {e}\"\n",
    "    try:\n",
    "        # Check for cached stage status; if no DVC repo, this will fail\n",
    "        out = subprocess.check_output([\"dvc\", \"status\", \"-c\"], stderr=subprocess.STDOUT, timeout=15).decode()\n",
    "        dvc_info[\"status\"] = out\n",
    "    except Exception as e:\n",
    "        dvc_info[\"status\"] = f\"(no DVC repo or error) {e}\"\n",
    "else:\n",
    "    dvc_info[\"status\"] = \"(dvc not installed)\"\n",
    "with open(os.path.join(ARTIFACTS, \"dvc_status.json\"), \"w\") as f:\n",
    "    json.dump(dvc_info, f, indent=2)\n",
    "print(json.dumps(dvc_info, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee89b364",
   "metadata": {},
   "source": [
    "## Helper: robust CLI runner (DRYâ€‘RUN when CLI missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6d25a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shlex, time\n",
    "\n",
    "def run_cli(cmd_list, log_name=\"run\"):\n",
    "    log_path = os.path.join(LOGS, f\"{log_name}.log\")\n",
    "    err_path = os.path.join(LOGS, f\"{log_name}.err\")\n",
    "    start = time.time()\n",
    "    result = {\"cmd\": cmd_list, \"dry_run\": not CLI_PRESENT, \"returncode\": 0, \"stdout\": \"\", \"stderr\": \"\"}\n",
    "    if not CLI_PRESENT:\n",
    "        msg = f\"[DRY-RUN] Would execute: {' '.join(shlex.quote(c) for c in cmd_list)}\\n\"\n",
    "        result[\"stdout\"] = msg\n",
    "        with open(log_path, \"w\") as f: f.write(msg)\n",
    "        with open(err_path, \"w\") as f: f.write(\"\")\n",
    "        return result\n",
    "\n",
    "    with open(log_path, \"wb\") as out, open(err_path, \"wb\") as err:\n",
    "        try:\n",
    "            proc = subprocess.Popen(cmd_list, stdout=out, stderr=err, env=os.environ.copy())\n",
    "            proc.wait()\n",
    "            result[\"returncode\"] = proc.returncode\n",
    "        except Exception as e:\n",
    "            result[\"returncode\"] = 99\n",
    "            with open(err_path, \"ab\") as errf:\n",
    "                errf.write(str(e).encode())\n",
    "\n",
    "    try: result[\"stdout\"] = open(log_path, \"r\").read()\n",
    "    except Exception: pass\n",
    "    try: result[\"stderr\"] = open(err_path, \"r\").read()\n",
    "    except Exception: pass\n",
    "    result[\"elapsed_sec\"] = round(time.time() - start, 3)\n",
    "    print(f\"[rc={result['returncode']}] logs: {log_path}\")\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ff37c2",
   "metadata": {},
   "source": [
    "## Endâ€‘toâ€‘end pipeline run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52aced9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calibrate (optionally subset for a fast CI smoke run)\n",
    "cal_cmd = [\n",
    "    \"spectramind\",\"calibrate\",\n",
    "    \"+outputs.root_dir=\"+ARTIFACTS,\n",
    "    # Optional flags if supported by your CLI:\n",
    "    # \"--sample\",\"8\"\n",
    "]\n",
    "res_cal = run_cli(cal_cmd, log_name=\"01_calibrate\")\n",
    "print(res_cal[\"stdout\"][:400])\n",
    "\n",
    "# Train (fast mode for CI; bump epochs in full runs)\n",
    "train_cmd = [\n",
    "    \"spectramind\",\"train\",\n",
    "    \"--config-name\",\"config_v50.yaml\",\n",
    "    \"+outputs.root_dir=\"+ARTIFACTS,\n",
    "    \"+training.max_epochs=1\",\n",
    "    \"+training.fast_mode=true\"\n",
    "]\n",
    "res_tr = run_cli(train_cmd, log_name=\"02_train\")\n",
    "print(res_tr[\"stdout\"][:400])\n",
    "\n",
    "# Diagnose (HTML dashboard)\n",
    "dash_html = os.path.join(DIAG_OUT, \"diagnostic_report_ci_v1.html\")\n",
    "diag_cmd = [\"spectramind\",\"diagnose\",\"dashboard\",\"--out\", dash_html]\n",
    "res_dg = run_cli(diag_cmd, log_name=\"03_diagnose_dashboard\")\n",
    "print(res_dg[\"stdout\"][:400])\n",
    "\n",
    "# Submit bundle (pack outputs)\n",
    "submit_zip = os.path.join(SUBMIT_OUT, \"submission_bundle.zip\")\n",
    "sub_cmd = [\"spectramind\",\"submit\",\"--out\", submit_zip]\n",
    "res_sb = run_cli(sub_cmd, log_name=\"04_submit\")\n",
    "print(res_sb[\"stdout\"][:400])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c60ad9ac",
   "metadata": {},
   "source": [
    "## Build a reproducibility manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb915859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib, json, glob, os\n",
    "\n",
    "def sha256_of_file(path, chunk=1024*1024):\n",
    "    try:\n",
    "        h = hashlib.sha256()\n",
    "        with open(path, \"rb\") as f:\n",
    "            while True:\n",
    "                b = f.read(chunk)\n",
    "                if not b: break\n",
    "                h.update(b)\n",
    "        return h.hexdigest()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "# Collect artifacts and hashes\n",
    "artifact_files = []\n",
    "for root, dirs, files in os.walk(ARTIFACTS):\n",
    "    for fn in files:\n",
    "        full = os.path.join(root, fn)\n",
    "        rel = os.path.relpath(full, ARTIFACTS)\n",
    "        artifact_files.append({\"path\": rel, \"sha256\": sha256_of_file(full)})\n",
    "\n",
    "manifest = {\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"timestamp_utc\": RUN_TS,\n",
    "    \"git\": env.get(\"git\"),\n",
    "    \"cli_present\": CLI_PRESENT,\n",
    "    \"dvc\": json.load(open(os.path.join(ARTIFACTS, \"dvc_status.json\"))),\n",
    "    \"commands\": {\n",
    "        \"calibrate\": res_cal[\"cmd\"],\n",
    "        \"train\": res_tr[\"cmd\"],\n",
    "        \"diagnose_dashboard\": res_dg[\"cmd\"],\n",
    "        \"submit\": res_sb[\"cmd\"],\n",
    "    },\n",
    "    \"returncodes\": {\n",
    "        \"calibrate\": res_cal[\"returncode\"],\n",
    "        \"train\": res_tr[\"returncode\"],\n",
    "        \"diagnose_dashboard\": res_dg[\"returncode\"],\n",
    "        \"submit\": res_sb[\"returncode\"],\n",
    "    },\n",
    "    \"artifacts\": artifact_files,\n",
    "    \"notes\": \"Config snapshots will be included if the CLI dumps composed Hydra configs into outputs. DRY-RUN indicates missing CLI.\"\n",
    "}\n",
    "with open(os.path.join(ARTIFACTS, \"repro_manifest.json\"), \"w\") as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "\n",
    "print(f\"Manifest written to: {os.path.join(ARTIFACTS, 'repro_manifest.json')}\")\n",
    "print(f\"Artifacts counted: {len(artifact_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7cc173",
   "metadata": {},
   "source": [
    "## CI smokeâ€‘test checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdd2d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple checks that help CI verify integrity\n",
    "import json, os\n",
    "\n",
    "rc_ok = all(x == 0 for x in [\n",
    "    res_cal[\"returncode\"],\n",
    "    res_tr[\"returncode\"],\n",
    "    res_dg[\"returncode\"],\n",
    "    res_sb[\"returncode\"],\n",
    "]) if CLI_PRESENT else True  # In DRY-RUN, allow pass\n",
    "\n",
    "manifest_path = os.path.join(ARTIFACTS, \"repro_manifest.json\")\n",
    "has_manifest = os.path.exists(manifest_path)\n",
    "\n",
    "print(\"Return codes OK (or DRY-RUN):\", rc_ok)\n",
    "print(\"Manifest exists:\", has_manifest)\n",
    "\n",
    "# (Optional) Idempotent rerun of a tiny step, e.g., diagnose-only\n",
    "# This is skipped in DRY-RUN to keep the notebook fast & deterministic.\n",
    "if CLI_PRESENT:\n",
    "    res_dg2 = run_cli([\"spectramind\",\"diagnose\",\"dashboard\",\"--out\", os.path.join(DIAG_OUT,\"diagnostic_report_ci_v2.html\")], log_name=\"05_diagnose_dashboard_rerun\")\n",
    "    print(\"Second dashboard rc:\", res_dg2[\"returncode\"])\n",
    "else:\n",
    "    print(\"[DRY-RUN] Skipping idempotent re-run.\")\n",
    "\n",
    "assert has_manifest, \"Reproducibility manifest missing.\"\n",
    "print(\"CI smoke-test checks complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6f2407",
   "metadata": {},
   "source": [
    "## Browse produced artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1622bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def tree(path, prefix=\"\"):\n",
    "    items = sorted(os.listdir(path))\n",
    "    lines = []\n",
    "    for i, name in enumerate(items):\n",
    "        full = os.path.join(path, name)\n",
    "        connector = \"â””â”€â”€ \" if i == len(items)-1 else \"â”œâ”€â”€ \"\n",
    "        lines.append(prefix + connector + name)\n",
    "        if os.path.isdir(full):\n",
    "            extension = \"    \" if i == len(items)-1 else \"â”‚   \"\n",
    "            lines.extend(tree(full, prefix + extension))\n",
    "    return lines\n",
    "\n",
    "print(\"ARTIFACTS TREE:\", ARTIFACTS)\n",
    "print(\"\\n\".join(tree(ARTIFACTS)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f79a61",
   "metadata": {},
   "source": [
    "## Pipeline sketch (Mermaid)\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "  A[Calibrate] --> B[Train]\n",
    "  B --> C[Diagnose â†’ HTML]\n",
    "  C --> D[Submit â†’ ZIP]\n",
    "  A -.->|DVC stages| B\n",
    "  B -.->|Hydra config| C\n",
    "  C -.->|Manifest hashes| D\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "951fa464",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "- Commit the generated `repro_manifest.json` and artifacts (or track large ones via **DVC**).\n",
    "- Add a **CI job** (GitHub Actions) that runs this notebook or its equivalent CLI sequence on a schedule and on PRs.\n",
    "- Ensure the **CLI dumps composed Hydra configs** into `configs/` per run (the manifest will capture them automatically).\n",
    "- Consider adding **MLflow** run logging alongside DVC for a web UI comparison of runs.\n",
    "\n",
    "If you want, I can also prepare a **GitHub Actions** CI YAML that runs the same smokeâ€‘test using the CLI only.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
