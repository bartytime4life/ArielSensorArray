{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ”­ SpectraMind V50 â€” 01_data_exploration.ipynb\n",
    "\n",
    "Missionâ€‘grade data exploration for **FGS1** (long timeâ€‘series) and **AIRS** (spectral bins).\n",
    "\n",
    "**Standards**\n",
    "- Notebooks are *thin orchestration*: **CLI â†’ Hydra configs â†’ DVC artifacts**. No adâ€‘hoc pipeline logic.\n",
    "- Read inputs solely from `data/` (DVC) or `outputs/` (produced by CLI).\n",
    "- Write all figures/summaries to `outputs/exploration/` (DVCâ€‘tracked as appropriate).\n",
    "- Record environment/CLI state for reproducibility in `logs/` and local cell output.\n",
    "\n",
    "**What this notebook does**\n",
    "1. Environment & repo sanity checks.\n",
    "2. Discover raw files (HDF5 / NPZ) under `data/`.\n",
    "3. FGS1 quick looks: light curve segment, rolling stats, basic noise proxy.\n",
    "4. AIRS quick looks: wavelength grid, example spectra, perâ€‘bin variance, molecular band overlays.\n",
    "5. Persist artifacts (PNGs + JSON summary) into `outputs/exploration/`.\n",
    "\n",
    "> Tip: For calibration and training, use the dedicated notebooks (02/03/â€¦) or the CLI directly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Setup & folders\n",
    "Resolve project paths (assumes this notebook lives in `/notebooks`). Creates an output folder for artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "init"
    ]
   },
   "outputs": [],
   "source": [
    "import os, sys, json, shutil, textwrap, subprocess\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook'); sns.set_style('whitegrid')\n",
    "\n",
    "# Resolve paths relative to repo root (../ from /notebooks)\n",
    "NB_DIR = Path.cwd()\n",
    "ROOT = NB_DIR if (NB_DIR / 'data').exists() else NB_DIR.parents[0]\n",
    "DATA = ROOT / 'data'\n",
    "OUT = ROOT / 'outputs'\n",
    "EXPOUT = OUT / 'exploration'\n",
    "LOGS = ROOT / 'logs'\n",
    "EXPOUT.mkdir(parents=True, exist_ok=True)\n",
    "LOGS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('ROOT:', ROOT)\n",
    "print('DATA:', DATA)\n",
    "print('OUT :', OUT)\n",
    "print('EXPO:', EXPOUT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Environment & CLI snapshot (bestâ€‘effort)\n",
    "These calls are optional and robust to missing tools; they help trace the environment used for exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "env"
    ]
   },
   "outputs": [],
   "source": [
    "def _run(cmd: str, cwd: Path | None = None):\n",
    "    print(f\"\\n$ {cmd}\")\n",
    "    try:\n",
    "        p = subprocess.run(cmd, shell=True, text=True, capture_output=True, cwd=str(cwd or ROOT))\n",
    "        out = (p.stdout or '')[-2000:]\n",
    "        err = (p.stderr or '')[-2000:]\n",
    "        print(out.strip())\n",
    "        if p.returncode != 0 and err.strip():\n",
    "            print('[stderr]', err.strip())\n",
    "    except Exception as e:\n",
    "        print('[skip]', e)\n",
    "\n",
    "_run('python --version')\n",
    "_run('spectramind --version')          # unified CLI (if available)\n",
    "_run('dvc --version')                   # DVC presence\n",
    "_run('git rev-parse --short HEAD')      # commit id\n",
    "_run('git status -s')                   # dirty state hint\n",
    "\n",
    "# Persist a small env snapshot for audit\nn",
    "env_snapshot = {\n",
    "    'python': sys.version.split()[0],\n",
    "    'cwd': str(Path.cwd()),\n",
    "}\n",
    "with open(EXPOUT / 'env_snapshot.json', 'w') as f:\n",
    "    json.dump(env_snapshot, f, indent=2)\n",
    "print('Saved', EXPOUT / 'env_snapshot.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Discover candidate raw files (HDF5 / NPZ)\n",
    "We only *read* from `data/`. You can plug calibrated/derived artifacts later from `outputs/` if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "discover"
    ]
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "raw_h5 = sorted(DATA.glob('**/*.h5'))\n",
    "raw_npz = sorted(DATA.glob('**/*.npz'))\n",
    "print(f\"Found {len(raw_h5)} HDF5 and {len(raw_npz)} NPZ files under data/ (show up to 10):\")\n",
    "for p in (raw_h5[:10] + raw_npz[:10]):\n",
    "    print(' -', p.relative_to(ROOT))\n",
    "\n",
    "# Choose a sample file for quick looks\n",
    "sample_h5 = raw_h5[0] if raw_h5 else None\n",
    "sample_npz = raw_npz[0] if raw_npz else None\n",
    "print('\\nSample HDF5:', sample_h5)\n",
    "print('Sample  NPZ:', sample_npz)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) HDF5 structure peek (FGS1 + AIRS groups)\n",
    "We expect groups like `FGS1/time, FGS1/raw or cal`, and `AIRS/wavelength, AIRS/raw or cal`. This is a *nonâ€‘failing* peek."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "peek"
    ]
   },
   "outputs": [],
   "source": [
    "def peek_h5(h5path: Path, max_keys: int = 15):\n",
    "    import h5py\n",
    "    try:\n",
    "        with h5py.File(h5path, 'r') as f:\n",
    "            print('Groups:', list(f.keys()))\n",
    "            for g in list(f.keys()):\n",
    "                try:\n",
    "                    keys = list(f[g].keys())\n",
    "                    head = keys[:max_keys]\n",
    "                    print(f'  /{g}: {head}...')\n",
    "                except Exception as e:\n",
    "                    print(f'  /{g}: <unreadable> ({e})')\n",
    "    except Exception as e:\n",
    "        print('[skip] h5 peek:', e)\n",
    "\n",
    "if sample_h5:\n",
    "    peek_h5(sample_h5)\n",
    "else:\n",
    "    print('No HDF5 found. You can still proceed with NPZ if schema matches.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) FGS1 exploration â€” light curve segment & rolling stats\n",
    "Plot a segment of the FGS1 time series and compute a simple rolling mean/std to visualize noise structure. Handles both `raw` and `cal` if present.\n",
    "\n",
    "> **Note**: This is for *exploration only*; do not perform pipeline detrending here. Use CLI calibration/training notebooks for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "fgs1"
    ]
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_fgs1(h5path: Path, n: int | None = 20000):\n",
    "    import h5py\n",
    "    with h5py.File(h5path, 'r') as f:\n",
    "        t = None\n",
    "        y = None\n",
    "        if 'FGS1' in f:\n",
    "            grp = f['FGS1']\n",
    "            if 'time' in grp: t = grp['time'][:]\n",
    "            # prefer calibrated if exists, else raw\n",
    "            if 'cal' in grp: y = grp['cal'][:]\n",
    "            elif 'raw' in grp: y = grp['raw'][:]\n",
    "        if t is None or y is None:\n",
    "            return None, None\n",
    "        if n is not None and len(t) > n:\n",
    "            t = t[:n]; y = y[:n]\n",
    "        return t, y\n",
    "\n",
    "if sample_h5:\n",
    "    t, y = load_fgs1(sample_h5, n=20000)\n",
    "else:\n",
    "    t, y = None, None\n",
    "\n",
    "if t is not None and y is not None:\n",
    "    fig, ax = plt.subplots(figsize=(12,4))\n",
    "    ax.plot(t, y, lw=0.5)\n",
    "    ax.set_title('FGS1 light curve (first ~20k samples)')\n",
    "    ax.set_xlabel('time [arb]')\n",
    "    ax.set_ylabel('flux [arb]')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(EXPOUT / 'fgs1_lightcurve_segment.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "    # Rolling statistics (window in samples â€” pick ~1â€“2% of the segment length)\n",
    "    df = pd.DataFrame({'time': t, 'flux': y})\n",
    "    win = max(51, int(0.01 * len(df))) | 1  # odd window\n",
    "    df['roll_mean'] = df['flux'].rolling(win, center=True, min_periods=win//2).mean()\n",
    "    df['roll_std']  = df['flux'].rolling(win, center=True, min_periods=win//2).std()\n",
    "\n",
    "    fig, ax = plt.subplots(2,1,figsize=(12,6), sharex=True)\n",
    "    ax[0].plot(df['time'], df['flux'], lw=0.4, label='flux')\n",
    "    ax[0].plot(df['time'], df['roll_mean'], lw=1.0, label=f'rolling mean (w={win})')\n",
    "    ax[0].legend(loc='best'); ax[0].set_ylabel('flux')\n",
    "    ax[1].plot(df['time'], df['roll_std'], lw=0.8, color='tab:orange')\n",
    "    ax[1].set_ylabel('rolling std'); ax[1].set_xlabel('time')\n",
    "    fig.suptitle('FGS1 rolling stats (exploration)')\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(EXPOUT / 'fgs1_rolling_stats.png', dpi=150)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('FGS1 not present in sample file.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) AIRS exploration â€” wavelength grid & example spectra\n",
    "We visualize the wavelength axis, a few spectra, and basic perâ€‘bin variance. If both `raw` and `cal` exist, we prefer `cal` for visualization only (no pipeline operations here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "airs"
    ]
   },
   "outputs": [],
   "source": [
    "def load_airs(h5path: Path, k: int = 3):\n",
    "    import h5py\n",
    "    with h5py.File(h5path, 'r') as f:\n",
    "        if 'AIRS' not in f:\n",
    "            return None, None\n",
    "        wl = None; cube = None\n",
    "        grp = f['AIRS']\n",
    "        if 'wavelength' in grp:\n",
    "            wl = grp['wavelength'][:]\n",
    "        # Prefer 'cal' if 3D [time/idx, wavelength] present; else 'raw'\n",
    "        key = 'cal' if 'cal' in grp else ('raw' if 'raw' in grp else None)\n",
    "        if key is None:\n",
    "            return wl, None\n",
    "        data = grp[key][:]\n",
    "        # Normalize shape to (N, W)\n",
    "        if data.ndim == 1:\n",
    "            data = data[None, :]\n",
    "        elif data.ndim == 2:\n",
    "            pass\n",
    "        else:\n",
    "            # If shape is (T, W, H) or similar, try first axis as index and collapse others\n",
    "            data = data.reshape(data.shape[0], -1)\n",
    "        # Limit to first k spectra for quick looks\n",
    "        data_k = data[:max(1, k)]\n",
    "        return wl, data_k\n",
    "\n",
    "wl, spectra = (None, None)\n",
    "if sample_h5:\n",
    "    wl, spectra = load_airs(sample_h5, k=5)\n",
    "\n",
    "if wl is not None:\n",
    "    fig, ax = plt.subplots(figsize=(10,3))\n",
    "    ax.hist(wl, bins=min(60, len(wl)//2 + 1), alpha=0.8)\n",
    "    ax.set_title('AIRS wavelength distribution')\n",
    "    ax.set_xlabel('wavelength [Î¼m]'); ax.set_ylabel('count')\n",
    "    fig.tight_layout(); fig.savefig(EXPOUT / 'airs_wavelength_hist.png', dpi=150)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No AIRS wavelength axis found in sample file.')\n",
    "\n",
    "if wl is not None and spectra is not None:\n",
    "    fig, ax = plt.subplots(figsize=(12,4))\n",
    "    for i, s in enumerate(spectra):\n",
    "        ax.plot(wl, s, lw=0.9, label=f'spectrum #{i}')\n",
    "    ax.set_title('AIRS example spectra (exploration)')\n",
    "    ax.set_xlabel('wavelength [Î¼m]'); ax.set_ylabel('flux [arb]')\n",
    "    ax.legend(loc='best')\n",
    "    fig.tight_layout(); fig.savefig(EXPOUT / 'airs_example_spectra.png', dpi=150)\n",
    "    plt.show()\n",
    "\n",
    "    # Perâ€‘bin variance (across the displayed sample spectra)\n",
    "    vb = np.nanvar(spectra, axis=0)\n",
    "    fig, ax = plt.subplots(figsize=(12,3))\n",
    "    ax.plot(wl, vb, lw=1.0, color='tab:orange')\n",
    "    ax.set_title('AIRS perâ€‘bin variance (sample)')\n",
    "    ax.set_xlabel('wavelength [Î¼m]'); ax.set_ylabel('var')\n",
    "    fig.tight_layout(); fig.savefig(EXPOUT / 'airs_perbin_variance.png', dpi=150)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('AIRS spectra not available for plotting.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Molecular band overlays (educational)\n",
    "For visualization only, shade canonical bands (Hâ‚‚O, COâ‚‚, CHâ‚„) over the plotted spectrum(s). This is not a physics pipeline step; it helps eyeball correspondence between features and known bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "bands"
    ]
   },
   "outputs": [],
   "source": [
    "molecular_bands = {\n",
    "    'H2O': [(1.30, 1.50), (1.80, 2.00)],\n",
    "    'CO2': [(2.00, 2.10), (4.20, 4.40)],\n",
    "    'CH4': [(3.20, 3.40)],\n",
    "}\n",
    "\n",
    "def overlay_bands(wl, s, title='AIRS spectrum with molecular bands'):\n",
    "    fig, ax = plt.subplots(figsize=(12,4))\n",
    "    ax.plot(wl, s, lw=0.9, label='spectrum')\n",
    "    for mol, bands in molecular_bands.items():\n",
    "        for (lo, hi) in bands:\n",
    "            ax.axvspan(lo, hi, color='gray', alpha=0.18)\n",
    "            ax.text((lo+hi)/2, np.nanmax(s)*0.98, mol, ha='center', va='top', fontsize=8, alpha=0.8)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('wavelength [Î¼m]'); ax.set_ylabel('flux [arb]')\n",
    "    fig.tight_layout();\n",
    "    return fig\n",
    "\n",
    "if wl is not None and spectra is not None and len(spectra):\n",
    "    fig = overlay_bands(wl, spectra[0])\n",
    "    fig.savefig(EXPOUT / 'airs_spectrum_with_bands.png', dpi=150)\n",
    "    plt.show()\n",
    "else:\n",
    "    print('Skip band overlay (no AIRS spectrum available).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Persist an exploration summary (JSON)\n",
    "We stash a structured summary of what was found/visualized so downstream diagnostics can pick it up if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "persist"
    ]
   },
   "outputs": [],
   "source": [
    "summary = {\n",
    "    'fgs1': {\n",
    "        'present': t is not None and y is not None,\n",
    "        'n_points': int(len(t)) if t is not None else 0,\n",
    "        'artifacts': [\n",
    "            str((EXPOUT / 'fgs1_lightcurve_segment.png').relative_to(ROOT)),\n",
    "            str((EXPOUT / 'fgs1_rolling_stats.png').relative_to(ROOT)),\n",
    "        ],\n",
    "    },\n",
    "    'airs': {\n",
    "        'present': wl is not None,\n",
    "        'wavelength_bins': int(len(wl)) if wl is not None else 0,\n",
    "        'example_spectra': int(spectra.shape[0]) if isinstance(spectra, np.ndarray) else 0,\n",
    "        'artifacts': [\n",
    "            str((EXPOUT / 'airs_wavelength_hist.png').relative_to(ROOT)),\n",
    "            str((EXPOUT / 'airs_example_spectra.png').relative_to(ROOT)),\n",
    "            str((EXPOUT / 'airs_perbin_variance.png').relative_to(ROOT)),\n",
    "            str((EXPOUT / 'airs_spectrum_with_bands.png').relative_to(ROOT)) if (EXPOUT / 'airs_spectrum_with_bands.png').exists() else None,\n",
    "        ],\n",
    "    },\n",
    "}\n",
    "with open(EXPOUT / 'exploration_summary.json', 'w') as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print('Saved', EXPOUT / 'exploration_summary.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) (Optional) CLI stubs you may run later\n",
    "These demonstrate the *correct* way to perform data calibration or diagnostics â€” **always via CLI/Hydra**, not adâ€‘hoc code. Keep commented unless you intend to run them here.\n",
    "\n",
    "```bash\n",
    "# Minimal selfâ€‘test (fast, safe):\n",
    "# spectramind test --fast\n",
    "\n",
    "# Sample calibration (writes to outputs/calibrated):\n",
    "# spectramind calibrate --sample 3 --outdir outputs/calibrated --fast\n",
    "\n",
    "# Diagnostics (HTML report saved under outputs/diagnostics):\n",
    "# spectramind diagnose dashboard --no-umap=false --no-tsne=false --out outputs/diagnostics/report.html\n",
    "```\n",
    "\n",
    "> For full calibration/training flows, see `02_calibration_walkthrough.ipynb` and `03_train_v50_demo.ipynb`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}