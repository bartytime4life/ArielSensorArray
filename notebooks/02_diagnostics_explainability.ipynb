{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "# üß≠ SpectraMind V50 ‚Äî 02 ¬∑ Diagnostics & Explainability\n\n**NeurIPS 2025 Ariel Data Challenge** ¬∑ *NASA‚Äëgrade reproducibility w/ Hydra + DVC + CLI*\n\nThis notebook focuses on diagnostics and explainability artifacts produced by the SpectraMind V50 pipeline.\nIt is *CLI‚Äëfirst*, meaning: wherever possible, we **call the `spectramind` CLI** to generate artifacts,\nthen **render them here**. Each section also includes a *graceful fallback* path that reads existing files\n(e.g., `diagnostic_summary.json`, `*.html`, `*.csv`, `*.npy`) directly if present.\n\n> Golden rule: **No hidden analytics**. The GUI/notebook **reflects** what the CLI generated to keep faithful,\n> reproducible results. Cells here log their actions and record run metadata for later auditing.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## ‚úÖ What you can do here\n\n1. Run *lightweight* CLI diagnostics (UMAP/t‚ÄëSNE, SHAP overlays, symbolic rule analysis, FFT/smoothness, calibration).\n2. Render previously generated HTML dashboards and plots.\n3. Inspect metrics from `diagnostic_summary.json` across planets and configs.\n4. Export a refreshed diagnostics dashboard and append metadata into `v50_debug_log.md`.\n\n> Tip: Start with the **Environment & Paths** cell below, then try **Quick CLI sanity** to verify your setup.\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## üîß Environment & Paths"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# This cell sets up common paths and logs environment context.\n# Adjust ROOT to your repository root if needed.\nfrom pathlib import Path\nimport json, os, sys, platform, shutil, textwrap\nfrom datetime import datetime\n\n# ---- Repository root deduction: prefer CWD; allow manual override ----\nROOT = Path.cwd()\nARTEFACTS = ROOT / \"artifacts\"\nDIAG_DIR = ARTEFACTS / \"diagnostics\"\nHTML_DIR = DIAG_DIR / \"html\"\nPLOTS_DIR = DIAG_DIR / \"plots\"\n\n# Common artifact inputs (created by CLI)\nDIAG_SUMMARY = DIAG_DIR / \"diagnostic_summary.json\"\nSHAP_JSON = DIAG_DIR / \"shap_symbolic_fusion_topk_bins.json\"\nSYMB_JSON = DIAG_DIR / \"symbolic_violation_summary.json\"\nCOREL_JSON = DIAG_DIR / \"corel_calibration_summary.json\"\nUMAP_HTML = HTML_DIR / \"umap_v50.html\"\nTSNE_HTML = HTML_DIR / \"tsne_interactive.html\"\nDASHBOARD_HTML = HTML_DIR / \"diagnostic_report_v1.html\"\nLOG_MD = ROOT / \"v50_debug_log.md\"\n\n# Optional latent/label fallbacks\nLATENTS_NPY = DIAG_DIR / \"latents.npy\"\nLATENTS_CSV = DIAG_DIR / \"latents.csv\"\nLABELS_CSV = DIAG_DIR / \"labels.csv\"\n\n# Create folders if missing (no-op if existing)\nfor d in [ARTEFACTS, DIAG_DIR, HTML_DIR, PLOTS_DIR]:\n    d.mkdir(parents=True, exist_ok=True)\n\nenv = {\n    \"timestamp\": datetime.now().isoformat(timespec=\"seconds\"),\n    \"python\": sys.version.replace(\"\\n\", \" \"),\n    \"platform\": platform.platform(),\n    \"cwd\": str(ROOT),\n    \"paths\": {\n        \"ARTEFACTS\": str(ARTEFACTS),\n        \"DIAG_DIR\": str(DIAG_DIR),\n        \"HTML_DIR\": str(HTML_DIR),\n        \"PLOTS_DIR\": str(PLOTS_DIR),\n        \"DIAG_SUMMARY\": str(DIAG_SUMMARY),\n        \"SHAP_JSON\": str(SHAP_JSON),\n        \"SYMB_JSON\": str(SYMB_JSON),\n        \"COREL_JSON\": str(COREL_JSON),\n        \"UMAP_HTML\": str(UMAP_HTML),\n        \"TSNE_HTML\": str(TSNE_HTML),\n        \"DASHBOARD_HTML\": str(DASHBOARD_HTML),\n        \"LOG_MD\": str(LOG_MD),\n        \"LATENTS_NPY\": str(LATENTS_NPY),\n        \"LATENTS_CSV\": str(LATENTS_CSV),\n        \"LABELS_CSV\": str(LABELS_CSV),\n    },\n}\nprint(json.dumps(env, indent=2))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## ü©∫ Quick CLI sanity (optional)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# This cell *optionally* checks CLI availability. It's safe to skip if your CLI isn't on PATH.\n# In many notebook runtimes, subprocess may not find your local CLI; that's okay.\nimport shutil, subprocess\n\ndef check_cli(cmd=\"spectramind\", args=[\"--version\"]):\n    exe = shutil.which(cmd)\n    if not exe:\n        print(\"‚ö†Ô∏è 'spectramind' CLI not found on PATH. Skipping CLI sanity check.\")\n        return {\"available\": False}\n    try:\n        out = subprocess.check_output([cmd] + args, stderr=subprocess.STDOUT, text=True, timeout=30)\n        print(out)\n        return {\"available\": True, \"output\": out}\n    except Exception as e:\n        print(f\"‚ö†Ô∏è CLI call failed: {e}\")\n        return {\"available\": True, \"error\": str(e)}\n\ncli_info = check_cli()\ncli_info\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## üåà UMAP Diagnostics ‚Äî generate or load"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Attempt to call the CLI to generate UMAP HTML; otherwise load existing HTML if present.\nimport subprocess, webbrowser\n\ndef run_umap_cli():\n    try:\n        exe = shutil.which(\"spectramind\")\n        if not exe:\n            return False, \"CLI not found\"\n        # Minimal example ‚Äî adjust flags to your configs\n        cmd = [\"spectramind\", \"diagnose\", \"umap\",\n               \"--html-out\", str(UMAP_HTML),\n               \"--log-file\", str(LOG_MD),\n               \"--open-browser\", \"false\"]\n        print(\"Running:\", \" \".join(cmd))\n        subprocess.check_call(cmd, timeout=600)\n        return True, \"OK\"\n    except Exception as e:\n        return False, str(e)\n\nok, msg = run_umap_cli()\nif ok:\n    print(f\"‚úÖ UMAP generated at: {UMAP_HTML}\")\nelif UMAP_HTML.exists():\n    print(\"‚ö†Ô∏è CLI skipped/failed; using existing:\", UMAP_HTML)\nelse:\n    print(\"‚ùå UMAP not available; create latents or run CLI separately.\")\n\n# Inline display hint (cannot iframe automatically in all notebook environments)\nprint(\"To open UMAP HTML manually if needed:\", str(UMAP_HTML))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## üåÄ t‚ÄëSNE Diagnostics ‚Äî generate or load"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Attempt to call CLI t‚ÄëSNE; otherwise load existing HTML if present.\ndef run_tsne_cli():\n    try:\n        exe = shutil.which(\"spectramind\")\n        if not exe:\n            return False, \"CLI not found\"\n        cmd = [\"spectramind\", \"diagnose\", \"tsne-latents\",\n               \"--html-out\", str(TSNE_HTML),\n               \"--log-file\", str(LOG_MD),\n               \"--open-browser\", \"false\"]\n        print(\"Running:\", \" \".join(cmd))\n        subprocess.check_call(cmd, timeout=600)\n        return True, \"OK\"\n    except Exception as e:\n        return False, str(e)\n\nok, msg = run_tsne_cli()\nif ok:\n    print(f\"‚úÖ t‚ÄëSNE generated at: {TSNE_HTML}\")\nelif TSNE_HTML.exists():\n    print(\"‚ö†Ô∏è CLI skipped/failed; using existing:\", TSNE_HTML)\nelse:\n    print(\"‚ùå t‚ÄëSNE not available; ensure latents exist or run CLI separately.\")\n\nprint(\"To open t‚ÄëSNE HTML manually if needed:\", str(TSNE_HTML))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "### üîÅ Fallback: quickscatter for latents (matplotlib)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# If HTMLs are not present, try to render a simple 2D scatter from CSV/NPY latents.\n# Matplotlib only (no seaborn, and a single plot per chart per project constraints).\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndef load_matrix(path):\n    if path.suffix == \".csv\":\n        import pandas as pd\n        return pd.read_csv(path, index_col=None).values\n    elif path.suffix == \".npy\":\n        return np.load(path)\n    else:\n        raise ValueError(f\"Unsupported format for {path}\")\n\nlatent_matrix = None\nfor p in [LATENTS_CSV, LATENTS_NPY]:\n    if p.exists():\n        try:\n            latent_matrix = load_matrix(p)\n            print(f\"Loaded latents from {p} with shape {latent_matrix.shape}\")\n            break\n        except Exception as e:\n            print(f\"Failed to load {p}: {e}\")\n\nif latent_matrix is not None:\n    # Use first 2 columns as a crude projection\n    x = latent_matrix[:, 0]\n    y = latent_matrix[:, 1] if latent_matrix.shape[1] > 1 else np.zeros_like(x)\n    plt.figure(figsize=(6, 5))\n    plt.scatter(x, y, s=10, alpha=0.7)\n    plt.title(\"Latent Quickscatter (fallback)\")\n    plt.xlabel(\"Dim 1\")\n    plt.ylabel(\"Dim 2\")\n    plt.show()\nelse:\n    print(\"No latents found for fallback quickscatter.\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## üîç SHAP √ó Symbolic Overlay Inspection"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Load SHAP/symbolic overlay JSON if present; show top-K bins per planet or aggregate stats.\nimport json\nfrom collections import Counter, defaultdict\n\ndef safe_load_json(path):\n    if not path.exists():\n        return None\n    try:\n        with open(path, \"r\", encoding=\"utf-8\") as f:\n            return json.load(f)\n    except Exception as e:\n        print(f\"Failed to parse {path}: {e}\")\n        return None\n\noverlay = safe_load_json(SHAP_JSON)\nif overlay is None:\n    print(f\"‚ö†Ô∏è No overlay JSON at {SHAP_JSON}. Generate via CLI or scripts first.\")\nelse:\n    # Expecting schema like: { \"planets\": { \"planet_id\": { \"top_bins\": [...], \"scores\": {...} } }, ...}\n    planets = overlay.get(\"planets\") or overlay  # tolerate flat schema\n    print(f\"Loaded overlay for {len(planets)} planets.\")\n    # Simple aggregate: most common bins across planets (if present)\n    bin_counts = Counter()\n    for pid, rec in planets.items():\n        top_bins = rec.get(\"top_bins\") or []\n        bin_counts.update(top_bins)\n    most_common = bin_counts.most_common(10)\n    print(\"Top 10 recurrent bins across planets:\", most_common)\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## üß© Symbolic Rule Violations ‚Äî summary view"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Inspect symbolic violation summaries to find dominant rules and hotspots.\nsymb = safe_load_json(SYMB_JSON)\nif symb is None:\n    print(f\"‚ö†Ô∏è No symbolic violation summary at {SYMB_JSON}.\")\nelse:\n    # Tolerate either list or dict formats\n    if isinstance(symb, dict) and \"rules\" in symb:\n        rules = symb[\"rules\"]\n    elif isinstance(symb, list):\n        rules = symb\n    else:\n        rules = symb\n\n    print(\"Symbolic rules summary keys:\", list(rules)[:10] if isinstance(rules, dict) else \"list\")\n    # Very simple aggregate if dict: sort rules by mean violation\n    if isinstance(rules, dict):\n        agg = []\n        for rname, vals in rules.items():\n            v = vals if isinstance(vals, (int, float)) else vals.get(\"mean\", None) if isinstance(vals, dict) else None\n            if v is not None:\n                agg.append((rname, float(v)))\n        agg.sort(key=lambda x: x[1], reverse=True)\n        print(\"Top 10 rules by mean violation:\")\n        for r, v in agg[:10]:\n            print(f\"  {r:40s}  {v:.4f}\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## üìà FFT & Smoothness ‚Äî quick checks on Œº spectra"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Try a lightweight smoothness/FFT visualization from diagnostic_summary.json if available.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ndiag = safe_load_json(DIAG_SUMMARY)\nif not diag:\n    print(f\"‚ö†Ô∏è No diagnostic summary at {DIAG_SUMMARY}. Generate via CLI or scripts first.\")\nelse:\n    # Heuristic: look for one planet entry with \"mu\" or \"spectrum\" field\n    # and draw its FFT magnitude and finite-difference smoothness.\n    # The exact schema varies; we attempt to be permissive.\n    candidates = []\n    if isinstance(diag, dict):\n        # Possible structures: {\"planets\": {...}}, or {\"items\": [...]}, or direct\n        root = diag.get(\"planets\") or diag.get(\"items\") or diag\n        if isinstance(root, dict):\n            candidates = list(root.values())\n        elif isinstance(root, list):\n            candidates = root\n    if not candidates:\n        print(\"Could not find planet entries in diagnostic summary.\")\n    else:\n        # Find first record with a 1D mu-like array\n        mu = None\n        for rec in candidates:\n            arr = rec.get(\"mu\") or rec.get(\"spectrum\") or rec.get(\"mu_mean\")\n            if isinstance(arr, list) and len(arr) >= 16:\n                mu = np.array(arr, dtype=float)\n                break\n        if mu is None:\n            print(\"No suitable Œº array found in diagnostic summary.\")\n        else:\n            # FFT magnitude\n            fft_mag = np.abs(np.fft.rfft(mu))\n            plt.figure(figsize=(6,4))\n            plt.plot(fft_mag)\n            plt.title(\"FFT magnitude of Œº (example planet)\")\n            plt.xlabel(\"Frequency bin\")\n            plt.ylabel(\"|FFT|\")\n            plt.show()\n\n            # Smoothness (finite differences)\n            grad = np.diff(mu)\n            curv = np.diff(mu, n=2)\n            plt.figure(figsize=(6,4))\n            plt.plot(np.abs(grad), label=\"|‚àÇŒº|\")\n            plt.plot(np.abs(curv), label=\"|‚àÇ¬≤Œº|\")\n            plt.title(\"Smoothness diagnostics of Œº (example planet)\")\n            plt.xlabel(\"Spectral bin\")\n            plt.ylabel(\"Magnitude\")\n            plt.legend()\n            plt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## üéØ Calibration (œÉ) ‚Äî COREL overview"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Load calibration summary if available and show simple histograms.\nimport numpy as np\nimport matplotlib.pyplot as plt\n\ncorel = safe_load_json(COREL_JSON)\nif corel is None:\n    print(f\"‚ö†Ô∏è No COREL calibration summary at {COREL_JSON}.\")\nelse:\n    # Heuristic: expect per-bin coverage or residuals arrays\n    cov = corel.get(\"coverage\") or corel.get(\"per_bin_coverage\")\n    res = corel.get(\"residuals\") or corel.get(\"per_bin_residual\")\n    if isinstance(cov, list) and len(cov) > 0:\n        cov = np.array(cov, dtype=float)\n        plt.figure(figsize=(6,4))\n        plt.hist(cov, bins=30, alpha=0.9)\n        plt.title(\"Coverage histogram (COREL)\")\n        plt.xlabel(\"Coverage\")\n        plt.ylabel(\"Count\")\n        plt.show()\n    if isinstance(res, list) and len(res) > 0:\n        res = np.array(res, dtype=float)\n        plt.figure(figsize=(6,4))\n        plt.hist(res, bins=30, alpha=0.9)\n        plt.title(\"Residual histogram (COREL)\")\n        plt.xlabel(\"Residual\")\n        plt.ylabel(\"Count\")\n        plt.show()\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## üß™ Build Diagnostics Dashboard (optional)"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Call the CLI to generate the full HTML diagnostics dashboard, or load an existing one.\ndef run_dashboard_cli():\n    try:\n        exe = shutil.which(\"spectramind\")\n        if not exe:\n            return False, \"CLI not found\"\n        cmd = [\"spectramind\", \"diagnose\", \"dashboard\",\n               \"--html-out\", str(DASHBOARD_HTML),\n               \"--log-file\", str(LOG_MD),\n               \"--open-browser\", \"false\"]\n        print(\"Running:\", \" \".join(cmd))\n        subprocess.check_call(cmd, timeout=1200)\n        return True, \"OK\"\n    except Exception as e:\n        return False, str(e)\n\nok, msg = run_dashboard_cli()\nif ok:\n    print(f\"‚úÖ Diagnostics dashboard generated at: {DASHBOARD_HTML}\")\nelif DASHBOARD_HTML.exists():\n    print(\"‚ö†Ô∏è CLI skipped/failed; using existing:\", DASHBOARD_HTML)\nelse:\n    print(\"‚ùå Dashboard not available. Generate via CLI when ready.\")\n\nprint(\"To open manually if needed:\", str(DASHBOARD_HTML))\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## üßæ Append run metadata to `v50_debug_log.md`"
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": "# Append a structured entry to v50_debug_log.md for auditability.\nfrom datetime import datetime\nentry = f\"\"\"### Notebook: 02_diagnostics_explainability.ipynb\n- timestamp: {datetime.now().isoformat(timespec=\"seconds\")}\n- cwd: {ROOT}\n- python: {platform.python_version()}\n- actions:\n  - env_init\n  - umap_try_cli: {'exists' if UMAP_HTML.exists() else 'missing'}\n  - tsne_try_cli: {'exists' if TSNE_HTML.exists() else 'missing'}\n  - shap_overlay_loaded: {SHAP_JSON.exists()}\n  - symbolic_summary_loaded: {SYMB_JSON.exists()}\n  - corel_summary_loaded: {COREL_JSON.exists()}\n  - dashboard: {'exists' if DASHBOARD_HTML.exists() else 'missing'}\n\"\"\"\n\ntry:\n    with open(LOG_MD, \"a\", encoding=\"utf-8\") as f:\n        f.write(entry + \"\\n\")\n    print(f\"Appended notebook log entry to {LOG_MD}\")\nexcept Exception as e:\n    print(f\"‚ö†Ô∏è Could not append to {LOG_MD}: {e}\")\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": "## üìö References & Next Steps\n\n- `spectramind diagnose umap` ¬∑ Generate UMAP HTML with symbolic overlays and links.\n- `spectramind diagnose tsne-latents` ¬∑ Interactive t‚ÄëSNE with confidence/links.\n- `spectramind diagnose smoothness` ¬∑ Produce smoothness maps and CSV summaries.\n- `spectramind diagnose dashboard` ¬∑ Unified HTML diagnostics dashboard.\n\n**Pro tip:** Pair this notebook with `00_quickstart.ipynb` and `03_ablation_and_tuning.ipynb` for the full pipeline flow.\n"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.8",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}