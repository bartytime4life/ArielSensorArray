{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aab413f3",
   "metadata": {},
   "source": [
    "# üß™ SpectraMind V50 ‚Äî 03 ¬∑ Ablation & Tuning\n",
    "\n",
    "**NeurIPS 2025 Ariel Data Challenge** ¬∑ *CLI‚Äëfirst, Hydra‚Äësafe, reproducible*\n",
    "\n",
    "This notebook drives **systematic ablations and hyperparameter tuning** over the SpectraMind V50 stack.\n",
    "It favors the **`spectramind` CLI** (Typer) for all heavy‚Äëlifting, and **reads artifacts** to visualize\n",
    "and compare results. Every step is **deterministic where possible** and produces evidence (logs/JSON/HTML).\n",
    "\n",
    "> Golden rule: the notebook mirrors what you'd do from the CLI and never hides transformations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d4f1f0",
   "metadata": {},
   "source": [
    "## üéØ Objectives\n",
    "\n",
    "- Run or resume **symbolic‚Äëaware ablations** (smoothness, symbolic weights, entropy penalties, COREL/œÉ, etc.).\n",
    "- Inspect and plot **GLL, RMSE/MAE, calibration, violation scores** from ablation artifacts.\n",
    "- Generate **Markdown + HTML leaderboards**, and optionally a **Top‚ÄëN ZIP** bundle.\n",
    "- Append run metadata to `v50_debug_log.md` for auditability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e218bf",
   "metadata": {},
   "source": [
    "## üîß Environment & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852fe9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json, os, sys, platform\n",
    "from datetime import datetime\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "ART = ROOT / \"artifacts\"\n",
    "ABLATE_DIR = ART / \"ablation\"\n",
    "ABLATE_RUNS = ABLATE_DIR / \"runs\"\n",
    "ABLATE_SUMMARY_JSON = ABLATE_DIR / \"leaderboard.json\"\n",
    "ABLATE_SUMMARY_CSV  = ABLATE_DIR / \"leaderboard.csv\"\n",
    "ABLATE_SUMMARY_MD   = ABLATE_DIR / \"leaderboard.md\"\n",
    "ABLATE_SUMMARY_HTML = ABLATE_DIR / \"leaderboard.html\"\n",
    "TOPN_ZIP            = ABLATE_DIR / \"topN_bundle.zip\"\n",
    "LOG_MD              = ROOT / \"v50_debug_log.md\"\n",
    "\n",
    "for d in [ART, ABLATE_DIR, ABLATE_RUNS]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "env = {\n",
    "    \"timestamp\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    \"python\": sys.version.replace(\"\\n\", \" \"),\n",
    "    \"platform\": platform.platform(),\n",
    "    \"cwd\": str(ROOT),\n",
    "    \"paths\": {\n",
    "        \"ART\": str(ART),\n",
    "        \"ABLATE_DIR\": str(ABLATE_DIR),\n",
    "        \"ABLATE_RUNS\": str(ABLATE_RUNS),\n",
    "        \"ABLATE_SUMMARY_JSON\": str(ABLATE_SUMMARY_JSON),\n",
    "        \"ABLATE_SUMMARY_CSV\": str(ABLATE_SUMMARY_CSV),\n",
    "        \"ABLATE_SUMMARY_MD\": str(ABLATE_SUMMARY_MD),\n",
    "        \"ABLATE_SUMMARY_HTML\": str(ABLATE_SUMMARY_HTML),\n",
    "        \"TOPN_ZIP\": str(TOPN_ZIP),\n",
    "        \"LOG_MD\": str(LOG_MD),\n",
    "    }\n",
    "}\n",
    "print(json.dumps(env, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b08003",
   "metadata": {},
   "source": [
    "## ü©∫ Quick CLI sanity (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60857b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, subprocess\n",
    "\n",
    "def check_cli(cmd=\"spectramind\", args=[\"--version\"]):\n",
    "    exe = shutil.which(cmd)\n",
    "    if not exe:\n",
    "        print(\"‚ö†Ô∏è 'spectramind' CLI not found on PATH. Skipping CLI sanity check.\")\n",
    "        return {\"available\": False}\n",
    "    try:\n",
    "        out = subprocess.check_output([cmd] + args, stderr=subprocess.STDOUT, text=True, timeout=30)\n",
    "        print(out)\n",
    "        return {\"available\": True, \"output\": out}\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è CLI call failed: {e}\")\n",
    "        return {\"available\": True, \"error\": str(e)}\n",
    "\n",
    "cli_info = check_cli()\n",
    "cli_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db30e5d6",
   "metadata": {},
   "source": [
    "## üß∞ Define Ablation Grids\n",
    "\n",
    "Below are **example grids** focused on symbolic and physics knobs. Tune to match your configs.\n",
    "\n",
    "- `loss.symbolic.smoothness.lambda`: smoothness penalty weight\n",
    "- `loss.symbolic.asymmetry.lambda`: asymmetry penalty weight\n",
    "- `loss.symbolic.nonneg.lambda`: non‚Äënegativity hinge\n",
    "- `training.scheduler.max_lr`: learning rate peak\n",
    "- `training.augmentation.jitter`: FGS1 jitter augmentation on/off\n",
    "- `uncertainty.corel.enable`: COREL œÉ calibration toggle\n",
    "- `uncertainty.temperature.value`: temperature scaling\n",
    "- `decoder.sigma.attn_fusion`: enable attention√ósymbolic fusion in œÉ head\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f115ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can edit these directly or build them programmatically.\n",
    "AB_GRID = {\n",
    "    \"one_at_a_time\": {\n",
    "        \"loss.symbolic.smoothness.lambda\": [0.0, 0.01, 0.05, 0.1],\n",
    "        \"loss.symbolic.asymmetry.lambda\":  [0.0, 0.01, 0.05],\n",
    "        \"loss.symbolic.nonneg.lambda\":     [0.0, 0.05],\n",
    "        \"training.scheduler.max_lr\":       [1e-4, 3e-4, 1e-3],\n",
    "        \"training.augmentation.jitter\":    [False, True],\n",
    "        \"uncertainty.corel.enable\":        [False, True],\n",
    "        \"uncertainty.temperature.value\":   [1.0, 1.25, 1.5],\n",
    "        \"decoder.sigma.attn_fusion\":       [False, True],\n",
    "    },\n",
    "    \"cartesian\": {\n",
    "        # Keep cartesian grids modest to respect runtime budgets.\n",
    "        \"loss.symbolic.smoothness.lambda\": [0.0, 0.05],\n",
    "        \"training.scheduler.max_lr\":       [1e-4, 3e-4],\n",
    "        \"uncertainty.corel.enable\":        [False, True],\n",
    "    }\n",
    "}\n",
    "print(json.dumps(AB_GRID, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5669d5ba",
   "metadata": {},
   "source": [
    "## üöÄ Launch ablations via `spectramind ablate` (or load existing results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cdc038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, subprocess, shutil, os, time\n",
    "\n",
    "def run_ablate(mode=\"one-at-a-time\",\n",
    "               top_n=10,\n",
    "               retries=1,\n",
    "               parallel=2,\n",
    "               md_out=None,\n",
    "               html_out=None,\n",
    "               csv_out=None,\n",
    "               topn_zip=None):\n",
    "    exe = shutil.which(\"spectramind\")\n",
    "    if not exe:\n",
    "        print(\"‚ö†Ô∏è CLI not found; skipping ablation launch. You can run it in a terminal and re-run next cells.\")\n",
    "        return False\n",
    "    cmd = [\n",
    "        \"spectramind\", \"ablate\",\n",
    "        \"--mode\", mode,\n",
    "        \"--retries\", str(retries),\n",
    "        \"--parallel\", str(parallel),\n",
    "        \"--top_n\", str(top_n),\n",
    "    ]\n",
    "    if md_out:\n",
    "        cmd += [\"--md\", str(md_out)]\n",
    "    if html_out:\n",
    "        cmd += [\"--open_html\", \"false\", \"--html\", str(html_out)]\n",
    "    if csv_out:\n",
    "        cmd += [\"--csv\", str(csv_out)]\n",
    "    if topn_zip:\n",
    "        cmd += [\"--zip\", str(topn_zip)]\n",
    "    # Note: advanced flags (symbols, metrics, diagnostics) are provided by the CLI impl.\n",
    "    print(\"Running:\", \" \".join(cmd))\n",
    "    try:\n",
    "        subprocess.check_call(cmd, timeout=18000)  # 5 hours cap; adjust to your infra\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"Ablation run failed/aborted:\", e)\n",
    "        return False\n",
    "\n",
    "# Example: try a quick one-at-a-time sweep that writes leaderboard artifacts\n",
    "ok = run_ablate(\n",
    "    mode=\"one-at-a-time\",\n",
    "    top_n=10,\n",
    "    retries=1,\n",
    "    parallel=2,\n",
    "    md_out=ABLATE_SUMMARY_MD,\n",
    "    html_out=ABLATE_SUMMARY_HTML,\n",
    "    csv_out=ABLATE_SUMMARY_CSV,\n",
    "    topn_zip=TOPN_ZIP\n",
    ")\n",
    "\n",
    "if ok:\n",
    "    print(\"‚úÖ Ablation CLI triggered. Artifacts should appear under:\", ABLATE_DIR)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Skipped or failed to launch ablation via CLI.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47d1097",
   "metadata": {},
   "source": [
    "## üìä Parse leaderboard & visualize top runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d339a26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, csv, math\n",
    "from pathlib import Path\n",
    "\n",
    "def load_leaderboard(json_path=ABLATE_SUMMARY_JSON, csv_path=ABLATE_SUMMARY_CSV):\n",
    "    data = None\n",
    "    if json_path.exists():\n",
    "        try:\n",
    "            with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                data = json.load(f)\n",
    "        except Exception as e:\n",
    "            print(\"Failed to parse JSON leaderboard:\", e)\n",
    "    rows = []\n",
    "    if csv_path.exists():\n",
    "        try:\n",
    "            import pandas as pd\n",
    "            df = pd.read_csv(csv_path)\n",
    "            print(\"CSV leaderboard loaded with shape:\", df.shape)\n",
    "            rows = df.to_dict(orient=\"records\")\n",
    "        except Exception as e:\n",
    "            print(\"Failed to parse CSV leaderboard via pandas:\", e)\n",
    "            # Fallback to Python csv\n",
    "            try:\n",
    "                with open(csv_path, newline=\"\", encoding=\"utf-8\") as f:\n",
    "                    reader = csv.DictReader(f)\n",
    "                    rows = list(reader)\n",
    "                print(\"CSV leaderboard loaded via csv module:\", len(rows), \"rows.\")\n",
    "            except Exception as e2:\n",
    "                print(\"CSV fallback failed:\", e2)\n",
    "    return data, rows\n",
    "\n",
    "lb_json, lb_rows = load_leaderboard()\n",
    "if lb_json is None and not lb_rows:\n",
    "    print(\"No leaderboard artifacts found yet. Once ablations complete, re-run this cell.\")\n",
    "else:\n",
    "    # Heuristic: find a numeric \"gll\" or \"score\" column for ranking\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Select rows and numeric metric\n",
    "    metric_key = None\n",
    "    if lb_rows:\n",
    "        keys = lb_rows[0].keys()\n",
    "        for k in [\"gll\", \"GLL\", \"score\", \"val_gll\", \"val_score\", \"mean_gll\"]:\n",
    "            if k in keys:\n",
    "                metric_key = k\n",
    "                break\n",
    "    # Plot top 15 by metric (lower GLL is better; adjust sign if needed)\n",
    "    if lb_rows and metric_key:\n",
    "        # Convert values to float where possible\n",
    "        def to_float(x):\n",
    "            try: return float(x)\n",
    "            except: return math.inf\n",
    "        sorted_rows = sorted(lb_rows, key=lambda r: to_float(r.get(metric_key, math.inf)))\n",
    "        top = sorted_rows[:15]\n",
    "        labels = [r.get(\"run_id\", r.get(\"short_id\", f\"r{i}\")) for i, r in enumerate(top)]\n",
    "        vals = [to_float(r.get(metric_key, math.inf)) for r in top]\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        plt.bar(range(len(vals)), vals)\n",
    "        plt.xticks(range(len(vals)), labels, rotation=45, ha=\"right\")\n",
    "        plt.ylabel(metric_key)\n",
    "        plt.title(\"Top runs by leaderboard metric\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"Leaderboard parsed, but could not identify a numeric metric column to plot.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c53fbe4",
   "metadata": {},
   "source": [
    "## üß∞ Optional: rebuild leaderboard & Top‚ÄëN ZIP via CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b35d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you ran custom ablations manually, you can regenerate summary artifacts here.\n",
    "import shutil, subprocess\n",
    "\n",
    "def rebuild_leaderboard(md_out=ABLATE_SUMMARY_MD, html_out=ABLATE_SUMMARY_HTML,\n",
    "                        csv_out=ABLATE_SUMMARY_CSV, topn_zip=TOPN_ZIP, top_n=10):\n",
    "    exe = shutil.which(\"spectramind\")\n",
    "    if not exe:\n",
    "        print(\"‚ö†Ô∏è CLI not found; cannot rebuild leaderboard via CLI.\")\n",
    "        return False\n",
    "    cmd = [\n",
    "        \"spectramind\", \"ablate\", \"--rebuild-only\",\n",
    "        \"--top_n\", str(top_n),\n",
    "        \"--md\", str(md_out),\n",
    "        \"--open_html\", \"false\", \"--html\", str(html_out),\n",
    "        \"--csv\", str(csv_out),\n",
    "        \"--zip\", str(topn_zip),\n",
    "    ]\n",
    "    print(\"Running:\", \" \".join(cmd))\n",
    "    try:\n",
    "        subprocess.check_call(cmd, timeout=3600)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"Rebuild failed:\", e)\n",
    "        return False\n",
    "\n",
    "# Example (safe to skip):\n",
    "# ok = rebuild_leaderboard()\n",
    "# print(\"Rebuild:\", ok)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf5e681",
   "metadata": {},
   "source": [
    "## üßæ Append run metadata to `v50_debug_log.md`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f063fb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "entry = f\"\"\"### Notebook: 03_ablation_and_tuning.ipynb\n",
    "- timestamp: {datetime.now().isoformat(timespec=\"seconds\")}\n",
    "- cwd: {ROOT}\n",
    "- python: {platform.python_version()}\n",
    "- actions:\n",
    "  - env_init\n",
    "  - ablate_cli_attempted: true\n",
    "  - leaderboard_json_exists: {ABLATE_SUMMARY_JSON.exists()}\n",
    "  - leaderboard_csv_exists: {ABLATE_SUMMARY_CSV.exists()}\n",
    "  - leaderboard_md_exists: {ABLATE_SUMMARY_MD.exists()}\n",
    "  - leaderboard_html_exists: {ABLATE_SUMMARY_HTML.exists()}\n",
    "  - topN_zip_exists: {TOPN_ZIP.exists()}\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    with open(LOG_MD, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(entry + \"\\n\")\n",
    "    print(f\"Appended notebook log entry to {LOG_MD}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not append to {LOG_MD}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
