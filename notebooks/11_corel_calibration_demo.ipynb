{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": { "display_name": "Python 3", "language": "python", "name": "python3" },
    "language_info": { "name": "python", "version": "3.10" },
    "title": "11_corel_calibration_demo.ipynb",
    "authors": ["SpectraMind V50 Team"],
    "spectramind": {
      "role": "calibration/uncertainty",
      "cli_first": true,
      "outputs_dir": "outputs/notebooks/11_corel_calibration",
      "reproducibility": { "hydra": true, "dvc": true, "logs": true }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 11 · COREL Calibration Demo (SpectraMind V50)\n",
        "\n",
        "Mission‑grade **uncertainty calibration** walkthrough for SpectraMind V50 using **CLI + Hydra** outputs only (no ad‑hoc pipeline code).\n",
        "\n",
        "This notebook:\n",
        "1) Locates pre‑calibration predictions (`μ, σ`) and held‑out targets `y` under `outputs/`.\n",
        "2) Computes baseline **z‑score** diagnostics and coverage before calibration.\n",
        "3) (Optional) Invokes the COREL conformal/GNN calibrator via the CLI to produce calibrated `σ` or prediction intervals.\n",
        "4) Loads calibrated artifacts and recomputes coverage/quantile diagnostics and reliability plots.\n",
        "5) Writes a compact **calibration_report.json** and detail CSV + PNGs under `outputs/notebooks/11_corel_calibration/`.\n",
        "\n",
        "**Contract**: Notebooks are thin orchestration. We only read CLI/Hydra artifacts and, when requested, *call* the CLI. All results are saved in `outputs/` and are DVC‑friendly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": { "tags": ["init"] },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os, sys, json, shutil, subprocess, platform\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_context('notebook'); sns.set_style('whitegrid')\n",
        "\n",
        "ROOT = Path.cwd().resolve()\n",
        "NB_OUT = ROOT / 'outputs' / 'notebooks' / '11_corel_calibration'\n",
        "NB_OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "CLI = shutil.which('spectramind') or (f\"{sys.executable} {ROOT/'spectramind.py'}\" if (ROOT/'spectramind.py').exists() else f\"{sys.executable} -m spectramind\")\n",
        "print('ROOT:', ROOT)\n",
        "print('NB_OUT:', NB_OUT)\n",
        "print('CLI  :', CLI)\n",
        "\n",
        "(NB_OUT/'env_snapshot.json').write_text(json.dumps({'python': platform.python_version(), 'platform': platform.platform()}, indent=2))\n",
        "print('Saved env snapshot.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Parameters\n",
        "Tell the notebook where to look for predictions/labels. If left to `None`, we try to auto‑discover under `outputs/`.\n",
        "\n",
        "- **Before‑calibration**: csv with columns like `planet_id, wavelength_index, mu, sigma` (and optionally `y`). If `y` is not present, set `LABELS_HINT`.\n",
        "- **Labels**: long table `planet_id, wavelength_index, y` or wide per‑planet rows `mu_000..` for ground truth.\n",
        "- **After‑calibration**: csv with same structure but calibrated `sigma_cal` or conformal intervals `lo,hi`.\n",
        "\n",
        "You can also toggle the CLI calibration cell below to generate the calibrated artifacts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": { "tags": ["params"] },
      "execution_count": null,
      "outputs": [],
      "source": [
        "PRED_HINTS = [\n",
        "    ROOT/'outputs'/'predictions'/'predictions.csv',\n",
        "    ROOT/'outputs'/'predictions.csv',\n",
        "    ROOT/'outputs'/'runs',  # scan\n",
        "]\n",
        "LABELS_HINT = None  # e.g., ROOT/'outputs'/'val_labels.csv' or ROOT/'data'/'labels'/'val_labels.csv'\n",
        "CAL_HINTS = [\n",
        "    ROOT/'outputs'/'calibration'/'corel_calibrated.csv',\n",
        "    ROOT/'outputs'/'runs',\n",
        "]\n",
        "\n",
        "# Coverage target (e.g., 90%) for conformal intervals if produced by the CLI\n",
        "TARGET_ALPHA = 0.1  # 1 - coverage\n",
        "\n",
        "print('PRED_HINTS:', [str(p) for p in PRED_HINTS])\n",
        "print('LABELS_HINT:', LABELS_HINT)\n",
        "print('CAL_HINTS :', [str(p) for p in CAL_HINTS])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Locate artifacts\n",
        "We search for the newest CSVs under the hints. If predictions do not include labels, we load labels separately and merge on `(planet_id, wavelength_index)`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": { "tags": ["io"] },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def newest_csv(paths):\n",
        "    cands = []\n",
        "    for h in paths:\n",
        "        if not h.exists():\n",
        "            continue\n",
        "        if h.is_file() and h.suffix.lower()=='.csv':\n",
        "            cands.append(h)\n",
        "        elif h.is_dir():\n",
        "            cands += list(h.rglob('*.csv'))\n",
        "    if not cands:\n",
        "        return None\n",
        "    return sorted(cands, key=lambda p: p.stat().st_mtime)[-1]\n",
        "\n",
        "PRED_CSV = newest_csv(PRED_HINTS)\n",
        "CAL_CSV  = newest_csv(CAL_HINTS)\n",
        "print('PRED_CSV:', PRED_CSV)\n",
        "print('CAL_CSV :', CAL_CSV)\n",
        "if PRED_CSV is None:\n",
        "    raise FileNotFoundError('No predictions CSV found in PRED_HINTS; generate predictions first (see 04_predict_v50_demo).')\n",
        "\n",
        "pred_df = pd.read_csv(PRED_CSV)\n",
        "print('pred_df:', pred_df.shape)\n",
        "pred_df.head(3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": { "tags": ["labels"] },
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Pull labels: from predictions if included, otherwise from LABELS_HINT.\n",
        "need_labels = 'y' not in {c.lower() for c in pred_df.columns}\n",
        "labels_df = None\n",
        "if need_labels:\n",
        "    if LABELS_HINT is None:\n",
        "        # Try a few common places\n",
        "        for guess in [ROOT/'outputs'/'val_labels.csv', ROOT/'data'/'labels'/'val_labels.csv']:\n",
        "            if guess.exists():\n",
        "                LABELS_HINT = guess; break\n",
        "    if LABELS_HINT and LABELS_HINT.exists():\n",
        "        labels_df = pd.read_csv(LABELS_HINT)\n",
        "        print('labels_df:', labels_df.shape, 'from', LABELS_HINT)\n",
        "    else:\n",
        "        print('WARNING: No labels found; coverage diagnostics will be limited.')\n",
        "\n",
        "# Normalize column names\n",
        "def normcols(df):\n",
        "    return df.rename(columns={c: c.lower() for c in df.columns})\n",
        "\n",
        "pred_df = normcols(pred_df)\n",
        "if labels_df is not None:\n",
        "    labels_df = normcols(labels_df)\n",
        "\n",
        "# Expect long format: planet_id, wavelength_index, mu, sigma, (y optional)\n",
        "required = {'planet_id','wavelength_index','mu'}\n",
        "if not required.issubset(set(pred_df.columns)):\n",
        "    raise ValueError(f'predictions missing required columns {required}; got {list(pred_df.columns)}')\n",
        "has_sigma = 'sigma' in pred_df.columns\n",
        "print('has_sigma:', has_sigma)\n",
        "\n",
        "if labels_df is not None:\n",
        "    keep = {'planet_id','wavelength_index','y'} & set(labels_df.columns)\n",
        "    labels_df = labels_df[list(keep)]\n",
        "    df = pred_df.merge(labels_df, on=['planet_id','wavelength_index'], how='inner')\n",
        "else:\n",
        "    df = pred_df.copy()\n",
        "print('merged df:', df.shape)\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Pre‑calibration diagnostics (baseline)\n",
        "We compute z‑scores `z = (μ−y)/σ` where available, histogram them, and estimate empirical coverage for nominal Gaussian intervals `μ±kσ`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": { "tags": ["pre_diag"] },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def zscores(mu, sigma, y):\n",
        "    s = np.asarray(sigma, float)\n",
        "    s = np.where(s<=0, np.nan, s)\n",
        "    return (np.asarray(mu, float) - np.asarray(y, float)) / s\n",
        "\n",
        "pre = {}\n",
        "if ('y' in df.columns) and has_sigma:\n",
        "    z = zscores(df['mu'], df['sigma'], df['y'])\n",
        "    pre['z_mean'] = float(np.nanmean(z))\n",
        "    pre['z_std']  = float(np.nanstd(z))\n",
        "    # Empirical coverage for 1σ/2σ\n",
        "    pre['cov_1sigma'] = float(np.nanmean(np.abs(z)<=1.0))\n",
        "    pre['cov_2sigma'] = float(np.nanmean(np.abs(z)<=2.0))\n",
        "else:\n",
        "    z = None\n",
        "    print('Sigma and/or y missing; z‑score baseline limited.')\n",
        "\n",
        "# Plot histogram if possible\n",
        "if z is not None:\n",
        "    plt.figure(figsize=(9,3))\n",
        "    sns.histplot(z[~np.isnan(z)], bins=60, kde=True, stat='density', color='tab:blue')\n",
        "    plt.title(f'Pre‑calibration z distribution (mean={pre.get(\"z_mean\",np.nan):.3f}, std={pre.get(\"z_std\",np.nan):.3f})')\n",
        "    plt.xlabel('z'); plt.ylabel('density')\n",
        "    plt.tight_layout(); plt.savefig(NB_OUT/'pre_z_hist.png', dpi=150); plt.close()\n",
        "    print('Saved pre_z_hist.png')\n",
        "\n",
        "# Per‑bin coverage heatmap (optional)\n",
        "bin_cov = None\n",
        "if z is not None:\n",
        "    tmp = df[['wavelength_index']].copy()\n",
        "    tmp['in1'] = np.abs(z)<=1\n",
        "    bin_cov = tmp.groupby('wavelength_index')['in1'].mean().reset_index()\n",
        "    plt.figure(figsize=(10,2.5))\n",
        "    plt.plot(bin_cov['wavelength_index'], bin_cov['in1'], lw=1)\n",
        "    plt.ylim(-0.05,1.05)\n",
        "    plt.title('Pre‑calibration per‑bin 1σ coverage')\n",
        "    plt.xlabel('wavelength index'); plt.ylabel('coverage')\n",
        "    plt.tight_layout(); plt.savefig(NB_OUT/'pre_bin_coverage.png', dpi=150); plt.close()\n",
        "    print('Saved pre_bin_coverage.png')\n",
        "\n",
        "pre"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) (Optional) Run COREL calibrator via CLI\n",
        "If your repository exposes a COREL or conformal calibration command, enable the cell below to generate calibrated artifacts.\n",
        "\n",
        "Common patterns:\n",
        "- `spectramind calibrate-uncertainty corel ...` (example)\n", 
        "- `spectramind corel-calibrate ...`\n",
        "\n",
        "Adjust flags to point at your predictions/labels and target coverage (`1−α`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": { "tags": ["cli_corel"] },
      "execution_count": null,
      "outputs": [],
      "source": [
        "RUN_COREL_CLI = False  # set True to enable\n",
        "if RUN_COREL_CLI:\n",
        "    try:\n",
        "        cmd = [\n",
        "            CLI,\n",
        "            'corel-calibrate',                   # <-- change to your actual subcommand\n",
        "            f'inputs={str(PRED_CSV)}',           # predictions with mu/sigma\n",
        "            f'labels={str(LABELS_HINT)}',        # labels csv (if needed by CLI)\n",
        "            f'alpha={TARGET_ALPHA}',             # desired miscoverage\n",
        "            f'outdir={str(ROOT/\"outputs\"/\"calibration\")}'\n",
        "        ]\n",
        "        print('Running:', ' '.join(map(str,cmd)))\n",
        "        subprocess.run(list(map(str,cmd)), check=True)\n",
        "    except Exception as e:\n",
        "        print('COREL CLI failed (non‑blocking):', e)\n",
        "else:\n",
        "    print('COREL CLI disabled; set RUN_COREL_CLI=True to run it here.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Load calibrated artifacts\n",
        "We look for `sigma_cal` or prediction intervals `lo,hi` in the calibrated file; if missing, we stay with baseline."
      ]
    },
    {
      "cell_type": "code",
      "metadata": { "tags": ["cal_load"] },
      "execution_count": null,
      "outputs": [],
      "source": [
        "cal_df = None\n",
        "if CAL_CSV and CAL_CSV.exists():\n",
        "    cal_df = pd.read_csv(CAL_CSV)\n",
        "    cal_df = cal_df.rename(columns={c: c.lower() for c in cal_df.columns})\n",
        "    print('cal_df:', cal_df.shape, 'from', CAL_CSV)\n",
        "else:\n",
        "    print('No calibrated CSV found; proceeding with baseline only.')\n",
        "\n",
        "# Merge calibrated columns if structure matches\n",
        "merged_df = df.copy()\n",
        "has_sigma_cal = False\n",
        "has_intervals = False\n",
        "if cal_df is not None:\n",
        "    join_keys = [k for k in ['planet_id','wavelength_index'] if k in cal_df.columns and k in merged_df.columns]\n",
        "    if join_keys:\n",
        "        merged_df = merged_df.merge(cal_df, on=join_keys, how='left', suffixes=('','_cal'))\n",
        "        has_sigma_cal = 'sigma_cal' in merged_df.columns\n",
        "        has_intervals = {'lo','hi'}.issubset(set(merged_df.columns))\n",
        "        print('has_sigma_cal:', has_sigma_cal, 'has_intervals:', has_intervals)\n",
        "    else:\n",
        "        print('WARNING: Could not align calibrated file with predictions on keys; skipping merge.')\n",
        "\n",
        "merged_df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Post‑calibration diagnostics\n",
        "We recompute z‑scores using `σ_cal` if provided, and/or coverage using intervals `lo,hi`. We also plot reliability and per‑bin coverage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": { "tags": ["post_diag"] },
      "execution_count": null,
      "outputs": [],
      "source": [
        "post = {}\n",
        "z_cal = None\n",
        "if ('y' in merged_df.columns) and has_sigma_cal:\n",
        "    z_cal = zscores(merged_df['mu'], merged_df['sigma_cal'], merged_df['y'])\n",
        "    post['z_mean'] = float(np.nanmean(z_cal))\n",
        "    post['z_std']  = float(np.nanstd(z_cal))\n",
        "    post['cov_1sigma'] = float(np.nanmean(np.abs(z_cal)<=1.0))\n",
        "    post['cov_2sigma'] = float(np.nanmean(np.abs(z_cal)<=2.0))\n",
        "\n",
        "if z_cal is not None:\n",
        "    plt.figure(figsize=(9,3))\n",
        "    sns.histplot(z_cal[~np.isnan(z_cal)], bins=60, kde=True, stat='density', color='tab:green')\n",
        "    plt.title(f'Post‑calibration z distribution (mean={post.get(\"z_mean\",np.nan):.3f}, std={post.get(\"z_std\",np.nan):.3f})')\n",
        "    plt.xlabel('z_cal'); plt.ylabel('density')\n",
        "    plt.tight_layout(); plt.savefig(NB_OUT/'post_z_hist.png', dpi=150); plt.close()\n",
        "    print('Saved post_z_hist.png')\n",
        "\n",
        "# Interval coverage (if conformal intervals lo,hi available)\n",
        "int_cov = None\n",
        "if ('y' in merged_df.columns) and has_intervals:\n",
        "    inside = (merged_df['y']>=merged_df['lo']) & (merged_df['y']<=merged_df['hi'])\n",
        "    int_cov = float(np.mean(inside))\n",
        "    post['interval_coverage'] = int_cov\n",
        "    plt.figure(figsize=(10,2.5))\n",
        "    # per‑bin interval coverage\n",
        "    perbin = merged_df[['wavelength_index']].copy()\n",
        "    perbin['inside'] = inside\n",
        "    gb = perbin.groupby('wavelength_index')['inside'].mean().reset_index()\n",
        "    plt.plot(gb['wavelength_index'], gb['inside'], lw=1, color='tab:purple')\n",
        "    plt.ylim(-0.05,1.05)\n",
        "    plt.title(f'Per‑bin interval coverage (target ~ {1-TARGET_ALPHA:.0%})')\n",
        "    plt.xlabel('wavelength index'); plt.ylabel('coverage')\n",
        "    plt.tight_layout(); plt.savefig(NB_OUT/'post_bin_interval_coverage.png', dpi=150); plt.close()\n",
        "    print('Saved post_bin_interval_coverage.png')\n",
        "\n",
        "post"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Reliability: empirical vs nominal\n",
        "For Gaussian σ, nominal central mass for `k` is `erf(k/√2)`. For conformal intervals, the nominal is `1−α`. We overlay empirical points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": { "tags": ["reliability"] },
      "execution_count": null,
      "outputs": [],
      "source": [
        "from math import erf, sqrt\n",
        "\n",
        "def nominal_gauss_mass(k):\n",
        "    return erf(k/sqrt(2.0))\n",
        "\n",
        "def empirical_mass_from_z(z, ks=(0.5,1.0,1.5,2.0,2.5)):\n",
        "    out = []\n",
        "    z = np.asarray(z)\n",
        "    for k in ks:\n",
        "        out.append(np.nanmean(np.abs(z)<=k))\n",
        "    return np.array(out), np.array(ks)\n",
        "\n",
        "# Pre (if available)\n",
        "if z is not None:\n",
        "    emp, ks = empirical_mass_from_z(z)\n",
        "    nom = np.array([nominal_gauss_mass(k) for k in ks])\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(nom, emp, 'o-', label='pre (empirical vs nominal)')\n",
        "    plt.plot([0,1],[0,1], 'k--', lw=1)\n",
        "    plt.xlabel('Nominal mass'); plt.ylabel('Empirical mass')\n",
        "    plt.title('Reliability (pre)'); plt.legend(); plt.tight_layout()\n",
        "    plt.savefig(NB_OUT/'reliability_pre.png', dpi=150); plt.close()\n",
        "    print('Saved reliability_pre.png')\n",
        "\n",
        "# Post (if z_cal)\n", 
        "if z_cal is not None:\n",
        "    emp2, ks2 = empirical_mass_from_z(z_cal)\n",
        "    nom2 = np.array([nominal_gauss_mass(k) for k in ks2])\n",
        "    plt.figure(figsize=(6,4))\n",
        "    plt.plot(nom2, emp2, 'o-', color='tab:green', label='post (empirical vs nominal)')\n",
        "    plt.plot([0,1],[0,1], 'k--', lw=1)\n",
        "    plt.xlabel('Nominal mass'); plt.ylabel('Empirical mass')\n",
        "    plt.title('Reliability (post)'); plt.legend(); plt.tight_layout()\n",
        "    plt.savefig(NB_OUT/'reliability_post.png', dpi=150); plt.close()\n",
        "    print('Saved reliability_post.png')\n",
        "\n",
        "# Interval reliability (conformal)\n",
        "if int_cov is not None:\n",
        "    plt.figure(figsize=(4,3))\n",
        "    plt.bar(['empirical','target'], [int_cov, 1-TARGET_ALPHA], color=['tab:purple','tab:gray'])\n",
        "    plt.ylim(0,1)\n",
        "    plt.title('Interval coverage (post)')\n",
        "    plt.tight_layout(); plt.savefig(NB_OUT/'reliability_interval.png', dpi=150); plt.close()\n",
        "    print('Saved reliability_interval.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) Report bundle\n",
        "We store a machine‑readable `calibration_report.json` and detail CSV with per‑bin coverage (if computed)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": { "tags": ["export"] },
      "execution_count": null,
      "outputs": [],
      "source": [
        "report = {\n",
        "    'pred_file': str(PRED_CSV) if PRED_CSV else None,\n",
        "    'cal_file': str(CAL_CSV) if CAL_CSV else None,\n",
        "    'target_alpha': float(TARGET_ALPHA),\n",
        "    'pre': pre,\n",
        "    'post': post,\n",
        "}\n",
        "(NB_OUT/'calibration_report.json').write_text(json.dumps(report, indent=2))\n",
        "print('Wrote calibration_report.json')\n",
        "\n",
        "if bin_cov is not None:\n",
        "    bin_cov.to_csv(NB_OUT/'pre_bin_coverage.csv', index=False)\n",
        "    print('Wrote pre_bin_coverage.csv')\n",
        "\n",
        "# Optionally, per‑bin post coverage if z_cal is present\n",
        "if (z_cal is not None) and ('wavelength_index' in merged_df.columns):\n",
        "    tmp2 = merged_df[['wavelength_index']].copy()\n",
        "    tmp2['in1'] = np.abs(z_cal)<=1\n",
        "    post_bin = tmp2.groupby('wavelength_index')['in1'].mean().reset_index()\n",
        "    post_bin.to_csv(NB_OUT/'post_bin_coverage.csv', index=False)\n",
        "    print('Wrote post_bin_coverage.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) (Optional) DVC add\n",
        "Register outputs for full reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "metadata": { "tags": ["dvc"] },
      "execution_count": null,
      "outputs": [],
      "source": [
        "if shutil.which('dvc'):\n",
        "    try:\n",
        "        subprocess.run(['dvc','add', str(NB_OUT)], check=False)\n",
        "        subprocess.run(['git','add', f'{NB_OUT}.dvc', '.gitignore'], check=False)\n",
        "        subprocess.run(['dvc','status'], check=False)\n",
        "        print('DVC add done (non‑blocking).')\n",
        "    except Exception as e:\n",
        "        print('DVC step failed (non‑blocking):', e)\n",
        "else:\n",
        "    print('DVC not found; skipping.')"
      ]
    }
  ]
}