{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§ª SpectraMind V50 â€” 01_pipeline_calibrate_train_predict\n",
    "\n",
    "Tiny **calibrate â†’ train â†’ predict** pipeline to sanity-check the stack with fast settings.\n",
    "\n",
    "This runs entirely via the **CLI** (Typer + Hydra), keeping the workflow reproducible and config-driven."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Runtime Helper â€” Resolve `spectramind`\n",
    "\n",
    "Resolves in order:\n",
    "1. `spectramind` (PATH)\n",
    "2. `poetry run spectramind`\n",
    "3. `python -m spectramind`\n",
    "\n",
    "Exposes helpers: `sm(cmd)`, `sm_print(cmd)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shlex, shutil, subprocess, sys, glob, json, textwrap\n",
    "from pathlib import Path\n",
    "\n",
    "def _resolve_spectramind_cmd():\n",
    "    if shutil.which(\"spectramind\"):\n",
    "        return [\"spectramind\"]\n",
    "    if shutil.which(\"poetry\"):\n",
    "        try:\n",
    "            out = subprocess.run([\"poetry\", \"run\", \"spectramind\", \"--version\"],\n",
    "                                 stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
    "            if out.returncode == 0:\n",
    "                return [\"poetry\", \"run\", \"spectramind\"]\n",
    "        except Exception:\n",
    "            pass\n",
    "    return [sys.executable, \"-m\", \"spectramind\"]\n",
    "\n",
    "SM = _resolve_spectramind_cmd()\n",
    "print(\"Resolved spectramind launcher:\", \" \".join(shlex.quote(p) for p in SM))\n",
    "\n",
    "def sm(cmd: str, check=False, capture=False):\n",
    "    args = shlex.split(cmd)\n",
    "    res = subprocess.run(SM + args,\n",
    "                         check=check,\n",
    "                         stdout=subprocess.PIPE if capture else None,\n",
    "                         stderr=subprocess.STDOUT if capture else None,\n",
    "                         text=True)\n",
    "    return res\n",
    "\n",
    "def sm_print(cmd: str):\n",
    "    print(\"$\", \" \".join(SM + shlex.split(cmd)))\n",
    "\n",
    "Path(\"outputs\").mkdir(exist_ok=True, parents=True)\n",
    "Path(\"outputs/preds_quick\").mkdir(exist_ok=True, parents=True)\n",
    "Path(\"outputs/diagnostics_quick\").mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Sanity Checks\n",
    "Python/Poetry/Git/DVC and optional CUDA snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python --version\n",
    "!pip --version\n",
    "!poetry --version || echo 'âš ï¸ Poetry not found (ok if not using Poetry)'\n",
    "!git --version\n",
    "!dvc --version || echo 'âš ï¸ DVC not found (ok for quick run)'\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    print(\"PyTorch:\", torch.__version__)\n",
    "    print(\"CUDA available:\", torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print(\"CUDA device:\", torch.cuda.get_device_name(0))\n",
    "except Exception:\n",
    "    print(\"PyTorch not installed â€” continuing\")\n",
    "\n",
    "sm_print(\"--version\")\n",
    "out = sm(\"--version\", capture=True)\n",
    "print(out.stdout if out.stdout else \"(no output)\")\n",
    "\n",
    "sm_print(\"--help\")\n",
    "out = sm(\"--help\", capture=True)\n",
    "print(\"\\n\".join(out.stdout.splitlines()[:20]) if out.stdout else \"(no output)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) (Optional) DVC Pull\n",
    "If your repo uses DVC for data/artifacts, pull latest (non-fatal if absent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "set -euo pipefail\n",
    "if command -v dvc >/dev/null 2>&1; then\n",
    "  echo \"DVC detected â€” pulling data (if remote configured)...\"\n",
    "  dvc pull || echo 'âš ï¸ dvc pull non-fatal'\n",
    "else\n",
    "  echo \"DVC not installed â€” skipping\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Calibrate (fast, sampled)\n",
    "Run calibration on a small sample for speed. Adjust `--sample` as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm_print(\"calibrate --sample 5 --fast\")\n",
    "cal = sm(\"calibrate --sample 5 --fast\", capture=True)\n",
    "print(cal.stdout or \"(no output)\")\n",
    "\n",
    "# List key outputs if your pipeline writes calibrated artifacts\n",
    "!ls -lah outputs || true\n",
    "!ls -lah outputs/* || true 2>/dev/null || true\n",
    "!find outputs -maxdepth 2 -type f | head -n 20 || true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Train (tiny)\n",
    "One quick epoch / fast-dev-run for smoke validation. Override Hydra config inline if desired."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cmd = \"train --epochs 1 training.fast_dev_run=true\"\n",
    "sm_print(train_cmd)\n",
    "tr = sm(train_cmd, capture=True)\n",
    "print(tr.stdout or \"(no output)\")\n",
    "\n",
    "# Peek at any saved checkpoints/metrics\n",
    "!find outputs -maxdepth 3 -type f \\( -name \"*.pt\" -o -name \"*.ckpt\" -o -name \"metrics*.json\" -o -name \"*log*.json\" \\) | head -n 20 || true\n",
    "!tail -n 50 logs/v50_debug_log.md 2>/dev/null || true\n",
    "!tail -n 50 outputs/metrics.json 2>/dev/null || true\n",
    "!tail -n 50 outputs/train/metrics.json 2>/dev/null || true\n",
    "!find outputs -maxdepth 3 -type f -name \"*.json\" | head -n 10 || true\n",
    "!find outputs -maxdepth 3 -type f -name \"*.yaml\" | head -n 10 || true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Predict\n",
    "Generate quick predictions (location may vary by your CLI). This writes predictions to `outputs/preds_quick/`.\n",
    "\n",
    "- If your CLI exposes `predict`, use that.\n",
    "- If predictions are created by `submit --dry-run`, run that and parse the produced CSV/ZIP accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_dir = Path(\"outputs/preds_quick\")\n",
    "\n",
    "# Try `predict` first\n",
    "predict_cmds = [\n",
    "    \"predict --outdir outputs/preds_quick --fast\",\n",
    "    # Fallback: some repos produce predictions as part of submit dry-run\n",
    "    \"submit --dry-run\"\n",
    "]\n",
    "\n",
    "ok = False\n",
    "for cmd in predict_cmds:\n",
    "    sm_print(cmd)\n",
    "    out = sm(cmd, capture=True)\n",
    "    print(out.stdout or \"(no output)\")\n",
    "    # Heuristic: check if something landed in preds_quick or a submission file exists\n",
    "    csvs = list(pred_dir.glob(\"**/*.csv\"))\n",
    "    subs = list(Path(\".\").glob(\"**/submission*.csv\"))\n",
    "    if csvs or subs:\n",
    "        ok = True\n",
    "        break\n",
    "\n",
    "if not ok:\n",
    "    print(\"âš ï¸ Could not detect predictions in expected locations. Inspect CLI outputs above.\")\n",
    "\n",
    "print(\"\\nDiscovered prediction files:\")\n",
    "for p in pred_dir.glob(\"**/*.csv\"):\n",
    "    print(\"-\", p)\n",
    "for p in Path(\".\").glob(\"**/submission*.csv\"):\n",
    "    print(\"-\", p)\n",
    "\n",
    "!ls -lah outputs/preds_quick 2>/dev/null || true\n",
    "!find outputs -maxdepth 2 -type f -name \"*.csv\" | head -n 20 || true\n",
    "!find . -maxdepth 3 -type f -name \"submission*.csv\" | head -n 10 || true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Inspect Predictions (preview & quick plot)\n",
    "This section attempts to open a CSV of predictions and visualize a spectrum for a quick sanity check (optional)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def _find_pred_csv():\n",
    "    # prefer explicit preds directory, else any submission*.csv\n",
    "    cands = list(Path(\"outputs/preds_quick\").glob(\"**/*.csv\"))\n",
    "    if cands:\n",
    "        return cands[0]\n",
    "    cands = list(Path(\".\").glob(\"**/submission*.csv\"))\n",
    "    return cands[0] if cands else None\n",
    "\n",
    "csv_path = _find_pred_csv()\n",
    "if csv_path and csv_path.is_file():\n",
    "    print(\"Preview:\", csv_path)\n",
    "    df = pd.read_csv(csv_path)\n",
    "    display(df.head(10))\n",
    "    # Try naive plot: look for columns that look like wavelength bins\n",
    "    num_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "    # If a single row contains a full spectrum across columns, plot the first row\n",
    "    if len(num_cols) > 10:\n",
    "        y = df[num_cols].iloc[0].values\n",
    "        x = list(range(len(y)))\n",
    "        plt.figure(figsize=(8,3))\n",
    "        plt.plot(x, y, lw=1)\n",
    "        plt.title(f\"Quick Spectrum Preview â€” {csv_path.name}\")\n",
    "        plt.xlabel(\"Bin index\")\n",
    "        plt.ylabel(\"Predicted Î¼\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"(Skipping plot â€” could not infer wide spectrum columns)\")\n",
    "else:\n",
    "    print(\"No prediction CSV found to preview.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) (Optional) Diagnostics Snapshot\n",
    "Run a minimal dashboard build to confirm plots render (UMAP/t-SNE disabled for speed). Outputs in `outputs/diagnostics_quick/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_cmd = \"diagnose dashboard --no-umap --no-tsne --outdir outputs/diagnostics_quick\"\n",
    "sm_print(diag_cmd)\n",
    "dg = sm(diag_cmd, capture=True)\n",
    "print(dg.stdout or \"(no output)\")\n",
    "\n",
    "!find outputs/diagnostics_quick -maxdepth 2 -type f | head -n 20 || true\n",
    "!ls -lah outputs/diagnostics_quick 2>/dev/null || true\n",
    "!find outputs -maxdepth 3 -type f -name \"*report*.html\" | head -n 10 || true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Summary & Next Steps\n",
    "- You now have calibrated data, a quick-trained model, and a prediction artifact.\n",
    "- For real experiments, increase `--sample`, remove `--fast_dev_run`, and raise `--epochs`.\n",
    "- Consider running `submit` without `--dry-run` to package a full submission when ready.\n",
    "- Explore diagnostics HTML under `outputs/diagnostics_quick/`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
