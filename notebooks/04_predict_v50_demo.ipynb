{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 04 — Predict V50 Demo\n",
        "\n",
        "This notebook demonstrates **inference/prediction** with the SpectraMind V50 pipeline using the **CLI + Hydra configs** only (no ad‑hoc modeling code), saving artifacts under `outputs/` for DVC tracking and later diagnostics.\n",
        "\n",
        "**Goals**\n",
        "1) Run a dry‑run and a small real prediction with the unified CLI\n",
        "2) Persist all outputs to versioned folders under `outputs/`\n",
        "3) Preview predicted spectra (\\mu and \\sigma)\n",
        "4) (Optional) Register artifacts with DVC for reproducibility\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Reproducibility contract**  \n",
        "- Single, unified CLI entrypoint (`spectramind ...`) with subcommands; all parameters come from **Hydra** configs or CLI overrides.  \n",
        "- All logs/configs and artifacts written under `outputs/` and tracked (e.g., via **DVC**) to tie code+config+data to results.  \n",
        "- Notebook cells only **invoke the CLI/configs** (no custom training/inference logic).  \n",
        "\n",
        "_If you run this on Kaggle, see the final cell for notes about GPUs/paths and saving artifacts._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Environment bootstrap\n",
        "Configure paths and check that the CLI is reachable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "import os, sys, shutil, subprocess, json, time\n",
        "from pathlib import Path\n",
        "\n",
        "# Project root (adjust if needed)\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "os.chdir(PROJECT_ROOT)\n",
        "\n",
        "# Prefer a venv if your repo uses one\n",
        "print(f\"PROJECT_ROOT = {PROJECT_ROOT}\")\n",
        "\n",
        "# Try to find the CLI. If not on PATH, fall back to a module form.\n",
        "CLI = shutil.which(\"spectramind\")\n",
        "if CLI is None:\n",
        "    # Generic fallback: try `python -m spectramind` or repo's entrypoint\n",
        "    if (PROJECT_ROOT / \"spectramind.py\").exists():\n",
        "        CLI = f\"{sys.executable} {PROJECT_ROOT / 'spectramind.py'}\"\n":,
        "    else:\n",
        "        CLI = f\"{sys.executable} -m spectramind\"\n",
        "print(\"CLI command:\", CLI)\n",
        "\n",
        "def sh(cmd, check=True, env=None):\n",
        "    print(\"\\n$\", cmd)\n",
        "    result = subprocess.run(cmd, shell=True, env=env)\n",
        "    if check and result.returncode != 0:\n",
        "        raise RuntimeError(f\"Command failed with code {result.returncode}\")\n",
        "    return result\n",
        "\n",
        "# Create a top-level outputs dir if missing\n",
        "Path(\"outputs\").mkdir(exist_ok=True)\n",
        "\n",
        "# Optional: make CLI visibly available in PATH for child processes\n",
        "os.environ.setdefault(\"PYTHONUTF8\", \"1\")\n",
        "print(\"Python:\", sys.version)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Version stamps (good hygiene)\n",
        "Capture git commit and CLI version (if the repo provides them)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "try:\n",
        "    sh(\"git rev-parse --short HEAD || true\", check=False)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# If CLI implements a --version or version subcommand, try it\n",
        "sh(f\"{CLI} --version || true\", check=False)\n",
        "\n",
        "# Hydra often prints composed config on run; we also keep a run-level copy below."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Define run parameters\n",
        "We keep everything explicit and override via Hydra in the CLI call."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from datetime import datetime\n",
        "\n",
        "RUN_TS = datetime.utcnow().strftime(\"%Y%m%d_%H%M%S\")\n",
        "RUN_NAME = f\"predict_v50_demo_{RUN_TS}\"\n",
        "\n",
        "# Example Hydra groups/overrides (adjust to your repository's config tree)\n",
        "DATA_CFG   = \"data/nominal.yaml\"           # e.g., configs/data/nominal.yaml\n",
        "MODEL_CFG  = \"model/v50.yaml\"              # e.g., configs/model/v50.yaml\n",
        "PRED_CFG   = \"predict/default.yaml\"        # e.g., configs/predict/default.yaml\n",
        "\n",
        "# Output folder for this run\n",
        "OUT_DIR = Path(\"outputs\") / RUN_NAME\n",
        "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Optional small-sample flags (depends on your CLI implementation)\n",
        "SAMPLE_KW = \"--sample 3\"          # or: --limit_planets 3\n",
        "FASTDEV   = \"--fast_dev_run true\"  # if supported\n",
        "\n",
        "print(\"RUN_NAME:\", RUN_NAME)\n",
        "print(\"OUT_DIR:\", OUT_DIR)\n",
        "print(\"Configs:\", DATA_CFG, MODEL_CFG, PRED_CFG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) CLI help and dry run\n",
        "Always check `--help` and do a quick dry run for wiring."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# See predict command usage\n",
        "sh(f\"{CLI} predict --help || true\", check=False)\n",
        "\n",
        "# Dry run: compose config and exit (if your CLI supports a dry-run flag)\n",
        "sh(\n",
        "    \" \".join([\n",
        "        f\"{CLI} predict\",\n",
        "        f\"data={DATA_CFG}\",\n",
        "        f\"model={MODEL_CFG}\",\n",
        "        f\"predict={PRED_CFG}\",\n",
        "        f\"outputs.dir={OUT_DIR}\",\n",
        "        f\"hydra.job.name={RUN_NAME}\",\n",
        "        \"dry_run=true || true\"  # tolerated if the flag doesn't exist\n",
        "    ]),\n",
        "    check=False\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Run a small real prediction\n",
        "We’ll execute a tiny slice (e.g., 3 targets) and write artifacts under `outputs/<RUN_NAME>/`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "cmd = \" \".join([\n",
        "    f\"{CLI} predict\",\n",
        "    f\"data={DATA_CFG}\",\n",
        "    f\"model={MODEL_CFG}\",\n",
        "    f\"predict={PRED_CFG}\",\n",
        "    f\"outputs.dir={OUT_DIR}\",\n",
        "    f\"hydra.job.name={RUN_NAME}\",\n",
        "    SAMPLE_KW,\n",
        "    FASTDEV\n",
        "])\n",
        "sh(cmd)\n",
        "\n",
        "print(\"\\nArtifacts written to:\", OUT_DIR)\n",
        "print(\"Directory tree:\")\n",
        "sh(f\"ls -lah {OUT_DIR} || true\", check=False)\n",
        "\n",
        "# Common artifact names used by the pipeline (adjust to match your code):\n",
        "PRED_CSV = OUT_DIR / \"predictions.csv\"          # e.g., concatenated predictions\n",
        "PRED_JSON = OUT_DIR / \"predictions.json\"        # optional richer output\n",
        "CFG_DUMP = OUT_DIR / \"config.yaml\"              # hydra-composed config snapshot (if your CLI saves it)\n",
        "for p in [PRED_CSV, PRED_JSON, CFG_DUMP]:\n",
        "    print(f\"exists({p.name}) ->\", p.exists())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Quick visualization of predicted spectra\n",
        "We expect means (\\mu) and uncertainties (\\sigma). Adjust column names to your pipeline’s output schema."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.rcParams.update({\"figure.figsize\": (8, 4)})\n",
        "\n",
        "if PRED_CSV.exists():\n",
        "    df = pd.read_csv(PRED_CSV)\n",
        "    print(df.head(2))\n",
        "    # Heuristic: columns like mu_000..mu_282 and sigma_000..sigma_282 or similar\n",
        "    mu_cols = [c for c in df.columns if c.startswith(\"mu_\")]\n",
        "    sg_cols = [c for c in df.columns if c.startswith(\"sigma_\") or c.startswith(\"sd_\") or c.startswith(\"std_\")]\n",
        "    wave = np.arange(len(mu_cols))\n",
        "\n",
        "    nplot = min(3, len(df))\n",
        "    for i in range(nplot):\n",
        "        mu = df.loc[i, mu_cols].to_numpy(dtype=float)\n",
        "        if sg_cols:\n",
        "            sg = df.loc[i, sg_cols].to_numpy(dtype=float)\n",
        "        else:\n",
        "            sg = np.full_like(mu, np.nan)\n",
        "\n",
        "        plt.figure()\n",
        "        plt.title(f\"Predicted spectrum #{i}\")\n",
        "        plt.plot(wave, mu, label=\"mu\")\n",
        "        if np.isfinite(sg).all():\n",
        "            plt.fill_between(wave, mu - sg, mu + sg, alpha=0.2, label=\"± sigma\")\n",
        "        plt.xlabel(\"Wavelength channel index\")\n",
        "        plt.ylabel(\"Transit depth (arb. units)\")\n",
        "        plt.legend()\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        fig_path = OUT_DIR / f\"preview_spectrum_{i:02d}.png\"\n",
        "        plt.savefig(fig_path, dpi=150)\n",
        "        print(\"Saved:\", fig_path)\n",
        "        plt.show()\n",
        "else:\n",
        "    print(\"No predictions.csv found; skip plotting.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6) (Optional) DVC register artifacts\n",
        "If your repository uses DVC, the following will add the run artifacts and show status."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": []
      },
      "source": [
        "if shutil.which(\"dvc\"):\n",
        "    sh(f\"dvc add {OUT_DIR} || true\", check=False)\n",
        "    sh(f\"git add {OUT_DIR}.dvc .gitignore || true\", check=False)\n",
        "    sh(\"dvc status || true\", check=False)\n",
        "else:\n",
        "    print(\"DVC not found on PATH; skipping.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7) Notes for Kaggle users\n",
        "- Switch **Accelerator** to GPU in Notebook Settings if your CLI uses CUDA for speed.  \n",
        "- Ensure the competition or dataset is attached under the **Data** tab so `data=...` config can find inputs.  \n",
        "- To persist `outputs/` across sessions, enable **Save state** (persistent storage) or export artifacts as a Kaggle Dataset.  \n",
        "- If internet is OFF (common in comps), avoid `pip install` in cells; rely on the project’s Docker/lockfiles.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": ""
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 5
}