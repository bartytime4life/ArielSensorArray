{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10"
    },
    "title": "14_radiation_and_noise_modeling.ipynb",
    "authors": [
      "SpectraMind V50 Team"
    ],
    "spectramind": {
      "role": "education/diagnostics",
      "cli_first": true,
      "outputs_dir": "outputs/notebooks/14_radiation_noise_modeling",
      "reproducibility": {
        "hydra": true,
        "dvc": true,
        "logs": true
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 14 · Radiation & Noise Modeling (SpectraMind V50)\n",
        "\n",
        "Educational, **mission‑grade** notebook to illustrate how radiation environments and detector/system noise influence transit spectra and downstream diagnostics. This notebook is **pipeline‑safe**: it *reads* existing artifacts (calibrated spectra or predictions) and writes educational diagnostics under `outputs/notebooks/14_radiation_noise_modeling/`.\n",
        "\n",
        "### Objectives\n",
        "1. Summarize noise sources relevant to spaceborne spectroscopy (shot noise, read noise, dark current, cosmic rays / radiation hits, background).\n",
        "2. Load one or more spectra from `outputs/` and inject controllable noise models (Poisson, Gaussian, 1/f) and **cosmic‑ray transients**.\n",
        "3. Visualize impact on FFT/autocorr structure, per‑bin variance, and symbolic bands.\n",
        "4. Export a compact diagnostics bundle (JSON + CSV + PNGs) for teaching and QA.\n",
        "\n",
        "> Contract: **Thin orchestration** over CLI/outputs; no ad‑hoc calibration or model training here. For production calibration and prediction, use the dedicated notebooks and CLI."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "init"
        ]
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "import os, sys, json, shutil, subprocess, platform, textwrap\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "try:\n",
        "    import seaborn as sns\n",
        "    sns.set_context('notebook'); sns.set_style('whitegrid')\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "ROOT = Path.cwd().resolve()\n",
        "NB_OUT = ROOT / 'outputs' / 'notebooks' / '14_radiation_noise_modeling'\n",
        "NB_OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "ENV = {\n",
        "    'python': platform.python_version(),\n",
        "    'platform': platform.platform(),\n",
        "    'time': datetime.utcnow().isoformat()+'Z',\n",
        "}\n",
        "(NB_OUT/'env_snapshot.json').write_text(json.dumps(ENV, indent=2))\n",
        "print('ROOT:', ROOT) ; print('NB_OUT:', NB_OUT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 0) Background: radiation & detector/system noise (recap)\n",
        "**Noise categories (simplified):**\n",
        "- **Shot noise (photon counting)**: Poisson with variance $\\sigma^2 \\approx N$ photons. Dominant at high flux, fundamental.\n",
        "- **Read noise**: electronics/ADC noise per read; Gaussian with fixed variance per exposure/read.\n",
        "- **Dark current**: thermally generated electrons; behaves like additional Poisson process with rate depending on temperature.\n",
        "- **Background (zodiacal/thermal)**: adds counts and variance; often Poisson‑like per pixel/extraction window.\n",
        "- **1/f (pink) noise)**: low‑frequency drift; can imprint long‑scale structure in spectra/time series.\n",
        "- **Cosmic rays / radiation hits**: transient, often impulsive events (spikes/glitches) that must be detected/flagged.\n",
        "\n",
        "We’ll illustrate how each affects a clean spectrum (or an existing prediction) by perturbing it with controlled levels and visualizing FFT/autocorr & per‑bin variance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1) Load a base spectrum from outputs/\n",
        "We try `outputs/` for a predictions CSV or NPY and reduce to a single `(wavelength_index, mu)` spectrum for demonstration.\n",
        "\n",
        "If none are found, we synthesize a plausible spectrum with two absorption features for educational use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "io"
        ]
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def find_candidates():\n",
        "    roots = [ROOT/'outputs']\n",
        "    pats = ['**/predictions.csv','**/mu.csv','**/spectra.npy','**/mu.npy']\n",
        "    cands = []\n",
        "    for r in roots:\n",
        "        if not r.exists():\n",
        "            continue\n",
        "        for pat in pats:\n",
        "            cands += list(r.glob(pat))\n",
        "    return sorted(set(cands), key=lambda p: p.stat().st_mtime) if cands else []\n",
        "\n",
        "def load_one_spectrum(path: Path) -> pd.DataFrame:\n",
        "    if path.suffix=='.npy':\n",
        "        arr = np.load(path)\n",
        "        if arr.ndim==1: arr = arr[None,:]\n",
        "        mu = arr[0]\n",
        "        return pd.DataFrame({'wavelength_index': np.arange(len(mu)), 'mu': mu})\n",
        "    df = pd.read_csv(path)\n",
        "    cols = {str(c).lower(): c for c in df.columns}\n",
        "    if {'planet_id','wavelength_index','mu'}.issubset(cols):\n",
        "        one = df[df[cols['planet_id']]==df[cols['planet_id']].iloc[0]].copy()\n",
        "        one = one.rename(columns={cols['wavelength_index']:'wavelength_index', cols['mu']:'mu'})\n",
        "        return one[['wavelength_index','mu']].sort_values('wavelength_index').reset_index(drop=True)\n",
        "    mu_cols = [c for c in df.columns if str(c).startswith('mu_')]\n",
        "    if mu_cols:\n",
        "        mu = df[mu_cols].iloc[0].to_numpy(float)\n",
        "        return pd.DataFrame({'wavelength_index': np.arange(len(mu)), 'mu': mu})\n",
        "    raise ValueError(f'Unsupported schema for {path}')\n",
        "\n",
        "CANDS = find_candidates()\n",
        "if not CANDS:\n",
        "    # synthesize a smooth demo spectrum\n",
        "    x = np.linspace(0, 1, 283)\n",
        "    mu = 0.01 + 0.002*np.exp(-0.5*((x-0.35)/0.08)**2) + 0.0015*np.exp(-0.5*((x-0.75)/0.05)**2)\n",
        "    base = pd.DataFrame({'wavelength_index': np.arange(283), 'mu': mu})\n",
        "    base_source = 'synthetic'\n",
        "    print('No outputs found; using synthetic spectrum.')\n",
        "else:\n",
        "    base = load_one_spectrum(CANDS[-1])\n",
        "    base_source = CANDS[-1].relative_to(ROOT).as_posix()\n",
        "    print('Loaded from:', base_source)\n",
        "\n",
        "base.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "viz_base"
        ]
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,3))\n",
        "plt.plot(base['wavelength_index'], base['mu'], lw=1.5)\n",
        "plt.title('Base spectrum (μ)')\n",
        "plt.xlabel('wavelength index'); plt.ylabel('μ (arb)')\n",
        "plt.tight_layout(); plt.savefig(NB_OUT/'base_spectrum.png', dpi=150); plt.close()\n",
        "print('Saved base_spectrum.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2) Noise models\n",
        "We implement simple, composable perturbations:\n",
        "- **Poisson shot noise**: `y ~ Poisson(λ=S·μ) / S` with scaling `S` to get counts domain.\n",
        "- **Gaussian read noise**: `N(0, σ_read)`.\n",
        "- **1/f noise**: generated via colored‑noise frequency shaping.\n",
        "- **Cosmic ray hits**: sparse spikes at random indices; optionally spread with small kernels.\n",
        "\n",
        "All random draws are controlled by a fixed seed for reproducibility. Adjust parameters as needed for teaching."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "noise"
        ]
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "rng = np.random.default_rng(1234)\n",
        "\n",
        "def add_shot_noise(mu, scale_counts=5e5):\n",
        "    lam = np.clip(scale_counts*np.maximum(mu, 0), 0, None)\n",
        "    y_counts = rng.poisson(lam)\n",
        "    return y_counts/scale_counts\n",
        "\n",
        "def add_read_noise(mu, sigma_read=2e-4):\n",
        "    return mu + rng.normal(0.0, sigma_read, size=mu.shape)\n",
        "\n",
        "def add_1f_noise(mu, alpha=1.0, amp=2e-4):\n",
        "    n = len(mu)\n",
        "    white = rng.normal(0,1,n)\n",
        "    f = np.fft.rfftfreq(n)\n",
        "    spec = np.fft.rfft(white)\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        shaping = 1.0/np.maximum(f, 1e-6)**alpha\n",
        "    shaped = spec*shaping\n",
        "    x = np.fft.irfft(shaped, n)\n",
        "    x = amp*x/np.std(x)\n",
        "    return mu + x\n",
        "\n",
        "def add_cosmic_rays(mu, n_hits=3, spike_amp=0.01, kernel=[1.0, 0.5]):\n",
        "    y = mu.copy()\n",
        "    W = len(mu)\n",
        "    if n_hits <= 0:\n",
        "        return y, np.array([], dtype=int)\n",
        "    hits = rng.choice(W, size=min(n_hits,W), replace=False)\n",
        "    for h in hits:\n",
        "        for k,a in enumerate(kernel):\n",
        "            idx = h+k\n",
        "            if idx < W:\n",
        "                y[idx] += a*spike_amp\n",
        "    return y, hits\n",
        "\n",
        "mu = base['mu'].to_numpy(float)\n",
        "noisy_shot   = add_shot_noise(mu, scale_counts=3e5)\n",
        "noisy_read   = add_read_noise(mu, sigma_read=2e-4)\n",
        "noisy_1f     = add_1f_noise(mu, alpha=1.0, amp=2e-4)\n",
        "noisy_cr, H  = add_cosmic_rays(mu, n_hits=4, spike_amp=0.01)\n",
        "H"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "viz_noise"
        ]
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "x = base['wavelength_index']\n",
        "fig, ax = plt.subplots(2,2, figsize=(12,6), sharex=True)\n",
        "ax = ax.ravel()\n",
        "ax[0].plot(x, mu, lw=1.2, label='base')\n",
        "ax[0].plot(x, noisy_shot, lw=0.8, label='shot')\n",
        "ax[0].set_title('Shot noise') ; ax[0].legend()\n",
        "\n",
        "ax[1].plot(x, mu, lw=1.2, label='base')\n",
        "ax[1].plot(x, noisy_read, lw=0.8, label='read')\n",
        "ax[1].set_title('Read noise') ; ax[1].legend()\n",
        "\n",
        "ax[2].plot(x, mu, lw=1.2, label='base')\n",
        "ax[2].plot(x, noisy_1f, lw=0.8, label='1/f')\n",
        "ax[2].set_title('1/f noise') ; ax[2].legend()\n",
        "\n",
        "ax[3].plot(x, mu, lw=1.2, label='base')\n",
        "ax[3].plot(x, noisy_cr, lw=0.8, label='cosmic rays')\n",
        "if H.size:\n",
        "    ax[3].scatter(x.iloc[H], noisy_cr[H], s=20, zorder=3)\n",
        "ax[3].set_title('Radiation hits (spikes)') ; ax[3].legend()\n",
        "\n",
        "for a in ax: a.set_ylabel('μ (arb)')\n",
        "ax[2].set_xlabel('wavelength index'); ax[3].set_xlabel('wavelength index')\n",
        "fig.tight_layout(); fig.savefig(NB_OUT/'noise_panels.png', dpi=150); plt.close(fig)\n",
        "print('Saved noise_panels.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3) FFT & autocorrelation impact\n",
        "We reuse the simple FFT/AC routines used elsewhere to illustrate how each noise class alters spectral frequency content and lag structure."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "fft_ac"
        ]
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def fft_power_onesided(y):\n",
        "    y = np.asarray(y, float)\n",
        "    y = y - np.nanmean(y)\n",
        "    fy = np.fft.rfft(y)\n",
        "    power = np.abs(fy)**2\n",
        "    freqs = np.fft.rfftfreq(len(y))\n",
        "    return freqs, power\n",
        "\n",
        "def autocorr_norm(y):\n",
        "    y = np.asarray(y, float)\n",
        "    y = y - np.nanmean(y)\n",
        "    r = np.correlate(y, y, mode='full')\n",
        "    r = r[r.size//2:]\n",
        "    if r[0] != 0:\n",
        "        r = r / r[0]\n",
        "    lags = np.arange(r.size)\n",
        "    return lags, r\n",
        "\n",
        "series = {\n",
        "    'base': mu,\n",
        "    'shot': noisy_shot,\n",
        "    'read': noisy_read,\n",
        "    '1f':   noisy_1f,\n",
        "    'cr':   noisy_cr\n",
        "}\n",
        "\n",
        "fig, ax = plt.subplots(2,2, figsize=(12,6))\n",
        "ax = ax.ravel()\n",
        "for i,(name, y) in enumerate(series.items()):\n",
        "    f,p = fft_power_onesided(y)\n",
        "    ax[i//2].semilogy(f[1:], p[1:], lw=1, label=name)\n",
        "ax[0].set_title('FFT power (A)') ; ax[1].set_title('FFT power (B)')\n",
        "ax[0].legend(); ax[1].legend()\n",
        "for a in ax[:2]: a.set_xlabel('freq'); a.set_ylabel('power')\n",
        "\n",
        "for i,(name, y) in enumerate(series.items()):\n",
        "    l,r = autocorr_norm(y)\n",
        "    ax[2 + (i%2)].plot(l, r, lw=1, label=name)\n",
        "ax[2].set_title('Autocorr (A)') ; ax[3].set_title('Autocorr (B)')\n",
        "ax[2].legend(); ax[3].legend()\n",
        "for a in ax[2:]: a.set_xlabel('lag'); a.set_ylabel('norm acorr')\n",
        "fig.tight_layout(); fig.savefig(NB_OUT/'fft_autocorr_noise_compare.png', dpi=150); plt.close(fig)\n",
        "print('Saved fft_autocorr_noise_compare.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4) Per‑bin variance & symbolic band overlays\n",
        "We compute per‑bin variance across a small ensemble of perturbed spectra and (optionally) overlay symbolic bands (e.g., water) to show if noise masks lines of interest."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "variance"
        ]
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "def ensemble_variance(mu, K=64, cfg=None):\n",
        "    cfg = cfg or {}\n",
        "    ens = []\n",
        "    for k in range(K):\n",
        "        y = mu.copy()\n",
        "        if cfg.get('shot'):   y = add_shot_noise(y, scale_counts=cfg.get('shot_scale',3e5))\n",
        "        if cfg.get('read'):   y = add_read_noise(y, sigma_read=cfg.get('read_sigma',2e-4))\n",
        "        if cfg.get('one_over_f'): y = add_1f_noise(y, alpha=cfg.get('alpha',1.0), amp=cfg.get('amp',2e-4))\n",
        "        if cfg.get('cosmic_hits'):\n",
        "            y,_ = add_cosmic_rays(y, n_hits=cfg.get('cr_n',3), spike_amp=cfg.get('cr_amp',0.01))\n",
        "        ens.append(y)\n",
        "    ens = np.stack(ens, axis=0)\n",
        "    return ens.var(axis=0)\n",
        "\n",
        "cfg = {'shot':True, 'read':True, 'one_over_f':True, 'cosmic_hits':True}\n",
        "var_bins = ensemble_variance(mu, K=64, cfg=cfg)\n",
        "plt.figure(figsize=(10,3))\n",
        "plt.plot(base['wavelength_index'], var_bins, lw=1)\n",
        "plt.title('Per‑bin variance under composite noise model')\n",
        "plt.xlabel('wavelength index'); plt.ylabel('variance')\n",
        "plt.tight_layout(); plt.savefig(NB_OUT/'perbin_variance.png', dpi=150); plt.close()\n",
        "print('Saved perbin_variance.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5) Bundle export\n",
        "We export a compact JSON + CSV for dashboards and lessons learned."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [
          "export"
        ]
      },
      "execution_count": null,
      "outputs": [],
      "source": [
        "bundle = {\n",
        "  'source': base_source,\n",
        "  'noise_panels': 'noise_panels.png',\n",
        "  'fft_autocorr_compare': 'fft_autocorr_noise_compare.png',\n",
        "  'perbin_variance': 'perbin_variance.png',\n",
        "  'notes': 'Educational demo; parameters are illustrative and not instrument‑calibrated.'\n",
        "}\n",
        "(NB_OUT/'radiation_noise_bundle.json').write_text(json.dumps(bundle, indent=2))\n",
        "pd.DataFrame({'wavelength_index': base['wavelength_index'], 'mu_base': mu, 'var_noise': var_bins}).to_csv(NB_OUT/'radiation_noise_detail.csv', index=False)\n",
        "print('Wrote bundle & detail CSV to', NB_OUT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "### Notes & Further Reading\n",
        "- **Shot/read/dark/background** processes and their statistics are standard detector topics; see your instrument handbook for exact models and units.\n",
        "- **Cosmic ray** rates depend on orbit and shielding; spikes must be detected/flagged to avoid biasing spectra and FFT/autocorr diagnostics.\n",
        "- For production pipeline, rely on the **calibration kill chain** and CLI diagnostics rather than these educational injectors."
      ]
    }
  ]
}