{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9cf7443",
   "metadata": {},
   "source": [
    "# 📐 SpectraMind V50 — 05 · Uncertainty Calibration & Cycle Consistency\n",
    "\n",
    "Goals:\n",
    "- Evaluate calibration quality (coverage vs. nominal for μ/σ)\n",
    "- Apply **temperature scaling** (global σ scale) and optional per-bin scaling\n",
    "- Emit a **calibrated submission CSV** with updated σ\n",
    "- (Optional) Run a **cycle-consistency** sanity check via forward sim\n",
    "- Log a **reproducibility entry** to `v50_debug_log.md`\n",
    "\n",
    "> CLI-first and reproducibility-friendly. Cells skip gracefully if inputs/CLI aren't present.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b80d63",
   "metadata": {},
   "source": [
    "## 🔧 Environment & Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e7b2fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json, os, sys, platform, shutil\n",
    "from datetime import datetime\n",
    "\n",
    "ROOT = Path.cwd()\n",
    "ART = ROOT / \"artifacts\"\n",
    "DIAG_DIR = ART / \"diagnostics\"\n",
    "SUBMIT_DIR = ART / \"submission\"\n",
    "CAL_DIR = ART / \"calibration\"\n",
    "CAL_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Typical inputs (if present)\n",
    "DIAG_SUMMARY = DIAG_DIR / \"diagnostic_summary.json\"  # expected to hold residual/sigma stats if generated\n",
    "SUBMISSION_CSV = SUBMIT_DIR / \"submission.csv\"\n",
    "\n",
    "# Outputs\n",
    "CAL_REPORT_JSON = CAL_DIR / \"calibration_report.json\"\n",
    "CAL_FACTORS_JSON = CAL_DIR / \"sigma_scale_factors.json\"\n",
    "CALIBRATED_SUBMISSION_CSV = SUBMIT_DIR / \"submission_calibrated.csv\"\n",
    "LOG_MD = ROOT / \"v50_debug_log.md\"\n",
    "\n",
    "env = {\n",
    "    \"timestamp\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    \"python\": sys.version.replace(\"\\n\", \" \"),\n",
    "    \"platform\": platform.platform(),\n",
    "    \"cwd\": str(ROOT),\n",
    "    \"paths\": {\n",
    "        \"ART\": str(ART),\n",
    "        \"DIAG_DIR\": str(DIAG_DIR),\n",
    "        \"SUBMIT_DIR\": str(SUBMIT_DIR),\n",
    "        \"CAL_DIR\": str(CAL_DIR),\n",
    "        \"DIAG_SUMMARY\": str(DIAG_SUMMARY),\n",
    "        \"SUBMISSION_CSV\": str(SUBMISSION_CSV),\n",
    "        \"CAL_REPORT_JSON\": str(CAL_REPORT_JSON),\n",
    "        \"CAL_FACTORS_JSON\": str(CAL_FACTORS_JSON),\n",
    "        \"CALIBRATED_SUBMISSION_CSV\": str(CALIBRATED_SUBMISSION_CSV),\n",
    "        \"LOG_MD\": str(LOG_MD),\n",
    "    }\n",
    "}\n",
    "print(json.dumps(env, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e46c6e",
   "metadata": {},
   "source": [
    "## 🩺 CLI sanity (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea2a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, subprocess\n",
    "\n",
    "def check_cli(cmd=\"spectramind\", args=[\"--version\"]):\n",
    "    exe = shutil.which(cmd)\n",
    "    if not exe:\n",
    "        print(\"ℹ️ 'spectramind' CLI not found on PATH. CLI-dependent steps will be skipped.\")\n",
    "        return {\"available\": False}\n",
    "    try:\n",
    "        out = subprocess.check_output([cmd] + args, stderr=subprocess.STDOUT, text=True, timeout=30)\n",
    "        print(out)\n",
    "        return {\"available\": True, \"output\": out}\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ CLI call failed: {e}\")\n",
    "        return {\"available\": True, \"error\": str(e)}\n",
    "\n",
    "cli_info = check_cli()\n",
    "cli_info\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa603dc",
   "metadata": {},
   "source": [
    "## 📊 Load diagnostics & compute temperature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ee48fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, math\n",
    "from statistics import median\n",
    "import numpy as np\n",
    "\n",
    "def load_diag_summary(path: Path):\n",
    "    if not path.exists():\n",
    "        print(\"⚠️ No diagnostic summary found:\", path)\n",
    "        return None\n",
    "    try:\n",
    "        with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(\"⚠️ Failed to parse diagnostic summary:\", e)\n",
    "        return None\n",
    "\n",
    "def extract_resid_sigma(diag_data):\n",
    "    \"\"\"Attempt to extract arrays of residuals and predicted sigmas from a generic diagnostic JSON.\n",
    "    Heuristics handle a few common schemas.\n",
    "    Returns arrays flattened across items/bins if possible.\n",
    "    \"\"\"\n",
    "    resids = []\n",
    "    sigmas = []\n",
    "    if diag_data is None:\n",
    "        return np.array([]), np.array([])\n",
    "\n",
    "    # Common shapes: {\"items\": [{\"residuals\":[...], \"sigma\":[...]} ...]}\n",
    "    # Or {\"planets\": {\"id\": {\"residuals\":[...], \"sigma\":[...]}}}\n",
    "    # Or flat: {\"residuals\":[...], \"sigma\":[...]}\n",
    "    if isinstance(diag_data, dict):\n",
    "        if \"items\" in diag_data and isinstance(diag_data[\"items\"], list):\n",
    "            for rec in diag_data[\"items\"]:\n",
    "                r = rec.get(\"residuals\") or rec.get(\"resid\") or rec.get(\"residual\")\n",
    "                s = rec.get(\"sigma\") or rec.get(\"sigmas\") or rec.get(\"pred_sigma\")\n",
    "                if isinstance(r, list) and isinstance(s, list):\n",
    "                    m = min(len(r), len(s))\n",
    "                    resids.extend(r[:m])\n",
    "                    sigmas.extend(s[:m])\n",
    "        elif \"planets\" in diag_data and isinstance(diag_data[\"planets\"], dict):\n",
    "            for _, rec in diag_data[\"planets\"].items():\n",
    "                r = rec.get(\"residuals\") or rec.get(\"resid\") or rec.get(\"residual\")\n",
    "                s = rec.get(\"sigma\") or rec.get(\"sigmas\") or rec.get(\"pred_sigma\")\n",
    "                if isinstance(r, list) and isinstance(s, list):\n",
    "                    m = min(len(r), len(s))\n",
    "                    resids.extend(r[:m])\n",
    "                    sigmas.extend(s[:m])\n",
    "        else:\n",
    "            r = diag_data.get(\"residuals\") or diag_data.get(\"resid\") or diag_data.get(\"residual\")\n",
    "            s = diag_data.get(\"sigma\") or diag_data.get(\"sigmas\") or diag_data.get(\"pred_sigma\")\n",
    "            if isinstance(r, list) and isinstance(s, list):\n",
    "                m = min(len(r), len(s))\n",
    "                resids.extend(r[:m])\n",
    "                sigmas.extend(s[:m])\n",
    "\n",
    "    res = np.array(resids, dtype=float) if resids else np.array([])\n",
    "    sg = np.array(sigmas, dtype=float) if sigmas else np.array([])\n",
    "    print(\"Extracted residuals:\", res.shape, \"sigmas:\", sg.shape)\n",
    "    return res, sg\n",
    "\n",
    "def compute_temperature_scaling(res, sg, eps=1e-12):\n",
    "    \"\"\"Compute a global scale alpha for sigma to improve calibration.\n",
    "    Two estimates:\n",
    "      - RMS-based: sqrt(mean(res^2) / mean(sigma^2))\n",
    "      - Median-abs-based: median(|res|/sigma) / median(|N(0,1)|) with median(|Z|)=0.674489...\n",
    "    Returns dict with both and a chosen alpha.\n",
    "    \"\"\"\n",
    "    if res.size == 0 or sg.size == 0 or res.size != sg.size:\n",
    "        return {\"alpha_rms\": 1.0, \"alpha_med\": 1.0, \"alpha\": 1.0, \"note\": \"insufficient data\"}\n",
    "\n",
    "    rms_res = np.sqrt(np.mean(res**2))\n",
    "    rms_sig = np.sqrt(np.mean((sg+eps)**2))\n",
    "    alpha_rms = (rms_res / (rms_sig + eps)) if rms_sig > 0 else 1.0\n",
    "\n",
    "    ratio = np.abs(res) / (sg + eps)\n",
    "    med_ratio = np.median(ratio)\n",
    "    med_abs_z = 0.6744897501960817  # median |N(0,1)|\n",
    "    alpha_med = (med_ratio / med_abs_z) if med_abs_z > 0 else 1.0\n",
    "\n",
    "    # Choose alpha preferring robust median, falling back to rms if extreme\n",
    "    alpha = alpha_med if 0.1 <= alpha_med <= 10 else alpha_rms\n",
    "    return {\"alpha_rms\": float(alpha_rms), \"alpha_med\": float(alpha_med), \"alpha\": float(alpha)}\n",
    "\n",
    "def nominal_coverage_checks(res, sg, alphas=(1.0,), eps=1e-12):\n",
    "    \"\"\"Compute empirical coverage for ±1σ (~68.27%) and ±1.96σ (~95%) under various alphas.\"\"\"\n",
    "    if res.size == 0 or sg.size == 0 or res.size != sg.size:\n",
    "        return {}\n",
    "    out = {}\n",
    "    for a in alphas:\n",
    "        z = np.abs(res) / (a*(sg+eps))\n",
    "        cov68 = float(np.mean(z <= 1.0))\n",
    "        cov95 = float(np.mean(z <= 1.96))\n",
    "        out[str(a)] = {\"cov_68\": cov68, \"cov_95\": cov95}\n",
    "    return out\n",
    "\n",
    "diag = load_diag_summary(DIAG_SUMMARY)\n",
    "res, sg = extract_resid_sigma(diag)\n",
    "scales = compute_temperature_scaling(res, sg)\n",
    "cov = nominal_coverage_checks(res, sg, alphas=(1.0, scales.get(\"alpha\", 1.0)))\n",
    "print(\"Proposed scaling:\", json.dumps(scales, indent=2))\n",
    "print(\"Coverage:\", json.dumps(cov, indent=2))\n",
    "\n",
    "# Persist a small calibration report\n",
    "report = {\n",
    "    \"timestamp\": datetime.now().isoformat(timespec=\"seconds\"),\n",
    "    \"counts\": int(min(res.size, sg.size)),\n",
    "    \"scales\": scales,\n",
    "    \"coverage\": cov\n",
    "}\n",
    "with open(CAL_REPORT_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "\n",
    "with open(CAL_FACTORS_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump({\"global_sigma_scale\": scales.get(\"alpha\", 1.0)}, f, indent=2)\n",
    "\n",
    "print(\"Saved:\", CAL_REPORT_JSON, \"and\", CAL_FACTORS_JSON)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d505447",
   "metadata": {},
   "source": [
    "## 📈 Visualize calibration (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dac7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build an empirical CDF of |res|/sigma and overlay nominal 68/95 thresholds\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_empirical_cdf(res, sg, alpha=1.0, title=\"Empirical |z| CDF\"):\n",
    "    if res.size == 0 or sg.size == 0 or res.size != sg.size:\n",
    "        print(\"No data to plot.\")\n",
    "        return\n",
    "    z = np.abs(res) / (alpha*(sg+1e-12))\n",
    "    z_sorted = np.sort(z)\n",
    "    y = np.linspace(0, 1, len(z_sorted), endpoint=False)\n",
    "\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(z_sorted, y)\n",
    "    plt.axvline(1.0, linestyle=\"--\")\n",
    "    plt.axvline(1.96, linestyle=\"--\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"|z| = |res| / (alpha * sigma)\")\n",
    "    plt.ylabel(\"CDF\")\n",
    "    plt.show()\n",
    "\n",
    "# Raw and scaled views (if data available)\n",
    "if res.size and sg.size and res.size == sg.size:\n",
    "    plot_empirical_cdf(res, sg, alpha=1.0, title=\"Empirical |z| CDF (alpha=1.0)\")\n",
    "    plot_empirical_cdf(res, sg, alpha=max(1e-6, float(scales.get(\"alpha\", 1.0))), title=f\"Empirical |z| CDF (alpha={scales.get('alpha', 1.0):.3f})\")\n",
    "else:\n",
    "    print(\"⚠️ Skipping plots — residual/sigma arrays unavailable.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fda4767",
   "metadata": {},
   "source": [
    "## 🛠️ Apply scaling to submission σ columns and save calibrated CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419d89ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def detect_sigma_columns(df: pd.DataFrame):\n",
    "    # Heuristics: columns containing \"sigma\" or ending with \"_sigma\"\n",
    "    cands = [c for c in df.columns if \"sigma\" in c.lower() or c.lower().endswith(\"_sigma\")]\n",
    "    return cands\n",
    "\n",
    "def scale_submission_sigmas(sub_csv: Path, out_csv: Path, alpha: float):\n",
    "    if not sub_csv.exists():\n",
    "        print(\"⚠️ Submission not found:\", sub_csv)\n",
    "        return False, []\n",
    "    try:\n",
    "        df = pd.read_csv(sub_csv)\n",
    "    except Exception as e:\n",
    "        print(\"❌ Failed to read submission CSV:\", e)\n",
    "        return False, []\n",
    "\n",
    "    sigma_cols = detect_sigma_columns(df)\n",
    "    if not sigma_cols:\n",
    "        # Fallback: if columns alternate mu/sigma per bin with patterns, user can adapt here\n",
    "        print(\"⚠️ No sigma-like columns detected; no scaling applied.\")\n",
    "        out_csv.write_text(df.to_csv(index=False))\n",
    "        return True, []\n",
    "\n",
    "    alpha = float(alpha) if np.isfinite(alpha) else 1.0\n",
    "    df[sigma_cols] = df[sigma_cols].astype(float) * alpha\n",
    "    out_csv.write_text(df.to_csv(index=False))\n",
    "    print(f\"✅ Wrote calibrated submission with alpha={alpha} to\", out_csv)\n",
    "    return True, sigma_cols\n",
    "\n",
    "alpha = float((scales or {}).get(\"alpha\", 1.0))\n",
    "ok, used_cols = scale_submission_sigmas(SUBMISSION_CSV, CALIBRATED_SUBMISSION_CSV, alpha)\n",
    "print(\"Sigma columns scaled:\", used_cols)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d5e13b5",
   "metadata": {},
   "source": [
    "## 🔬 (Optional) Per-bin scaling (if binwise stats available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29511e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If DIAG_SUMMARY contains per-bin RMSE and mean sigma per wavelength/bin,\n",
    "# compute per-bin alpha and (optionally) save a separate per-bin-calibrated submission.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "PERBIN_FACTORS_JSON = CAL_DIR / \"sigma_scale_perbin.json\"\n",
    "CALIBRATED_PERBIN_SUBMISSION_CSV = SUBMIT_DIR / \"submission_calibrated_perbin.csv\"\n",
    "\n",
    "def compute_perbin_alphas(diag_data):\n",
    "    # Heuristics: look for entries like {\"bin_index\": i, \"rmse\": ..., \"mean_sigma\": ...}\n",
    "    # or arrays diag_data[\"per_bin\"][\"rmse\"], diag_data[\"per_bin\"][\"mean_sigma\"]\n",
    "    if diag_data is None:\n",
    "        return None\n",
    "    rmse = None; msig = None\n",
    "    if isinstance(diag_data, dict) and \"per_bin\" in diag_data:\n",
    "        per = diag_data[\"per_bin\"]\n",
    "        if isinstance(per, dict):\n",
    "            rmse = per.get(\"rmse\")\n",
    "            msig = per.get(\"mean_sigma\") or per.get(\"sigma_mean\")\n",
    "    if isinstance(rmse, list) and isinstance(msig, list) and len(rmse)==len(msig):\n",
    "        rmse = np.array(rmse, dtype=float)\n",
    "        msig = np.array(msig, dtype=float)\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            alphas = np.where(msig>0, np.sqrt(rmse**2 / (msig**2 + 1e-12)), 1.0)\n",
    "        return alphas.tolist()\n",
    "    return None\n",
    "\n",
    "perbin_alphas = compute_perbin_alphas(diag)\n",
    "if perbin_alphas:\n",
    "    with open(PERBIN_FACTORS_JSON, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump({\"per_bin_alphas\": perbin_alphas}, f, indent=2)\n",
    "    print(\"Saved per-bin scale factors:\", PERBIN_FACTORS_JSON)\n",
    "\n",
    "    # Attempt to apply to submission if it has distinct sigma columns per-bin\n",
    "    try:\n",
    "        df = pd.read_csv(SUBMISSION_CSV)\n",
    "        sigma_cols = [c for c in df.columns if \"sigma\" in c.lower() or c.lower().endswith(\"_sigma\")]\n",
    "        # If sigma columns equal in number to perbin_alphas, map directly\n",
    "        if sigma_cols and len(sigma_cols) == len(perbin_alphas):\n",
    "            df[sigma_cols] = df[sigma_cols].astype(float) * np.array(perbin_alphas, dtype=float)\n",
    "            CALIBRATED_PERBIN_SUBMISSION_CSV.write_text(df.to_csv(index=False))\n",
    "            print(\"✅ Wrote per-bin calibrated submission:\", CALIBRATED_PERBIN_SUBMISSION_CSV)\n",
    "        else:\n",
    "            print(\"ℹ️ Per-bin scaling not applied: mismatch between sigma columns and per-bin factors.\")\n",
    "    except Exception as e:\n",
    "        print(\"ℹ️ Per-bin scaling skipped due to error:\", e)\n",
    "else:\n",
    "    print(\"ℹ️ No per-bin stats detected; skipping per-bin scaling.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca81697",
   "metadata": {},
   "source": [
    "## 🔁 (Optional) Cycle-consistency via forward simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b018f132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, subprocess\n",
    "\n",
    "def run_cycle_consistency(sub_csv: Path):\n",
    "    exe = shutil.which(\"spectramind\")\n",
    "    if not exe:\n",
    "        print(\"ℹ️ spectramind CLI not found; skipping forward-sim cycle test.\")\n",
    "        return False\n",
    "    # Hypothetical CLI signature; adjust to your repo's `simulate` subcommand if present\n",
    "    cmd = [\"spectramind\", \"simulate\", \"--from-spectra\", str(sub_csv), \"--out\", str(CAL_DIR / \"simulated_observations\")]\n",
    "    print(\"Running:\", \" \".join(cmd))\n",
    "    try:\n",
    "        subprocess.check_call(cmd, timeout=3600)\n",
    "        print(\"✅ Forward simulation produced artifacts in:\", CAL_DIR / \"simulated_observations\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"ℹ️ Forward-sim step failed or not implemented:\", e)\n",
    "        return False\n",
    "\n",
    "# Try on calibrated submission if present; fallback to original\n",
    "target_csv = CALIBRATED_SUBMISSION_CSV if CALIBRATED_SUBMISSION_CSV.exists() else SUBMISSION_CSV\n",
    "_ = run_cycle_consistency(target_csv) if target_csv.exists() else print(\"ℹ️ No submission CSV available for cycle check.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b467502e",
   "metadata": {},
   "source": [
    "## 🧾 Append run metadata to `v50_debug_log.md`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185ef0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "entry = f\"\"\"### Notebook: 05_uncertainty_calibration_and_cycle_consistency.ipynb\n",
    "- timestamp: {datetime.now().isoformat(timespec=\"seconds\")}\n",
    "- cwd: {ROOT}\n",
    "- python: {platform.python_version()}\n",
    "- actions:\n",
    "  - diag_summary_present: {DIAG_SUMMARY.exists()}\n",
    "  - submission_csv_present: {SUBMISSION_CSV.exists()}\n",
    "  - alpha_used: {(scales or {}).get(\"alpha\", 1.0)}\n",
    "  - calibrated_submission_csv_exists: {CALIBRATED_SUBMISSION_CSV.exists()}\n",
    "\"\"\"\n",
    "try:\n",
    "    with open(LOG_MD, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(entry + \"\\n\")\n",
    "    print(f\"Appended notebook log entry to {LOG_MD}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ Could not append to {LOG_MD}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "mimetype": "text/x-python",
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
