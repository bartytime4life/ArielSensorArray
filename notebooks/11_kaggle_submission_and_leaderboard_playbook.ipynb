{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "696fab6b",
   "metadata": {},
   "source": [
    "# ðŸ SpectraMind V50 â€” Kaggle Submission & Leaderboard Playbook (Notebook 11)\n",
    "\n",
    "**Goal.** Package, validate, and (optionally) upload a **Kaggle submission** for the NeurIPS Ariel Data Challenge.  \n",
    "This notebook is **CLI-first** and provides **DRY-RUN** safety if the `kaggle` CLI isn't available.\n",
    "\n",
    "**What this notebook does**\n",
    "1. Pre-flight: detect Kaggle CLI, capture env/git info, set run paths  \n",
    "2. Locate/validate the submission artifacts (CSV/ZIP) produced by `spectramind submit`  \n",
    "3. Create a **submission bundle** + README/model card and a **manifest** with hashes  \n",
    "4. (Optional) **Kaggle upload** via CLI/API â€” with **DRY-RUN fallback**  \n",
    "5. Record **leaderboard metadata** and a submission log usable in CI and postmortems  \n",
    "6. Mermaid sketch of the submission workflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19e3b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â–‘â–‘ Pre-flight â–‘â–‘\n",
    "import os, sys, json, shutil, subprocess, datetime, pathlib, hashlib\n",
    "\n",
    "RUN_TS = datetime.datetime.utcnow().strftime(\"%Y%m%dT%H%M%SZ\")\n",
    "RUN_ID = f\"kaggle_submit_{RUN_TS}\"\n",
    "ROOT_OUT = \"/mnt/data/kaggle_submission\"\n",
    "ARTIFACTS = os.path.join(ROOT_OUT, RUN_ID)\n",
    "LOGS = os.path.join(ARTIFACTS, \"logs\")\n",
    "PKG = os.path.join(ARTIFACTS, \"package\")\n",
    "for p in (ROOT_OUT, ARTIFACTS, LOGS, PKG):\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "\n",
    "def which(cmd:str)->bool: return shutil.which(cmd) is not None\n",
    "KAGGLE_PRESENT = which(\"kaggle\")\n",
    "CLI_PRESENT = which(\"spectramind\")\n",
    "\n",
    "def git_cmd(args):\n",
    "    try:\n",
    "        out = subprocess.check_output([\"git\", *args], stderr=subprocess.STDOUT, timeout=5).decode().strip()\n",
    "        return out\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "env = {\n",
    "    \"python\": sys.version.replace(\"\\n\",\" \"),\n",
    "    \"platform\": sys.platform,\n",
    "    \"kaggle_present\": KAGGLE_PRESENT,\n",
    "    \"spectramind_present\": CLI_PRESENT,\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"paths\": {\"artifacts\": ARTIFACTS, \"logs\": LOGS, \"package\": PKG},\n",
    "    \"git\": {\n",
    "        \"commit\": git_cmd([\"rev-parse\", \"HEAD\"]),\n",
    "        \"branch\": git_cmd([\"rev-parse\", \"--abbrev-ref\", \"HEAD\"]),\n",
    "        \"status\": git_cmd([\"status\", \"--porcelain\"]),\n",
    "    },\n",
    "}\n",
    "with open(os.path.join(ARTIFACTS, \"env.json\"), \"w\") as f:\n",
    "    json.dump(env, f, indent=2)\n",
    "\n",
    "print(\"=== Pre-flight ===\")\n",
    "print(json.dumps(env, indent=2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab28e92",
   "metadata": {},
   "source": [
    "## Locate submission artifact (CSV/ZIP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda6dbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, json, pathlib\n",
    "\n",
    "# Heuristics: look for a submission file produced earlier (e.g., by `spectramind submit`)\n",
    "candidate_globs = [\n",
    "    \"/mnt/data/**/submission*.csv\",\n",
    "    \"/mnt/data/**/submission*.zip\",\n",
    "    \"/mnt/data/**/submission_bundle*.zip\",\n",
    "]\n",
    "found = []\n",
    "for pattern in candidate_globs:\n",
    "    for path in glob.glob(pattern, recursive=True):\n",
    "        if os.path.isfile(path):\n",
    "            found.append(path)\n",
    "\n",
    "found = sorted(set(found), key=lambda p: (os.path.getmtime(p), p), reverse=True)\n",
    "print(\"Found candidate submissions:\", json.dumps(found[:10], indent=2))\n",
    "\n",
    "SUBMISSION_FILE = found[0] if found else None\n",
    "print(\"Chosen submission file:\", SUBMISSION_FILE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9930b46a",
   "metadata": {},
   "source": [
    "## Validate & stage submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ef636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil, os, csv, zipfile, json, hashlib\n",
    "\n",
    "def sha256_of_file(path, chunk=1024*1024):\n",
    "    try:\n",
    "        h = hashlib.sha256()\n",
    "        with open(path, \"rb\") as f:\n",
    "            while True:\n",
    "                b = f.read(chunk)\n",
    "                if not b: break\n",
    "                h.update(b)\n",
    "        return h.hexdigest()\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "valid = False\n",
    "msg = \"\"\n",
    "\n",
    "if SUBMISSION_FILE and os.path.isfile(SUBMISSION_FILE):\n",
    "    # Basic checks: csv or zip\n",
    "    ext = os.path.splitext(SUBMISSION_FILE)[1].lower()\n",
    "    if ext == \".csv\":\n",
    "        # Minimal CSV sanity: header present, at least one row\n",
    "        try:\n",
    "            with open(SUBMISSION_FILE, newline=\"\") as f:\n",
    "                reader = csv.reader(f)\n",
    "                header = next(reader, None)\n",
    "                row = next(reader, None)\n",
    "                valid = header is not None and row is not None\n",
    "                msg = f\"CSV header={header} first_row={row[:3] if row else None}\"\n",
    "        except Exception as e:\n",
    "            msg = f\"CSV read error: {e}\"\n",
    "    elif ext == \".zip\":\n",
    "        try:\n",
    "            with zipfile.ZipFile(SUBMISSION_FILE, \"r\") as zf:\n",
    "                namelist = zf.namelist()\n",
    "                valid = len(namelist) > 0\n",
    "                msg = f\"ZIP contains: {namelist[:5]}...\"\n",
    "        except Exception as e:\n",
    "            msg = f\"ZIP read error: {e}\"\n",
    "    else:\n",
    "        msg = f\"Unsupported extension: {ext}\"\n",
    "else:\n",
    "    msg = \"No submission file found.\"\n",
    "\n",
    "print(\"Valid?\", valid, \"|\", msg)\n",
    "\n",
    "STAGED = None\n",
    "if valid:\n",
    "    STAGED = os.path.join(PKG, os.path.basename(SUBMISSION_FILE))\n",
    "    shutil.copy2(SUBMISSION_FILE, STAGED)\n",
    "    print(\"Staged:\", STAGED, \"SHA256:\", sha256_of_file(STAGED))\n",
    "else:\n",
    "    print(\"Skipping stage; invalid or missing submission file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afeb306",
   "metadata": {},
   "source": [
    "## Write README/model card & manifest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4e8776",
   "metadata": {},
   "outputs": [],
   "source": [
    "readme = f\"\"\"# SpectraMind V50 â€” Kaggle Submission Package\n",
    "\n",
    "**Run ID:** {RUN_ID}  \n",
    "**Timestamp (UTC):** {RUN_TS}\n",
    "\n",
    "This package was generated by *Notebook 11 â€” Kaggle Submission & Leaderboard Playbook*.\n",
    "\n",
    "## Contents\n",
    "- `{os.path.basename(STAGED) if STAGED else 'MISSING'}` â€” submission artifact\n",
    "- `manifest.json` â€” provenance (git, hashes)\n",
    "- `notes.md` â€” optional notes\n",
    "\n",
    "## Reproducibility\n",
    "- Code commit: {env['git']['commit']}\n",
    "- Branch: {env['git']['branch']}\n",
    "- Python: {env['python']}\n",
    "\n",
    "This package is designed to be CI-friendly and traceable.\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(PKG, \"README.md\"), \"w\") as f:\n",
    "    f.write(readme)\n",
    "\n",
    "manifest = {\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"timestamp_utc\": RUN_TS,\n",
    "    \"git\": env.get(\"git\"),\n",
    "    \"submission_file\": STAGED,\n",
    "    \"submission_sha256\": sha256_of_file(STAGED) if STAGED else None,\n",
    "    \"kaggle_cli_present\": KAGGLE_PRESENT,\n",
    "}\n",
    "with open(os.path.join(PKG, \"manifest.json\"), \"w\") as f:\n",
    "    json.dump(manifest, f, indent=2)\n",
    "\n",
    "with open(os.path.join(PKG, \"notes.md\"), \"w\") as f:\n",
    "    f.write(\"Add experiment notes or leaderboard observations here.\\n\")\n",
    "    \n",
    "print(\"Wrote README, manifest, notes into\", PKG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa6b85d",
   "metadata": {},
   "source": [
    "## (Optional) Upload to Kaggle â€” DRY-RUN safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cc03e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, shlex, os, json\n",
    "\n",
    "def run_cmd(cmd_list, log_name):\n",
    "    log_path = os.path.join(LOGS, f\"{log_name}.log\")\n",
    "    err_path = os.path.join(LOGS, f\"{log_name}.err\")\n",
    "    if not KAGGLE_PRESENT:\n",
    "        msg = f\"[DRY-RUN] Would execute: {' '.join(shlex.quote(c) for c in cmd_list)}\\n\"\n",
    "        open(log_path, \"w\").write(msg); open(err_path, \"w\").write(\"\")\n",
    "        return 0, msg, \"\"\n",
    "    try:\n",
    "        proc = subprocess.Popen(cmd_list, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "        out, err = proc.communicate()\n",
    "        open(log_path, \"wb\").write(out or b\"\"); open(err_path, \"wb\").write(err or b\"\")\n",
    "        return proc.returncode, (out or b\"\").decode(), (err or b\"\").decode()\n",
    "    except Exception as e:\n",
    "        return 99, \"\", str(e)\n",
    "\n",
    "# NOTE: adjust competition slug if needed\n",
    "COMPETITION = \"ariel-data-challenge-2025\"\n",
    "\n",
    "rc, out, err = (0, \"\", \"\")\n",
    "if STAGED and os.path.isfile(STAGED):\n",
    "    # Kaggle expects: kaggle competitions submit -c <comp> -f <file> -m \"<message>\"\n",
    "    msg = f\"SpectraMind V50 auto-submit {RUN_ID}\"\n",
    "    cmd = [\"kaggle\", \"competitions\", \"submit\", \"-c\", COMPETITION, \"-f\", STAGED, \"-m\", msg]\n",
    "    rc, out, err = run_cmd(cmd, log_name=\"kaggle_submit\")\n",
    "    print(\"Submit rc:\", rc)\n",
    "    print(\"stdout (truncated):\", out[:300])\n",
    "    print(\"stderr (truncated):\", err[:300])\n",
    "else:\n",
    "    print(\"[Skip] No staged submission file to upload.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e71ad91",
   "metadata": {},
   "source": [
    "## Record submission log & leaderboard metadata stub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5bc21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = {\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"ts_utc\": RUN_TS,\n",
    "    \"kaggle_present\": KAGGLE_PRESENT,\n",
    "    \"submitted_file\": os.path.basename(STAGED) if STAGED else None,\n",
    "    \"submit_rc\": rc if 'rc' in locals() else None,\n",
    "}\n",
    "with open(os.path.join(ARTIFACTS, \"submission_log.json\"), \"w\") as f:\n",
    "    json.dump(log, f, indent=2)\n",
    "print(\"Saved submission log:\", os.path.join(ARTIFACTS, \"submission_log.json\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ae4b3a",
   "metadata": {},
   "source": [
    "## Browse produced artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5011f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def tree(path, prefix=\"\"):\n",
    "    items = sorted(os.listdir(path))\n",
    "    lines = []\n",
    "    for i, name in enumerate(items):\n",
    "        full = os.path.join(path, name)\n",
    "        connector = \"â””â”€â”€ \" if i == len(items)-1 else \"â”œâ”€â”€ \"\n",
    "        lines.append(prefix + connector + name)\n",
    "        if os.path.isdir(full):\n",
    "            extension = \"    \" if i == len(items)-1 else \"â”‚   \"\n",
    "            lines.extend(tree(full, prefix + extension))\n",
    "    return lines\n",
    "\n",
    "print(\"PKG TREE:\", PKG)\n",
    "print(\"\\n\".join(tree(PKG)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d5c50f",
   "metadata": {},
   "source": [
    "## Submission flow (Mermaid)\n",
    "\n",
    "```mermaid\n",
    "flowchart LR\n",
    "  A[Find submission CSV/ZIP] --> B[Validate structure]\n",
    "  B --> C[Stage into /package]\n",
    "  C --> D[Write README + manifest]\n",
    "  D --> E{Kaggle CLI available?}\n",
    "  E -- Yes --> F[Upload via kaggle competitions submit]\n",
    "  E -- No --> G[DRY-RUN: log command]\n",
    "  F --> H[Submission log + LB notes]\n",
    "  G --> H\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b095a240",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "- Ensure your **Kaggle API token** is configured (`~/.kaggle/kaggle.json`) with proper permissions.\n",
    "- Verify the **competition slug** (default: `ariel-data-challenge-2025`) before uploading.\n",
    "- Use this notebook in **CI** after `10_full_pipeline_reproducibility_and_ci.ipynb` to automate packaging and submission.\n",
    "- Track submissions & scores in a lightweight CSV or use MLflow/Sheets for team visibility.\n",
    "\n",
    "> Tip: read Kaggleâ€™s platform guide for notebook/CLI usage and submission rules.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
