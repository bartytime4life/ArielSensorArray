{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§  SpectraMind V50 â€” 03_train_v50_demo.ipynb\n",
    "\n",
    "Missionâ€‘grade **mini training run** that exercises the official CLI with Hydra overrides.\n",
    "\n",
    "**Standards**\n",
    "- Notebooks are *thin orchestration*: **CLI â†’ Hydra â†’ DVC artifacts**. No adâ€‘hoc training logic.\n",
    "- Inputs/outputs are versioned and written under `data/` and `outputs/` (DVCâ€‘tracked where applicable).\n",
    "- Figures/JSON from this demo are saved under `outputs/train_demo/`.\n",
    "- Logs/diaries live under `logs/` (Rich console, JSONL, and Markdown run diary).\n",
    "\n",
    "**What this notebook does**\n",
    "1) Environment & CLI sanity checks.\n",
    "2) (Optional) print the merged Hydra config for visibility.\n",
    "3) Run a **fast** demo training via CLI (e.g., `training.fast_dev_run=true`).\n",
    "4) Surface key artifacts (e.g., `loss_curve.png`), and tail the run diary.\n",
    "5) Persist a small `training_report.json` for downstream diagnostics.\n",
    "\n",
    "> For full training or sweeps, use the CLI directly with your Hydra configs (e.g., `spectramind train training.epochs=50 model=...`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Setup & paths\n",
    "Assumes this notebook is in `/notebooks`. Weâ€™ll create a demo output folder under `outputs/train_demo/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": { "tags": ["init"] },
   "outputs": [],
   "source": [
    "import os, sys, json, subprocess, textwrap\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_context('notebook'); sns.set_style('whitegrid')\n",
    "\n",
    "NB_DIR = Path.cwd()\n",
    "ROOT = NB_DIR if (NB_DIR / 'data').exists() else NB_DIR.parents[0]\n",
    "DATA = ROOT / 'data'\n",
    "OUT = ROOT / 'outputs'\n",
    "LOGS = ROOT / 'logs'\n",
    "DEMO = OUT / 'train_demo'\n",
    "OUT.mkdir(parents=True, exist_ok=True)\n",
    "LOGS.mkdir(parents=True, exist_ok=True)\n",
    "DEMO.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('ROOT:', ROOT)\n",
    "print('DATA:', DATA)\n",
    "print('OUT :', OUT)\n",
    "print('LOGS:', LOGS)\n",
    "print('DEMO:', DEMO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Environment & CLI snapshot (bestâ€‘effort)\n",
    "Capture versions and commit state for auditability. Cells are robust to missing tools and wonâ€™t hardâ€‘fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": { "tags": ["env"] },
   "outputs": [],
   "source": [
    "def _run(cmd: str, cwd: Path | None = None):\n",
    "    print(f\"\\n$ {cmd}\")\n",
    "    try:\n",
    "        p = subprocess.run(cmd, shell=True, text=True, capture_output=True, cwd=str(cwd or ROOT))\n",
    "        out = (p.stdout or '')[-2000:]\n",
    "        err = (p.stderr or '')[-2000:]\n",
    "        print(out.strip())\n",
    "        if p.returncode != 0 and err.strip():\n",
    "            print('[stderr]', err.strip())\n",
    "        return p.returncode\n",
    "    except Exception as e:\n",
    "        print('[skip]', e)\n",
    "        return -1\n",
    "\n",
    "_run('python --version')\n",
    "_run('spectramind --version')              # unified CLI (if available)\n",
    "_run('dvc --version')                       # DVC presence\n",
    "_run('git rev-parse --short HEAD')          # commit id\n",
    "_run('git status -s')                       # working tree state\n",
    "\n",
    "env_snapshot = {\n",
    "    'python': sys.version.split()[0],\n",
    "    'cwd': str(Path.cwd()),\n",
    "}\n",
    "with open(DEMO / 'env_snapshot.json', 'w') as f:\n",
    "    json.dump(env_snapshot, f, indent=2)\n",
    "print('Saved', DEMO / 'env_snapshot.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) (Optional) Print merged Hydra config for this demo\n",
    "If the CLI supports a `--print-config` flag (or similar), we can render the composed configuration before running.\n",
    "\n",
    "> If your CLI exposes a different flag for printing configs, update the command below accordingly, or skip if unsupported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": { "tags": ["config"] },
   "outputs": [],
   "source": [
    "# This is optional and may be a no-op if the CLI doesn't support it.\n",
    "_run('spectramind train training.fast_dev_run=true --print-config')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Run a **fast** training demo via CLI\n",
    "Weâ€™ll prefer `training.fast_dev_run=true` for a smoke test. As a fallback (if unsupported), use `training.epochs=1`.\n",
    "\n",
    "Artifacts (e.g., `loss_curve.png`, checkpoints, JSON logs) should be written under `outputs/` per your configs. We wonâ€™t assume exact subpaths; weâ€™ll discover them after the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": { "tags": ["train"] },
   "outputs": [],
   "source": [
    "ret = _run('spectramind train training.fast_dev_run=true')\n",
    "if ret != 0:\n",
    "    print('\\nRetrying with epochs=1 fallback...')\n",
    "    ret = _run('spectramind train training.epochs=1')\n",
    "print('Training command exit code:', ret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Surface key artifacts (loss curve, checkpoints, logs)\n",
    "Weâ€™ll search `outputs/` for typical training artifacts and display what we find, without assuming a fixed layout. Any discovered images (e.g. `loss_curve.png`) are copied or referenced in `outputs/train_demo/` for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": { "tags": ["discover_artifacts"] },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "def find_all(patterns):\n",
    "    found = []\n",
    "    for pat in patterns:\n",
    "        found.extend(OUT.glob(pat))\n",
    "        found.extend(OUT.glob(f'**/{pat}'))\n",
    "    # unique preserve order\n",
    "    seen = set(); uniq = []\n",
    "    for p in found:\n",
    "        if p not in seen:\n",
    "            uniq.append(p); seen.add(p)\n",
    "    return uniq\n",
    "\n",
    "loss_imgs = find_all(['loss_curve.png', '*loss*.png'])\n",
    "ckpts = find_all(['*.pt', '*.pth', '*.ckpt'])\n",
    "json_logs = find_all(['*.json', '*.jsonl'])\n",
    "\n",
    "print('Found loss images:')\n",
    "for p in loss_imgs[:5]:\n",
    "    print(' -', p.relative_to(ROOT))\n",
    "print('\\nFound checkpoints:')\n",
    "for p in ckpts[:5]:\n",
    "    print(' -', p.relative_to(ROOT))\n",
    "print('\\nFound logs (json/jsonl):')\n",
    "for p in json_logs[:5]:\n",
    "    print(' -', p.relative_to(ROOT))\n",
    "\n",
    "# Optionally copy the first loss curve into the demo folder for easy viewing\n",
    "if loss_imgs:\n",
    "    try:\n",
    "        target = DEMO / 'loss_curve.png'\n",
    "        shutil.copy2(loss_imgs[0], target)\n",
    "        print('Copied loss curve to', target.relative_to(ROOT))\n",
    "    except Exception as e:\n",
    "        print('[skip copy]', e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display the first loss curve (if found)\n",
    "This is just a convenience visualization for the demo run; the canonical artifact remains where the training script wrote it under `outputs/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": { "tags": ["show_img"] },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "from IPython.display import display\n",
    "\n",
    "img_path = DEMO / 'loss_curve.png'\n",
    "if not img_path.exists() and loss_imgs:\n",
    "    img_path = loss_imgs[0]\n",
    "\n",
    "if img_path.exists():\n",
    "    img = mpimg.imread(str(img_path))\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.title('Loss curve (demo)')\n",
    "    plt.tight_layout(); plt.show()\n",
    "else:\n",
    "    print('No loss curve image found.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Tail the CLI run diary (Markdown) and DVC status\n",
    "Helpful to confirm reproducibility and locate Hydra config snapshots linked to the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": { "tags": ["logs"] },
   "outputs": [],
   "source": [
    "log_md = LOGS / 'v50_debug_log.md'\n",
    "print('CLI journal exists?', log_md.exists(), log_md)\n",
    "if log_md.exists():\n",
    "    try:\n",
    "        tail = '\\n'.join(log_md.read_text(errors='ignore').splitlines()[-60:])\n",
    "        print('\\n--- tail logs/v50_debug_log.md ---\\n' + tail)\n",
    "    except Exception as e:\n",
    "        print('[skip log tail]', e)\n",
    "\n",
    "_run('dvc status')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Persist a `training_report.json`\n",
    "We record what we found so downstream notebooks or dashboards can reference these artifacts directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": { "tags": ["report"] },
   "outputs": [],
   "source": [
    "report = {\n",
    "    'loss_images': [str(p.relative_to(ROOT)) for p in loss_imgs[:10]],\n",
    "    'checkpoints': [str(p.relative_to(ROOT)) for p in ckpts[:10]],\n",
    "    'json_logs': [str(p.relative_to(ROOT)) for p in json_logs[:10]],\n",
    "}\n",
    "with open(DEMO / 'training_report.json', 'w') as f:\n",
    "    json.dump(report, f, indent=2)\n",
    "print('Saved', DEMO / 'training_report.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Next steps / reference CLI commands\n",
    "Use the CLI for real training; scale epochs, switch models/optimizers, and attach diagnostics.\n",
    "\n",
    "```bash\n",
    "# Minimal smoketest (preferred):\n",
    "# spectramind train training.fast_dev_run=true\n",
    "\n",
    "# Short run:\n",
    "# spectramind train training.epochs=5 optimizer=adamw model=v50_default\n",
    "\n",
    "# Resume / checkpoint (example â€” adapt to your layout):\n",
    "# spectramind train training.resume_from=outputs/checkpoints/last.ckpt\n",
    "\n",
    "# After training, run diagnostics and HTML dashboard:\n",
    "# spectramind diagnose dashboard --no-umap=false --no-tsne=false \\\n",
    "#   --out outputs/diagnostics/report.html\n",
    "```\n",
    "\n",
    "**See also**: `04_predict_v50_demo.ipynb` for inference and `05_diagnostics_suite.ipynb` for unified diagnostics."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}