# üõ∞Ô∏è `/configs/data/ARCHITECTURE.md` ‚Äî Data Configuration Architecture (SpectraMind V50)

> **Scope:** Authoritative architecture for **data ingestion ‚Üí calibration ‚Üí preprocessing ‚Üí splitting ‚Üí loading** across **local/HPC**, **Kaggle**, and **CI**.  
> **Guarantees:** Hydra-first composition, DVC/lakeFS traceability, physics-informed defaults, fail-fast validation, Kaggle/CI guardrails.

---

## 0) Purpose & Scope

`/configs/data` transforms **raw telescope signals** ‚Äî **FGS1** photometry (time√óchannels) + **AIRS** spectroscopy (time√ówavelength) ‚Äî into **calibrated, normalized, model-ready** tensors under strict **mission-grade reproducibility**:

- **Deterministic composition** (Hydra snapshots, fixed seeds)
- **Physics-informed calibration** (ADC, nonlinearity, dark, flat, CDS, photometry, trace/phase)
- **Scenario flexibility** (full science / Kaggle / CI smoke / toy synthetic)
- **Auditability** (DVC lineage, config hash, generator manifest, run manifests & artifacts)

---

## 1) Design Principles

- **Hydra-first modularity**  
  Dataset modes are YAML components (`nominal.yaml`, `kaggle.yaml`, `debug.yaml`, `toy.yaml`) composed by higher-level configs (`train.yaml`, `predict.yaml`, `selftest.yaml`) via Hydra `defaults`.
- **Zero hardcoding**  
  Paths, splits, calibration flags, loaders, bin maps live in YAML ‚Äî never in Python.
- **DVC/lakeFS integration**  
  Raw/processed artifacts are DVC-tracked; configs reference tracked paths or environment mounts (`/kaggle/input`).
- **Physics realism**  
  Encodes calibration and symbolic constraints (non-negativity, smoothness, molecular windows). Supports 356‚Üí283 bin remap for decoder compatibility.
- **Environment awareness**  
  Dedicated runtime profiles for **Local/HPC** (`nominal`), **Kaggle** (`kaggle`), **CI** (`debug`), **Synthetic Dev** (`toy`).
- **Mission constraints**  
  Kaggle: ‚â§9 hr walltime, ‚â§16 GB GPU, **no internet**.  
  CI smoke: **<60 s**. Toy: **<3 min**.

---

## 2) Directory Structure

configs/data/
‚îú‚îÄ nominal.yaml       # Full scientific dataset (default for experiments)
‚îú‚îÄ kaggle.yaml        # Kaggle runtime-safe dataset (offline, resource-guarded)
‚îú‚îÄ debug.yaml         # Tiny deterministic slice (CI/self-test)
‚îú‚îÄ toy.yaml           # Synthetic toy dataset (generator-compatible)
‚îú‚îÄ method/
‚îÇ  ‚îú‚îÄ top_level.yaml  # Umbrella method schema (ADC‚Üí‚Ä¶‚Üíphase; contracts/artifacts)
‚îÇ  ‚îî‚îÄ nominal.yaml    # Balanced method profile (binning, detrending, jitter align)
‚îú‚îÄ README.md          # Quick how-to and usage
‚îî‚îÄ ARCHITECTURE.md    # (this document)

**Cross-refs**
- Generator: `configs/dat/ariel_toy_dataset.py` (deterministic `.npz/.npy/.pkl` + `splits/` + `toy_manifest.json`)
- Self-test: `selftest.yaml` calls data=debug and runs validation/preview.

---

## 3) Component Responsibilities

### `nominal.yaml` (Science)
- Full DVC-tracked inputs.
- **Complete** calibration kill-chain (ADC‚ÜíNonlin‚ÜíDark‚ÜíFlat‚ÜíCDS‚ÜíPhotometry‚ÜíTrace/Phase).
- Preprocessing (normalize, detrend polyfit/savgol), symbolic hooks, rich diagnostics.
- Fail-fast gates: schema, remap integrity, split sums, non-negativity, GPU memory.
- Use for experiments & leaderboard‚Äêgrade training.

### `kaggle.yaml` (Competition)
- IO roots: `/kaggle/input/neurips-2025-ariel/`, `/kaggle/working/`, `/kaggle/temp/`.
- Guardrails: `num_workers‚â§2`, `batch_size‚â§64`, **no internet**, lean diagnostics, memmap support.
- Accepts legacy shapes; optional bin remap 356‚Üí283.
- Optimized to finish within **‚â§9 hr**.

### `debug.yaml` (CI/Smoke)
- **5-planet** slice mirroring nominal schema; **deterministic**, minimal I/O, zero augmentation.
- Loader: `batch_size=2`, `num_workers=0`.
- Completes in **seconds**; used by CI/self-test and local smoke.

### `toy.yaml` (Synthetic Dev/CI)
- 64-planet synthetic with `.npz/.npy/.pkl` compatibility, `splits/`, and manifest checks.
- Designed to smoke a **calibrate‚Üítrain‚Üídiagnose‚Üísubmit** loop in **<3 min**.

---

## 4) Data Flow & Calibration Chain

```mermaid
flowchart TD
    A[Raw Inputs<br/>FGS1 (T√óC) + AIRS (T√óŒª)] --> B[Calibration<br/>ADC ‚Ä¢ Nonlin ‚Ä¢ Dark ‚Ä¢ Flat ‚Ä¢ CDS ‚Ä¢ Photometry ‚Ä¢ Trace/Phase]
    B --> C[Preprocessing<br/>Normalize ‚Ä¢ Detrend ‚Ä¢ (Re)sample ‚Ä¢ Remap 356‚Üí283 ‚Ä¢ Clip]
    C --> D[Hydra Dataset Object<br/>data=nominal|kaggle|debug|toy]
    D --> E[Train / Predict / Diagnose]
    E --> F[Artifacts<br/>Œº, œÉ, submission.csv, JSON/PNG/HTML diagnostics]

Calibration steps (method/top_level.yaml ‚Üí method/nominal.yaml overrides)

Step	Key knobs (YAML)	Purpose
adc_correction	bit_depth, gain_map, offset_map	Remove ADC offsets & gain structure
nonlinearity_correction	lut_path, saturation_dn	Correct sensor response nonlinearity
dark_subtraction	master_dark_path, exposure/temperature scaling	Remove dark current
flat_fielding	master_flat_path, epsilon	Correct pixel sensitivity variations
correlated_double_sampling	strategy, noise_threshold_dn, reset_frame_path	Reduce kTC & 1/f noise
photometric_extraction	aperture, radius_px, bkg_annulus_px, method=sum	Extract photometry
trace_normalization	reference_window, epsilon	Normalize per trace
phase_alignment	`method=xcorr	template, max_shift`


‚∏ª

5) Schema, Safety & Integrity Gates

Fail-fast checks:
	‚Ä¢	Schema
FGS1: accept (N, T_fgs1, 32) (legacy (N,32,32) auto-transpose).
AIRS: accept (N, T_airs, 283) or (N, T_airs, 356) ‚Üí remap 356‚Üí283 if instrument.bin_remap.enabled.
	‚Ä¢	Instrument remap
Validates map shape (283,), indices monotonic within source range, no dupes when required.
	‚Ä¢	Numeric safety
Post-preproc ensure œÉ‚àà[min_sigma, max_sigma], Œº within conservative flux bounds, non-negativity where applicable.
	‚Ä¢	Runtime consistency
DVC remote & writable paths (nominal), GPU VRAM floor, Kaggle time budget (kaggle), CI time (debug/toy).
	‚Ä¢	Splits
Fractions sum‚âà1, source splits/*.npy preferred; export mirrors under ${paths.processed_dir}/splits.

‚∏ª

6) Integration Points
	‚Ä¢	Hydra CLI
Swap datasets with data=<nominal|kaggle|debug|toy>:

spectramind train data=kaggle
spectramind diagnose data=nominal diagnostics.fft_analysis=true
spectramind train data=debug training.epochs=1
spectramind train data=toy loader.batch_size=8


	‚Ä¢	Dashboards/Reports
generate_html_report.py embeds data snapshot (paths, method flags, bin map hash, config hash).
	‚Ä¢	Self-Test
selftest.py asserts: paths exist, schema match, remap integrity, non-negativity after preproc, split indices ok.

‚∏ª

7) Runtime Modes ‚Äî Quick Reference

Mode	IO Roots	Target Hardware	Diagnostics	Expected Time
nominal	DVC-tracked local/cluster paths	Local/HPC GPU(s)	Rich	hours
kaggle	/kaggle/input, /kaggle/working	Kaggle P100/T4 (16 GB)	Lean	‚â§ 9 hr
debug	data/debug, outputs/debug	CI/CPU or any	Minimal	< 60 s
toy	data/raw/toy, data/processed	CI/CPU/GPU	Light	< 3 min


‚∏ª

8) Adding a New Dataset Mode (Checklist)
	1.	Copy a template (debug.yaml for small; nominal.yaml for full).
	2.	Set paths to DVC or environment mounts (Kaggle). No ad-hoc absolutes.
	3.	Calibrate/Preprocess: toggle kill-chain steps; pick detrend/smoothing/jitter.
	4.	Schema/Safety: interface.num_bins=283 or provide validated bin_remap.
	5.	Splits/Loader: fractions, seed, batch_size, num_workers per environment.
	6.	Diagnostics: tune to budget (rich ‚Üí research; lean ‚Üí Kaggle/CI).
	7.	Register via Hydra defaults in train.yaml/predict.yaml & verify with:

spectramind train data=<new> validate.fail_fast=true



‚∏ª

9) Common Recipes

Switch detrend method (nominal)

spectramind train data=nominal preprocessing.detrend.method=savgol

Accelerate diagnostics

spectramind diagnose data=nominal diagnostics.fft_analysis=false diagnostics.shap_overlay=false

Kaggle memory safety

spectramind train data=kaggle loader.batch_size=48 runtime.reduce_heavy_ops=true

Run CI smoke in seconds

spectramind train data=debug training.epochs=1

Toy with generator manifest checks

spectramind train data=toy validate.checks=[paths_exist,schema_match,no_nan_inf,manifest_consistency]


‚∏ª

10) DVC Pipeline (Config ‚Üí Stages)

flowchart LR
  A0{{Hydra<br/>data=nominal|kaggle|debug|toy}} --> A1[Compose cfg<br/>configs/data/*.yaml]

  subgraph S0[Versioned Sources (DVC)]
    R1[(raw_fgs1/)]:::dvc --- R2[(raw_airs/)]:::dvc
    R3[(calib_refs/)]:::dvc
  end

  subgraph P0[Data Pipeline (DVC DAG)]
    direction LR
    S1[calibrate]:::stage --> S2[preprocess]:::stage --> S3[split]:::stage --> S4[package_batches]:::stage
  end

  A1 -->|paths, flags| S1
  R1 --> S1
  R2 --> S1
  R3 --> S1

  S1 --> O1[(calibrated/)]:::dvc
  S2 --> O2[(processed/)]:::dvc
  S3 --> O3[(splits/)]:::dvc
  S4 --> O4[(batches/)]:::dvc

  O4 --> T1[[train]]:::cons
  O4 --> P1[[predict]]:::cons
  O4 --> D1[[diagnose]]:::cons

  classDef dvc fill:#e8f5e9,stroke:#2e7d32,color:#1b5e20
  classDef stage fill:#e3f2fd,stroke:#1565c0,color:#0d47a1
  classDef cons fill:#fff3e0,stroke:#ef6c00,color:#e65100

Stage Mapping

Stage	Inputs (DVC)	Hydra-bound parameters (examples)	Outputs (DVC)
calibrate	raw_*, calib_refs/	calibration.* (adc, nonlin, dark, flat, cds, photometry, phase)	calibrated/
preprocess	calibrated/	preprocessing.* (normalize, detrend, align, remap, clip)	processed/
split	processed/	splits.* (strategy, fractions, seed, export)	splits/
package_batches	splits/	loader.*, paths.*, interface.*	batches/

Hydra selection (data=<mode>) parametrizes the same DVC DAG with different IO roots & flags.

‚∏ª

11) Validation Matrix

Check	nominal	kaggle	debug	toy
paths_exist	‚úÖ	‚úÖ	‚úÖ	‚úÖ
schema_match	‚úÖ	‚úÖ	‚úÖ	‚úÖ
bin_remap_ok (356‚Üí283)	‚úÖ	‚úÖ	‚úÖ	‚úÖ
no_nan_inf	‚úÖ	‚úÖ	‚úÖ	‚úÖ
split_indices_ok	‚úÖ	‚úÖ	‚úÖ	‚úÖ
manifest_consistency	‚öôÔ∏è	‚öôÔ∏è	‚öôÔ∏è	‚úÖ
gpu_memory_floor	‚úÖ	‚úÖ	‚Äì	‚Äì
kaggle_time_budget	‚Äì	‚úÖ	‚Äì	‚Äì
ci_time_budget	‚Äì	‚Äì	‚úÖ	‚úÖ

Legend: ‚úÖ enforced ‚Ä¢ ‚öôÔ∏è optional (if manifest present) ‚Ä¢ ‚Äì not applicable

‚∏ª

12) Troubleshooting
	‚Ä¢	Missing file on CI/Kaggle ‚Üí Verify io.fail_on_missing=true and path under expected root (Kaggle: /kaggle/input/...).
	‚Ä¢	Shape mismatch ‚Üí Check schema.accepted_shapes; enable instrument.bin_remap for AIRS 356; auto-transpose legacy FGS1 (N,32,32) if supported.
	‚Ä¢	OOM or slow on Kaggle ‚Üí Lower loader.batch_size, set runtime.reduce_heavy_ops=true, disable heavy diagnostics.
	‚Ä¢	Split drift ‚Üí Prefer generator‚Äôs splits/*.npy; fix splits.seed; export indices for reproducibility.
	‚Ä¢	Non-negativity violation ‚Üí Confirm detrend and normalization order; inspect diagnostics/*_preview.png.

‚∏ª

13) References
	‚Ä¢	SpectraMind V50 Technical Plan ‚Ä¢ Project Analysis ‚Ä¢ Strategy for Updating & Extending V50
	‚Ä¢	Hydra for AI Projects ‚Ä¢ Kaggle Platform Guide ‚Ä¢ Comparison of Kaggle Models

‚∏ª

‚úÖ TL;DR

/configs/data is the flight control module for SpectraMind V50 datasets.
Pick data=<nominal|kaggle|debug|toy> and the pipeline runs with mission-grade, physics-aware, reproducible behavior across local, Kaggle, and CI environments.

