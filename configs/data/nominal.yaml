```yaml
# configs/data/nominal.yaml
# ==============================================================================
# üõ∞Ô∏è SpectraMind V50 ‚Äî Nominal Data Configuration
# NeurIPS 2025 Ariel Data Challenge (ESA Ariel telescope simulation)
#
# Purpose:
#   Define the nominal dataset + calibration setup for standard runs.
#   Includes ESA Ariel‚Äìstyle photometer/spectrometer cubes, preprocessing,
#   calibration kill chain, augmentations, symbolic-aware masking, and DVC tracking.
#
# Hydra:
#   This config is Hydra-composable (part of defaults: in train.yaml).
#   All fields can be overridden via CLI, e.g.:
#     spectramind train data=nominal augmentation.jitter.amplitude_ppm=50
#
# DVC:
#   Paths and outputs are DVC-tracked for reproducibility.
# ==============================================================================

# ----------------------------------------------------------------------
# Hydra defaults (ensures clean composition)
# ----------------------------------------------------------------------
defaults:
  - override hydra/job_logging: default
  - override hydra/hydra_logging: default

# ----------------------------------------------------------------------
# Dataset metadata
# ----------------------------------------------------------------------
dataset:
  name: "nominal_v50"
  description: "Default ESA Ariel Challenge dataset (FGS1 + AIRS) with calibration."
  version: "1.1"
  source: "neurips-2025-ariel"        # Kaggle competition slug
  dvc_stage: "data/nominal"
  dvc_remote: "storage"               # remote DVC target
  cache: "data/cache"
  hash: "${now:%Y%m%d}_${now:%H%M%S}" # run-level DVC hash for traceability

# Optional provenance hooks (filled at runtime by CLI)
provenance:
  git_commit: null
  dvc_rev: null
  created_at: "${now:%Y-%m-%d %H:%M:%S}"

# ----------------------------------------------------------------------
# File paths (DVC-tracked)
# ----------------------------------------------------------------------
paths:
  raw_dir: "data/raw"
  processed_dir: "data/processed/nominal"
  fgs1_file: "${paths.raw_dir}/fgs1_train.npy"     # shape (N_fgs1, 32, 32)
  airs_file: "${paths.raw_dir}/airs_train.npy"     # shape (N_airs, 32, 356)
  labels_file: "${paths.raw_dir}/labels.csv"       # metadata + targets
  test_fgs1: "${paths.raw_dir}/fgs1_test.npy"
  test_airs: "${paths.raw_dir}/airs_test.npy"
  submission_template: "data/sample_submission.csv"

# ----------------------------------------------------------------------
# Instrument & schema expectations (for validation)
# ----------------------------------------------------------------------
schema:
  fgs1:
    expected_rank: 3
    expected_shape: [-1, 32, 32]      # -1 = any (num frames)
    dtype: "float32"
  airs:
    expected_rank: 3
    expected_shape: [-1, 32, 356]
    dtype: "float32"
  labels:
    required_columns: ["planet_id", "split", "target_mu[0:283]", "target_sigma[0:283]"]

# ----------------------------------------------------------------------
# Calibration pipeline (kill chain)
# ----------------------------------------------------------------------
calibration:
  enabled: true
  steps:
    - "adc_correction"
    - "nonlinearity_correction"
    - "dark_subtraction"
    - "flat_fielding"
    - "correlated_double_sampling"
    - "photometric_extraction"
    - "trace_normalization"
    - "phase_alignment"
  save_intermediate: true
  output_dir: "${paths.processed_dir}/calibrated"

# ----------------------------------------------------------------------
# Preprocessing & normalization
# ----------------------------------------------------------------------
preprocessing:
  normalize_flux: true
  standardize_time: true
  clip_outliers: true
  outlier_sigma: 6.0
  detrend:
    enabled: true
    method: "polyfit"                # "polyfit"|"savgol"|"none"
    degree: 2
  smoothing:
    enabled: true
    window: 5
    method: "median"                 # "median"|"gaussian"
  resample_time: false               # preserve original cadence by default

# ----------------------------------------------------------------------
# Augmentation (training robustness)
# ----------------------------------------------------------------------
augmentation:
  jitter:
    enabled: true
    amplitude_ppm: 100
  dropout:
    enabled: true
    prob: 0.01
  mask:
    enabled: true
    scheme: "block"                  # "block"|"random"
    fraction: 0.15
  snr_dropout:
    enabled: true
    snr_threshold: 5.0
  temporal_shift:
    enabled: false
    max_phase_offset: 0.02

# ----------------------------------------------------------------------
# Symbolic & physics-aware constraints
# ----------------------------------------------------------------------
symbolic:
  enforce_nonnegativity: true
  smoothness_penalty: 0.01
  asymmetry_penalty: 0.001
  fft_prior:
    enabled: true
    freq_cutoff: 0.25                # normalized frequency cutoff
    weight: 0.002
  molecular_masking:
    enabled: true
    molecules: ["H2O", "CO2", "CH4"]
    apply_in_preprocessing: true
  temporal_dropout:
    enabled: true
    fraction: 0.1
  region_masking:
    enabled: true
    regions:
      - { name: "AIRS_short_IR", start: 0,   end: 100 }
      - { name: "AIRS_long_IR",  start: 200, end: 356 }
      - { name: "Grav_lens_corr", start: 120, end: 160 }  # gravitational lensing overlay
  corel_uncertainty:
    enabled: true
    weight: 0.005

# ----------------------------------------------------------------------
# Splits
# ----------------------------------------------------------------------
splits:
  train_fraction: 0.8
  val_fraction: 0.1
  test_fraction: 0.1
  stratify: true
  seed: 42
  export_paths:
    indices_dir: "${paths.processed_dir}/splits"   # save split indices for reproducibility

# ----------------------------------------------------------------------
# Loader parameters
# ----------------------------------------------------------------------
loader:
  batch_size: 32
  num_workers: 4
  pin_memory: true
  prefetch_factor: 2
  persistent_workers: true

# ----------------------------------------------------------------------
# Validation & sanity checks
# ----------------------------------------------------------------------
validate:
  enabled: true
  checks:
    - "paths_exist"                  # raw_dir, labels_file present
    - "schema_match"                 # shapes/dtypes align with schema
    - "no_nan_inf"                   # basic numeric hygiene
    - "split_sums_to_one"            # train+val+test fractions sum‚Üí1.0 (¬±1e-6)
    - "stratify_ok"                  # class/planet distribution balanced if stratify
  fail_fast: true
  sample_size_preview: 8

# ----------------------------------------------------------------------
# Diagnostics
# ----------------------------------------------------------------------
diagnostics:
  save_plots: true
  fft_analysis: true
  zscore_analysis: true
  symbolic_overlay: true
  shap_overlay: true
  output_dir: "outputs/diagnostics/data_nominal"
  artifacts:
    stats_json: "${diagnostics.output_dir}/stats.json"
    preview_png: "${diagnostics.output_dir}/preview.png"

# ----------------------------------------------------------------------
# Kaggle/runtime guardrails (data-side toggles)
# ----------------------------------------------------------------------
runtime:
  kaggle_safe: true                  # prefer light-weight I/O & plots
  max_hours: 9
  write_intermediates: true

# ----------------------------------------------------------------------
# Interface hooks (shared across configs)
# ----------------------------------------------------------------------
interface:
  num_bins: 283                      # AIRS spectral bins (used by model/metrics)
  output_dir: "${hydra.run.dir}"     # inherit hydra run dir unless overridden

# ----------------------------------------------------------------------
# Runtime notes
# ----------------------------------------------------------------------
notes: |
  ‚Ä¢ This config defines the *nominal data pipeline* for SpectraMind V50.
  ‚Ä¢ All paths are DVC-tracked; commit pointers ensure reproducibility.
  ‚Ä¢ Symbolic rules applied at data stage enforce physical priors (nonnegativity, smoothness).
  ‚Ä¢ Augmentations simulate spacecraft/system noise (jitter, dropout, SNR masking).
  ‚Ä¢ FFT and molecular overlays provide early diagnostics of constraint compliance.
  ‚Ä¢ Kaggle runtime guardrails: tuned for ‚â§9 hr execution with GPU-safe defaults.
```
