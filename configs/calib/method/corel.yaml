# FILE: configs/calib/method/corel.yaml
# ==============================================================================
# ðŸ§© COREL-Style Learnable Calibration (Graph over Spectral Bins) â€” Mission-Grade
# ------------------------------------------------------------------------------
# Purpose
#   Learn binwise relational corrections or uncertainty scalings by passing
#   (Î¼, Ïƒ, and optional metadata features) through a GNN defined on the spectral
#   bin graph. Supports:
#     â€¢ Graph construction: knn / dense / threshold with optional edge features
#     â€¢ GNN backends: GCN / GAT / MPNN(NNConv) with residuals, norm, attention
#     â€¢ Heads: "scale" (predict T_b for Ïƒ) or "delta" (predict Î”Î¼, Î”Ïƒ or Î”logÏƒ)
#     â€¢ Priors: laplacian smoothness, scale-to-one, Î¼-shift penalties
#     â€¢ COREL/conformal coverage evaluation and optional post-hoc conformalization
#     â€¢ Instrument-aware options (FGS1 emphasis, AIRS region/molecule priors)
#
# Usage
#   Composed by your calibration chain after model inference (pre-submission).
#   Example overrides:
#     spectramind calibrate calib.method.corel.method=corel \
#       corel.model.arch=gat corel.train.epochs=50 corel.graph.k=12
# ==============================================================================

_meta:
  schema_version: "1.1.0"
  last_updated: "${now:%Y-%m-%d}"

method: "corel"

corel:
  # ---------------------------------------------------------------------------
  # Instrument-aware knobs (optional)
  # ---------------------------------------------------------------------------
  instrument:
    fgs1_weight: 58.0                 # emphasize FGS1-calibration when relevant
    use_region_priors: true           # use region/molecule priors if supplied
    molecule_prior_weight: 0.0        # weight in Laplacian/contrastive terms (advanced)

  # ---------------------------------------------------------------------------
  # Graph over bins
  # ---------------------------------------------------------------------------
  graph:
    type: "knn"                        # knn | dense | threshold
    k: 8                               # if type == knn
    threshold: 0.15                    # if type == threshold on distance/similarity
    distance: "l2"                     # l1 | l2 | cosine
    self_loops: true
    normalize_adj: true                # Ã‚ = D^{-1/2}(A+I)D^{-1/2}
    dropout: 0.0

    # Optional edge features to enrich message passing
    edge_features:
      enabled: true
      use_distance: true               # scalar d(i,j) (normalized)
      use_delta_wavelength: true       # |Î»_i - Î»_j|
      use_molecule_same_class: true    # 1 if same molecule class, else 0
      use_detector_same_region: true   # 1 if same detector region, else 0
      # Fourier/sinusoidal encodings of relative index (positional prior)
      posenc:
        enabled: true
        num_freqs: 6
        scale: 1.0

  # ---------------------------------------------------------------------------
  # Node input features
  # ---------------------------------------------------------------------------
  features:
    include:
      mu: true                 # predicted mean Î¼_b
      sigma: true              # predicted Ïƒ_b (pre-calibration)
      wavelength: true         # Î»_b (normalized)
      snr: true                # Î¼_b / Ïƒ_b
      region_onehot: false     # detector region ID â†’ onehot
      molecule_onehot: false   # molecule class â†’ onehot
      posenc_abs: false        # absolute positional encoding for bin index
    normalize: true            # per-feature z-score on train split

  # ---------------------------------------------------------------------------
  # GNN model
  # ---------------------------------------------------------------------------
  model:
    arch: "gat"                # gcn | gat | mpnn
    in_dim: 2                  # executor expands automatically if feats added
    hidden_dim: 64
    num_layers: 3
    activation: "gelu"         # relu | gelu | silu
    residual: true
    norm: "layer"              # batch | layer | none
    dropout: 0.1
    out_head: "scale"          # scale | delta

    # GAT-specific
    heads: 4
    attn_dropout: 0.1

    # MPNN/NNConv-specific
    mpnn:
      edge_mlp_hidden: 32
      agg: "mean"              # mean | sum | max

    # If out_head == "delta", choose parameterization for Ïƒ
    delta_param:
      sigma_space: "log"       # linear | log

  # ---------------------------------------------------------------------------
  # Head semantics
  # ---------------------------------------------------------------------------
  head:
    scale:
      init_to_one: true
      apply_to: "sigma"        # sigma | mu_sigma (future use)
      min_sigma: 1.0e-8
      max_sigma: 1.0e2
      clamp: true
    delta:
      predict_mu: true
      predict_sigma: true
      min_sigma: 1.0e-8
      max_sigma: 1.0e2
      clamp: true

  # ---------------------------------------------------------------------------
  # Optimization
  # ---------------------------------------------------------------------------
  optim:
    name: "adamw"
    lr: 1.0e-3
    weight_decay: 1.0e-4
    betas: [0.9, 0.999]
    eps: 1.0e-8

  sched:
    name: "cosine"             # none | cosine | plateau
    warmup_steps: 200
    min_lr_scale: 0.05
    plateau:
      patience: 5
      factor: 0.5
      min_lr: 1.0e-6

  # ---------------------------------------------------------------------------
  # Training
  # ---------------------------------------------------------------------------
  train:
    epochs: 30
    batch_bins: 283            # process a full spectrum per sample by default
    loss: "nll"                # nll (Gaussian NLL on (Î¼â€™,Ïƒâ€™)) | mse_mu
    label_smoothing: 0.0
    grad_clip: 1.0
    mixed_precision: false
    log_every: 20
    early_stop:
      enabled: true
      monitor: "val_nll"       # val_nll | val_mse_mu | val_coverage
      patience: 8
      mode: "min"

  # ---------------------------------------------------------------------------
  # Regularization / priors
  # ---------------------------------------------------------------------------
  reg:
    t_l2_to_1: 1.0e-3          # encourage Tâ‰ˆ1 (scale head)
    mu_delta_l2: 0.0           # penalize large Î¼ shifts (delta head)
    # Laplacian smoothness across neighboring bins (graph prior)
    laplacian_smooth:
      enabled: true
      weight: 1.0e-3
      apply_to: "mu_sigma"     # mu | sigma | mu_sigma | scale_T
    # Contrastive prior (optional): push dissimilar molecules apart (advanced)
    contrastive:
      enabled: false
      weight: 0.0
      margin: 0.0
    # Soft floor to keep Ïƒâ€™ above stability threshold
    min_sigma: 1.0e-8

  # ---------------------------------------------------------------------------
  # Conformal / COREL evaluation (optional post-hoc coverage control)
  # ---------------------------------------------------------------------------
  conformal:
    enabled: true
    method: "split"            # split | cv_plus
    alpha: 0.1                 # (1 - coverage); e.g., 0.1 â†’ 90% nominal coverage
    mondrian_by: "molecule"    # none | molecule | region
    use_val_split: true        # use internal val split for calibration
    export_intervals: false    # optionally write conformal Î¼Â±q_b Ïƒ for reporting

  # ---------------------------------------------------------------------------
  # Checkpointing
  # ---------------------------------------------------------------------------
  ckpt:
    dir: "${oc.env:RUN_DIR, runs}/corel_ckpts"
    keep_last: 3
    save_best_on: "val_nll"    # val_nll | val_mse_mu | val_coverage
    filename: "corel-{epoch:03d}-{val_nll:.5f}.pt"

  # ---------------------------------------------------------------------------
  # Evaluation / metrics
  # ---------------------------------------------------------------------------
  eval:
    metrics:
      - "val_nll"
      - "val_mse_mu"
      - "coverage_68"
      - "coverage_95"
      - "calib_curve"
      - "ece_sigma"             # expected calibration error for Ïƒ
    calib_curve:
      quantiles: [0.1, 0.2, 0.5, 0.8, 0.9]

  # ---------------------------------------------------------------------------
  # IO binding (Hydra/pipeline executor contracts)
  # ---------------------------------------------------------------------------
  io:
    input_key: "inference"      # dict containing model predictions & metadata
    fields_in:
      mu: "mu_pred"             # [B, C=283]
      sigma: "sigma_pred"       # [B, C=283]
      y_true: "y_true"          # [B, C] (optional; required for training/eval)
      wavelength: "wavelengths" # [C] (optional)
      molecule_id: "molecule_id"# [C] ints (optional)
      region_id: "region_id"    # [C] ints (optional)
      split: "split"            # "train"/"val"/"test" (optional)
    output_key: "corel"
    fields_out:
      mu_cal: "mu_corel"        # calibrated Î¼â€™ (delta head) or copy of Î¼ (scale head)
      sigma_cal: "sigma_corel"  # calibrated Ïƒâ€™ (or T*Ïƒ)
      scale_T: "scale_T"        # predicted T (scale head)
      metrics: "corel_metrics"  # dict of eval metrics
      coverage: "corel_coverage"# dict of coverage stats

  # ---------------------------------------------------------------------------
  # Data split / loader (lightweight; executor may override)
  # ---------------------------------------------------------------------------
  data:
    make_split:
      enabled: true
      val_fraction: 0.2
      seed: 1337
    shuffle_train: true

  # ---------------------------------------------------------------------------
  # Runtime & logging
  # ---------------------------------------------------------------------------
  runtime:
    device: "auto"              # auto | cpu | cuda:0
    num_workers: 2
    deterministic: false
    seed: 1337

  logging:
    level: "INFO"               # DEBUG | INFO | WARNING | ERROR
    log_graph_stats: true
    log_samples: 2
    tensorboard:
      enabled: false
      dir: "${oc.env:RUN_DIR, runs}/corel_tb"

  # ---------------------------------------------------------------------------
  # Validation (fail fast for missing/incompatible resources)
  # ---------------------------------------------------------------------------
  validation:
    require_y_true_for_training: true
    check_shape_compatibility: true
    require_graph_nonempty: true
    assert_sigma_floor: true

  # ---------------------------------------------------------------------------
  # Profile-specific overrides
  # ---------------------------------------------------------------------------
  profile_overrides:
    fast:
      model.arch: "gcn"
      model.hidden_dim: 32
      train.epochs: 10
      reg.laplacian_smooth.weight: 5.0e-4
      conformal.enabled: false
      logging.log_graph_stats: false
    strict:
      model.arch: "mpnn"
      graph.edge_features.enabled: true
      model.hidden_dim: 96
      model.num_layers: 4
      train.epochs: 60
      train.mixed_precision: true
      reg.laplacian_smooth.weight: 2.0e-3
      conformal.enabled: true
      conformal.method: "cv_plus"

  notes: |
    â€¢ Prefer "scale" head initiallyâ€”learn per-bin T to recalibrate Ïƒ_b and improve NLL/coverage
      without perturbing Î¼. Switch to "delta" when systematic Î¼ biases remain after upstream fixes.
    â€¢ Enable edge features and MPNN to share information across physically related bins (molecule,
      detector region, Î”Î»). Laplacian smoothness regularizes noisy corrections.
    â€¢ Conformal block can report empirical coverage and optionally export post-hoc intervals for audits.
    â€¢ Use profile_overrides.fast/strict to trade runtime vs accuracy in CI/Kaggle settings.