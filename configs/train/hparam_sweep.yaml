# =====================================================================
# SpectraMind V50 â€” Hyperparameter Sweep (Optuna)
# ---------------------------------------------------------------------
# Requires: pip/poetry install hydra-optuna-sweeper
# Example:
#   poetry run spectramind train train=hparam_sweep_optuna -m
# =====================================================================

defaults:
  - model: mlp
  - data: toy
  - override hydra/job_logging: default
  - override hydra/hydra_logging: default
  - override hydra/sweeper: optuna

train:
  epochs: 8
  device: "cpu"
  seed: 1337
  log_interval: 10
  save_dir: "outputs/checkpoints_optuna"

optimizer:
  name: "adamw"
  lr: 1e-3
  weight_decay: 1e-4
  betas: [0.9, 0.999]
  eps: 1e-8

scheduler:
  name: "cosine"
  warmup_steps: 50
  min_lr_scale: 0.05

# ---- Hydra/Optuna configuration ---------------------------------------------
hydra:
  run:
    dir: outputs/train/${now:%Y%m%d_%H%M%S}
  sweep:
    dir: outputs/train/optuna
    subdir: ${hydra.job.num}
  sweeper:
    direction: minimize                # your train loop should report/return a scalar loss/metric
    study_name: spectramind_v50_optuna
    n_trials: 20
    sampler:
      _target_: optuna.samplers.TPESampler
      seed: 1337
    params:
      # Continuous/log domains
      optimizer.lr:
        distribution: loguniform
        low: 1e-5
        high: 3e-3
      optimizer.weight_decay:
        distribution: loguniform
        low: 1e-6
        high: 1e-2
      # Discrete choices
      data.batch_size:
        distribution: categorical
        choices: [8, 16, 32, 64]
      # Model choice as categorical (switches defaults/model/*)
      model:
        distribution: categorical
        choices: [mlp, transformer]