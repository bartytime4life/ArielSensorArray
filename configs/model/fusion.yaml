# configs/model/fusion.yaml
# ==============================================================================
# ðŸ”— Fusion â€” Cross-Modal Fusion between FGS1 (SSM latent) and AIRS (GNN latent)
# Swap via CLI: model/fusion={concat|cross_attention|gated_sum}
# ==============================================================================

fusion:
  # --------------------------------------------------------------------------
  # Core Method & Capacity
  # --------------------------------------------------------------------------
  method: "cross_attention"           # cross_attention | concat | gated_sum
  hidden_dim: 256
  num_heads: 4
  num_layers: 2                       # stack multiple x-attn blocks for capacity
  bidirectional: true                 # if true: do FGS1â†’AIRS and AIRSâ†’FGS1
  dropout: 0.10
  attn_dropout: 0.05
  normalize: true                     # pre/post LayerNorm inside fusion blocks
  residual: true
  init: "xavier_uniform"

  # Optional gating on residual/fused output
  gating:
    enabled: true
    type: "sigmoid"                   # sigmoid | tanh | softplus
    init_bias: 0.0

  # --------------------------------------------------------------------------
  # Cross-Modal Alignment & Position Encoding
  # --------------------------------------------------------------------------
  # Fourier PE can assist cross-modal alignment; learnable scale for flexibility
  position_encoding:
    type: "fourier"                   # fourier | none
    learnable_scale: true

  # Alignment between temporal and spectral spaces
  alignment:
    strategy: "project_and_pool"      # project_and_pool | mean_pool | none
    fgs1_pool: "mean"                 # how to reduce FGS1 time latents to token(s)
    airs_pool: "none"                 # usually keep all AIRS tokens for attention
    temporal_window: 256              # if windowed pooling is needed

  masking:
    enabled: true                     # masks invalid/padded timesteps or bins

  # Exportables for diagnostics and XAI
  export_attention: true              # save cross-attn maps
  save_fused_latents: true

  # --------------------------------------------------------------------------
  # Physics- & Symbolic-Aware Fusion Regularizers
  # (small penalties to keep fused rep physically plausible and stable)
  # --------------------------------------------------------------------------
  regularizers:
    spectral_smoothness_weight: 0.005
    temporal_smoothness_weight: 0.0005
    cross_modality_consistency_weight: 0.010   # encourage coherent features
    band_preservation_weight: 0.020            # preserve known molecular bands

  # --------------------------------------------------------------------------
  # Optional Auxiliary Alignment Losses (gentle co-regularization)
  # --------------------------------------------------------------------------
  alignment_losses:
    nce:
      enabled: true
      temperature: 0.07              # InfoNCE temperature
      weight: 0.02
    cca:
      enabled: false
      weight: 0.00

  # --------------------------------------------------------------------------
  # Fallback / Lightweight Alternatives
  # --------------------------------------------------------------------------
  concat:
    proj_dim: 256
    dropout: 0.10
    residual: true
    normalize: true

  gated_sum:
    proj_dim: 256
    gate_bias: 0.0
    dropout: 0.10
    residual: true
    normalize: true

  # --------------------------------------------------------------------------
  # Precision, Budget & Runtime Guardrails
  # --------------------------------------------------------------------------
  precision:
    amp_allowed: true                # enable mixed precision in fusion block

  param_budget:
    enabled: true
    max_params: 1.5e7                # hard cap for fusion subgraph (Kaggle-safe)

  # JIT/TS exports and Kaggle safety flags
  jit: true
  torchscript: true
  kaggle_safe: true

  # --------------------------------------------------------------------------
  # Notes
  # --------------------------------------------------------------------------
  notes: |
    â€¢ Cross-attention exposes AIRS nodes to FGS1 temporal context (and vice versa when bidirectional=true).
    â€¢ Use alignment_losses.nce to gently co-regularize latent spaces; keep weights small (â‰¤2e-2).
    â€¢ For speed-sensitive runs: method=concat, num_layers=1, num_heads=2, hidden_dim=128.
    â€¢ regularizers preserve physics plausibility while remaining secondary to main likelihood/objectives.
