# ==============================================================================
# ðŸš€ Kaggle Devices â€” NVIDIA L4 GPU (SpectraMind V50)
# ------------------------------------------------------------------------------
# Purpose:
#   â€¢ Kaggle experimental GPU runtime (L4, 24 GB, Ada Lovelace architecture).
#   â€¢ Configures AMP and runtime guardrails for â‰¤ 9-hour Kaggle walltime.
#   â€¢ Reproducible and leaderboard-safe by default.
#
# Usage:
#   spectramind train local=devices/kaggle_l4 trainer=kaggle_safe
#
# Notes:
#   â€¢ Kaggle kernels run offline â€” no internet, datasets must be pre-attached.
#   â€¢ L4 GPUs (Ada Lovelace) handle AMP (16-mixed) efficiently with larger memory (24 GB).
#   â€¢ Runtime capped at 9h for leaderboard compliance.
# ==============================================================================

_target_: torch.device

# Device orchestration
devices: 1                   # Kaggle provides one L4 GPU per runtime
autodetect: false            # fixed: Kaggle always provisions 1 GPU

# Precision / numerical stability
precision: 16-mixed          # default AMP; override to bf16-mixed/32 via CLI if needed
deterministic: true          # enforce deterministic ops for reproducibility
cudnn_benchmark: true        # enable cuDNN autotune (safe with static Kaggle inputs)

# Reproducibility guardrails
seed: 2025
numpy_seed: 2025
pythonhashseed: 0

# Threading controls (Kaggle: ~2 vCPUs typical)
max_threads: 2
intraop_threads: 2
interop_threads: 1

# Runtime guardrails
timeout_hours: 9             # Kaggle walltime hard cap
gradient_clip_val: 1.0       # stabilize training on small/medium batch sizes

# Diagnostics
log_device_info: true        # log CUDA device properties on startup
profile_runtime: false        # disable by default to conserve 9h runtime

# Metadata
notes: |
  Kaggle L4 device profile (24 GB Ada Lovelace GPU).
  - Designed for competition inference & training within Kaggleâ€™s runtime sandbox.
  - AMP (16-mixed) precision by default for efficiency.
  - Deterministic kernels with fixed seeds ensure reproducibility.
  - Threads capped to Kaggleâ€™s vCPU limits.
  - Logs device and runtime info at startup for audit trails.
