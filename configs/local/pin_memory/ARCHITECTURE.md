Hereâ€™s the **full set of upgraded files for `/configs/local/pin_memory/`**, built in the same style as your `precision/`, `num_workers/`, and `cudnn_benchmark/` configs:

---

### `configs/local/pin_memory/enabled.yaml`

```yaml
# ==============================================================================
# ðŸ“Œ Pin Memory â€” Enabled
# ------------------------------------------------------------------------------
# Purpose:
#   â€¢ Enable page-locked (pinned) host memory in DataLoader.
#   â€¢ Speeds up hostâ†’GPU transfers by avoiding OS paging overhead.
# ------------------------------------------------------------------------------
# When to Use
#   â€¢ âœ… GPU training/inference (especially large batches).
#   â€¢ âš ï¸ Not needed on CPU-only runs (ignored).
# ==============================================================================

pin_memory: true

notes: |
  Pin memory enabled:
  â€¢ Faster transfers from host (CPU) to device (GPU).
  â€¢ Recommended for most Kaggle/HPC GPU runs.
  â€¢ Slightly higher host RAM usage; avoid if memory is tight.
```

---

### `configs/local/pin_memory/disabled.yaml`

```yaml
# ==============================================================================
# ðŸ“Œ Pin Memory â€” Disabled
# ------------------------------------------------------------------------------
# Purpose:
#   â€¢ Use regular pageable host memory.
#   â€¢ Lower RAM footprint; deterministic and safe for debugging.
# ------------------------------------------------------------------------------
# When to Use
#   â€¢ âœ… CPU-only runs (no effect).
#   â€¢ âœ… Low-RAM environments (avoid extra pinned allocations).
# ==============================================================================

pin_memory: false

notes: |
  Pin memory disabled:
  â€¢ Safer in memory-constrained or CPU-only environments.
  â€¢ Slightly slower GPU data transfers, but reproducible.
  â€¢ Good default for CI or audit/debug runs.
```

---

### `configs/local/pin_memory/ARCHITECTURE.md`

````markdown
# ðŸ“‚ `configs/local/pin_memory/` â€” Pin Memory Profiles

## Purpose
Control whether PyTorch DataLoaders use **pinned host memory** for batch tensors.  
Pinned memory speeds up hostâ†’GPU transfer but uses more RAM.

## Profiles
- **`enabled.yaml`** â€” Enables pinning (best for GPU training/inference).
- **`disabled.yaml`** â€” Disables pinning (best for CPU, CI, or low-RAM).

## Usage
In your main config (e.g. `configs/train.yaml`):

```yaml
defaults:
  - local/pin_memory: enabled   # or disabled
````

Or via CLI override:

```bash
spectramind train local/pin_memory=enabled
```

## Rule of Thumb

| Environment                 | Recommendation                   |
| --------------------------- | -------------------------------- |
| Kaggle GPU (T4/A10/L4/A100) | `enabled` (faster transfers)     |
| HPC GPU Cluster             | `enabled` (8â€“16 workers benefit) |
| CPU-only                    | `disabled` (no effect)           |
| CI / Debugging              | `disabled` (safe + reproducible) |
| Memory constrained          | `disabled`                       |

## Notes

* Pinning can increase host RAM usage; disable if memory is limited.
* On GPUs, pinned memory usually improves throughput, especially with larger batch sizes.
* Combine with `num_workers` > 0 for best performance (workers prefetch into pinned buffers).

```

