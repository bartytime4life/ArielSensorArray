# ==============================================================================
# ðŸ§  Prefetch Factor â€” Heavy Pipeline / HPC
# ------------------------------------------------------------------------------
# Purpose:
#   â€¢ Maximize data-loading throughput for multi-GPU HPC or local SSD RAID setups.
#   â€¢ Designed for nodes with abundant system memory (â‰¥128 GB) and very fast I/O.
#   â€¢ Ensures GPUs are saturated with data even in large-scale distributed runs.
# ==============================================================================

prefetch_factor: 8               # each worker preloads 8 batches in advance
persistent_workers: true         # keep workers alive across epochs for efficiency
pin_memory: true                 # lock host memory for faster GPU transfer

notes: |
  Heavy mode:
  â€¢ Each DataLoader worker preloads 8 batches, minimizing GPU idle cycles.
  â€¢ Ideal for HPC clusters, multi-GPU servers, or local rigs with NVMe RAID.
  â€¢ Requires substantial host RAM; each worker may hold 8Ã—batch_size in memory.
  â€¢ Not recommended for Kaggle kernels or small-memory nodes (risk of OOM).
  â€¢ Best paired with large batch sizes and mixed precision (AMP) to maximize throughput.
  â€¢ Use when throughput is the bottleneck, not memory, and system resources are abundant.
