# ==============================================================================
# ðŸ›°ï¸ SpectraMind V50 â€” Gradient Accumulation (TRAINING)
# ------------------------------------------------------------------------------
# Purpose:
#   â€¢ Control how many forward/backward passes to accumulate before an optimizer step.
#   â€¢ Enables training with an effectively larger batch size than physically fits in GPU memory.
#   â€¢ Core knob for scaling stability/throughput under Kaggle (â‰¤9h) and HPC GPU limits.
# ------------------------------------------------------------------------------
# When to Use
#   â€¢ âœ… Set >1 if:
#       â€“ Model/batch does not fit in GPU memory directly.
#       â€“ You want to simulate larger global batch size for smoother updates.
#   â€¢ ðŸš« Keep =1 if GPU memory is sufficient for the desired batch size.
#   â€¢ âš ï¸ Effective batch size = batch_size Ã— accumulate_grad_batches.
#       Adjust learning rate using the linear scaling rule when increasing this factor.
# ==============================================================================

accumulate_grad_batches: 1

notes: |
  Training loaders:
  â€¢ Default =1 (no accumulation; optimizer updates every batch).
  â€¢ Use >1 to simulate large-batch training on limited-memory GPUs:
      â€“ Example: batch_size=32, accumulate_grad_batches=4 â†’ effective batch=128.
  â€¢ LR scaling guideline: scale learning rate proportionally with accumulate_grad_batches.
  â€¢ Mission-grade considerations:
      â€“ Log accumulation factor in v50_debug_log.md with config hash for reproducibility.
      â€“ Monitor wall-clock runtime: accumulation reduces memory but may increase step time.
  â€¢ Kaggle environments:
      â€“ T4/A10 GPUs often require accumulation to reach target effective batch sizes.
      â€“ Must balance runtime (â‰¤9h) vs. stability.
  â€¢ HPC environments:
      â€“ With A100/H100 GPUs and large RAM, may keep =1 unless intentionally scaling up.
      â€“ For multi-GPU distributed training, ensure accumulation interacts correctly with DDP.
  â€¢ Debug/CI:
      â€“ Always keep =1 for smoke tests and pipeline verification to minimize variance.
