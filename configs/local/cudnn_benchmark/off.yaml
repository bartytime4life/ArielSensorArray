# ==============================================================================
# üö´ cuDNN Autotune ‚Äî Disabled (v1.2)
# ------------------------------------------------------------------------------
# Purpose
#   ‚Ä¢ Enforce deterministic kernel execution (no autotune search).
#   ‚Ä¢ Prioritize reproducibility and auditability over raw speed.
#   ‚Ä¢ Useful for debugging, CI validation, and scientific diagnostics.
# ------------------------------------------------------------------------------
# Trade-offs
#   ‚Ä¢ ‚úÖ Reproducibility: Kernel choices are fixed ‚Üí run-to-run bitwise stability.
#   ‚Ä¢ ‚úÖ Debugging: Easier to compare across hardware/driver versions.
#   ‚Ä¢ ‚ùå Performance: Throughput is reduced, especially if input shapes vary.
#   ‚Ä¢ ‚ùå Not recommended for leaderboard-scale training due to runtime cost.
# ==============================================================================
cudnn_benchmark: false

# ------------------------------------------------------------------------------
# Extended Controls (optional)
# ------------------------------------------------------------------------------
# deterministic: true        # ensure all torch/cuDNN kernels use deterministic paths
# allow_tf32: false          # (Ampere+) force-disable TensorFloat32 for strict FP32
# torch_compile_deterministic: true   # (PyTorch ‚â•2.2) enforce compile-time determinism

# ------------------------------------------------------------------------------
# üìì Notes
# ------------------------------------------------------------------------------
notes: |
  cuDNN autotuner disabled ‚Üí fixed kernel selection.
  
  ‚Ä¢ Guarantees reproducible results across runs, GPUs, and driver versions.
  ‚Ä¢ Best for: CI pipelines, ablations, symbolic diagnostics, or reproducibility audits.
  ‚Ä¢ Expect slower training when input shapes are constant (benchmarking skipped).
  ‚Ä¢ Combine with `local/precision/strict_deterministic.yaml` for full audit mode.

  ‚úÖ Recommended: CI, audits, scientific debugging
  ‚ùå Avoid: Kaggle leaderboard runs, long training with static shapes
