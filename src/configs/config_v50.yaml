# configs/config_v50.yaml
# SpectraMind V50 — Unified Hydra config (NeurIPS 2025 Ariel Data Challenge)
# ---------------------------------------------------------------------------
# This is the single source-of-truth config used by:
#   • src/train_v50.py
#   • src/predict_v50.py
#   • CLI wrappers (spectramind.py) for train / diagnose / submit
#
# Philosophy:
#   - Minimal but complete defaults (run out-of-the-box with synthetic data)
#   - Every knob has a documented purpose and sane default
#   - Groups kept inline for a single-file handoff; split into folders if preferred
# ---------------------------------------------------------------------------

# -----------------------------
# Runtime
# -----------------------------
runtime:
  out_dir: outputs/${now:%Y%m%d_%H%M%S}
  seed: 1337
  cuda: true
  amp: true                   # autocast in train/predict
  bundle_zip: true            # zip minimal artifacts at end of run
  log_level: INFO
  weights: outputs/checkpoints/best.pt   # used by predict_v50.py

# -----------------------------
# Data
# -----------------------------
data:
  # Manifest-driven dataset (see src/data/loaders.py)
  manifest: data/manifest.csv
  cache_dir: .cache/preprocessed
  dtype: float32
  max_time: null              # truncate time dimension if set (e.g. 8192)
  split_names: {train: train, val: val, test: test}

  preprocess:
    detrend: true             # wavelength-wise median subtraction
    normalize: true           # per-channel (zero-mean, unit-var)
    eps: 1.0e-6

  # Inference view splits for predict_v50 (used by PairedDataset)
  id_col: id
  delimiter: ","
  # If you generate per-view CSVs, you can still use predict_v50 by mapping columns here:
  fgs1_cols: [f0, f1, f2, f3]               # example placeholder; replace with your columns
  airs_cols: [a0, a1, a2, a3, a4, a5, a6]   # example placeholder

# -----------------------------
# Model
# -----------------------------
model:

  # ---- FGS1 — Mamba SSM encoder (src/models/fgs1_mamba.py)
  fgs1:
    in_dim: 64
    d_model: 256
    n_layers: 6
    dropout: 0.10
    conv_kernel: 5
    ssm_rank: 1
    bidirectional: false
    return_sequence: false
    pool: mean            # mean | last | cls

  # ---- AIRS — Spectral GNN encoder (src/models/airs_gnn.py)
  airs:
    in_features: 8
    hidden: 128
    gcn_layers: 4
    gcn_dropout: 0.10
    mlp_hidden: 128
    mlp_dropout: 0.10
    k_adj: 1
    smooth_lambda: 1.0e-3
    nonneg_lambda: 1.0e-3
    group_lambda: 5.0e-4
    min_log_sigma: -7.0
    max_log_sigma: 3.0

  # ---- Multi-scale decoder (src/models/multi_scale_decoder.py)
  decoder:
    num_wavelengths: 283
    in_dims: [256, 128, 256]  # (fgs1, airs, fusion/aux) — adjust to actual fusion ordering
    hidden: 512
    dropout: 0.10
    out_mode: gaussian        # gaussian | quantile
    quantiles: [0.1, 0.5, 0.9]
    temporal_pool: attn       # mean | max | attn
    use_laplacian_refine: true
    laplacian_alpha: 0.10
    laplacian_iters: 3
    laplacian_lambda: 1.0e-3
    physics_nonneg: true
    physics_sigmoid_range: null   # e.g. [0.0, 1.0] if you want bounded outputs

# -----------------------------
# Loss (neuro‑symbolic composite)
# -----------------------------
loss:
  reduction: mean
  gll:
    weight: 1.0
    sigma_min: 1.0e-6
    sigma_scale: 1.0
  smooth:
    enable_fd2: true
    fd2_weight: 1.0e-3
    enable_fft: false
    fft_weight: 0.0
    fft_cutoff_ratio: 0.5
    fft_power: 2.0
  nonneg:
    enable: false
    weight: 1.0e-4
    p: 2.0
  asym:
    enable: false
    weight: 0.0
    p: 2.0

# -----------------------------
# Training
# -----------------------------
training:
  epochs: 50
  lr: 1.0e-3
  weight_decay: 1.0e-4
  batch_size: 64
  grad_clip_norm: 1.0
  cosine_lr: true
  early_stopping_patience: 8
  deterministic: {enable: true, seed: ${runtime.seed}}
  save_best: true

  data_loader:
    train: {batch_size: ${training.batch_size}, shuffle: true,  num_workers: 4, pin_memory: true, persistent_workers: true, drop_last: true}
    val:   {batch_size: ${training.batch_size}, shuffle: false, num_workers: 4, pin_memory: true, persistent_workers: true, drop_last: false}
    test:  {batch_size: ${training.batch_size}, shuffle: false, num_workers: 4, pin_memory: true, persistent_workers: true, drop_last: false}

# -----------------------------
# Calibration (post-hoc / predict-time)
# -----------------------------
calibration:
  temperature: 1.0          # global σ scale at predict-time (1.0 = no-op)
  corel:
    enable: false           # set true if you have COREL implemented & wired
    # ... corel-specific params here ...

# -----------------------------
# Outputs
# -----------------------------
outputs:
  submission_dir: outputs/submission
  submission_filename: submission.csv
  format: wide               # wide | long   (see predict_v50._write_submission)

# -----------------------------
# MLflow (optional)
# -----------------------------
mlflow:
  enable: false
  tracking_uri: file:./mlruns
  experiment: SpectraMindV50
  run_name: null

# -----------------------------
# Diagnostics (optional hooks)
# -----------------------------
diagnostics:
  save_loss_curve: true
  preview_spectra: 5
  save_preview_paths: true