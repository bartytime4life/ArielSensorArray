==============================================================================

SpectraMind V50 — Local Developer Makefile

Neuro‑Symbolic, Physics‑Informed AI Pipeline (Dev Workflows)



Goals:

• CLI‑first (routes through spectramind)

• Hydra overrides via OVERRIDES

• DVC data sync helpers

• Benchmarks + Kaggle parity helpers

• Rich dev ergonomics (fmt/lint/test/analyze)

==============================================================================

========= Shell =========

SHELL         := /usr/bin/env bash
.ONESHELL:
.SHELLFLAGS   := -euo pipefail -c

========= Tooling =========

PYTHON        ?= python3
POETRY        ?= poetry
CLI           ?= $(POETRY) run spectramind

========= Defaults (override with make VAR=value) =========

DEVICE        ?= cpu               # cpu|gpu|auto (if supported)
EPOCHS        ?= 1
TS            := $(shell date +%Y%m%d_%H%M%S)

OUT_DIR       ?= outputs
LOGS_DIR      ?= logs
DIAG_DIR      ?= $(OUT_DIR)/diagnostics
PRED_DIR      ?= $(OUT_DIR)/predictions
SUBMIT_DIR    ?= $(OUT_DIR)/submission
SUBMIT_ZIP    ?= $(SUBMIT_DIR)/bundle.zip

OVERRIDES     ?=
EXTRA_ARGS    ?=

========= PHONY =========

.PHONY: help init env info 
fmt lint test 
selftest selftest-deep 
calibrate calibrate-temp corel-train 
train predict diagnose ablate submit 
analyze-log check-cli-map 
dvc-pull dvc-push 
benchmark benchmark-cpu benchmark-gpu benchmark-run benchmark-report benchmark-clean bench-selftest 
kaggle-run kaggle-submit 
clean realclean

========= Help =========

help:
@echo “SpectraMind V50 — Local Dev Targets”
@echo “  make selftest            # fast integrity check”
@echo “  make train               # train model”
@echo “  make predict             # inference → $(PRED_DIR)”
@echo “  make diagnose            # diagnostics dashboard”
@echo “  make submit              # package submission as zip”
@echo “  make benchmark           # simulate Kaggle-like run”
@echo “  make kaggle-run          # convenience: 1-epoch GPU run in Kaggle”
@echo “  make kaggle-submit       # submit current CSV to Kaggle competition”
@echo “  make fmt | lint | test   # developer ergonomics”
@echo “  make dvc-pull|dvc-push   # DVC artifact sync”
@echo “  make clean|realclean     # cleanup artifacts & caches”

========= Init =========

init: env
env:
mkdir -p “$(OUT_DIR)” “$(LOGS_DIR)” “$(DIAG_DIR)” “$(PRED_DIR)” “$(SUBMIT_DIR)”

info:
@echo “python  : $$($(PYTHON) –version 2>&1)”
@echo “poetry  : $$($(POETRY) –version 2>&1 || true)”
@echo “cli     : $(CLI)”
@echo “device  : $(DEVICE)”

========= Dev / Quality =========

fmt:
@echo “>>> Formatting with isort + black”
$(POETRY) run isort .
$(POETRY) run black .

lint:
@echo “>>> Linting with ruff”
$(POETRY) run ruff check .

test: init
@echo “>>> Running pytest”
$(POETRY) run pytest -q || $(POETRY) run pytest -q -x
@echo “>>> Tests complete”

========= Pipeline =========

selftest: init
@echo “>>> Selftest (fast)”
$(CLI) selftest

selftest-deep: init
@echo “>>> Selftest (deep)”
$(CLI) selftest –deep

calibrate: init
@echo “>>> Calibrate”
$(CLI) calibrate $(OVERRIDES) $(EXTRA_ARGS)

calibrate-temp: init
@echo “>>> Temperature scaling”
$(CLI) calibrate-temp $(OVERRIDES) $(EXTRA_ARGS)

corel-train: init
@echo “>>> COREL conformal training”
$(CLI) corel-train $(OVERRIDES) $(EXTRA_ARGS)

train: init
@echo “>>> Train”
@echo “    DEVICE    : $(DEVICE)”
@echo “    EPOCHS    : $(EPOCHS)”
@echo “    OVERRIDES : $(OVERRIDES)”
$(CLI) train +training.epochs=$(EPOCHS) $(OVERRIDES) –device $(DEVICE) $(EXTRA_ARGS)

predict: init
@echo “>>> Predict”
mkdir -p “$(PRED_DIR)”
$(CLI) predict –out-csv “$(PRED_DIR)/submission.csv” $(OVERRIDES) $(EXTRA_ARGS)
@echo “>>> Wrote $(PRED_DIR)/submission.csv”

diagnose: init
@echo “>>> Diagnostics — smoothness + dashboard”
$(CLI) diagnose smoothness –outdir “$(DIAG_DIR)” $(EXTRA_ARGS)
$(CLI) diagnose dashboard –outdir “$(DIAG_DIR)” $(EXTRA_ARGS) || true

ablate: init
@echo “>>> Ablations”
$(CLI) ablate $(OVERRIDES) $(EXTRA_ARGS)

submit: init
@echo “>>> Submission packaging”
mkdir -p “$(SUBMIT_DIR)”
$(CLI) submit –zip-out “$(SUBMIT_ZIP)” $(EXTRA_ARGS)
@echo “>>> Submission bundle → $(SUBMIT_ZIP)”

analyze-log: init
@echo “>>> Analyze CLI debug log”
$(CLI) analyze-log –md “$(OUT_DIR)/log_table.md” –csv “$(OUT_DIR)/log_table.csv” $(EXTRA_ARGS)
@echo “>>> Reports: $(OUT_DIR)/log_table.md, $(OUT_DIR)/log_table.csv)”

check-cli-map:
@echo “>>> Check CLI command-to-file mapping”
$(CLI) check-cli-map $(EXTRA_ARGS)

========= DVC =========

dvc-pull:
@echo “>>> DVC pull”
dvc pull || true

dvc-push:
@echo “>>> DVC push”
dvc push || true

========= Benchmarks =========

bench-selftest:
@echo “>>> Pipeline selftest (fast)…”
$(CLI) selftest –fast

benchmark: bench-selftest
@$(MAKE) –no-print-directory benchmark-run DEVICE=$(DEVICE) EPOCHS=$(EPOCHS) OVERRIDES=’$(OVERRIDES)’ EXTRA_ARGS=’$(EXTRA_ARGS)’

benchmark-cpu: bench-selftest
@$(MAKE) –no-print-directory benchmark-run DEVICE=cpu EPOCHS=$(EPOCHS) OVERRIDES=’$(OVERRIDES)’ EXTRA_ARGS=’$(EXTRA_ARGS)’

benchmark-gpu: bench-selftest
@$(MAKE) –no-print-directory benchmark-run DEVICE=gpu EPOCHS=$(EPOCHS) OVERRIDES=’$(OVERRIDES)’ EXTRA_ARGS=’$(EXTRA_ARGS)’

benchmark-run:
@set -euo pipefail
OUTDIR=“benchmarks/$(TS)_$(DEVICE)”
mkdir -p “$$OUTDIR”
@echo “>>> Benchmark start”
@echo “    DEVICE     : $(DEVICE)”
@echo “    EPOCHS     : $(EPOCHS)”
@echo “    OUTDIR     : $$OUTDIR”
@echo “    OVERRIDES  : $(OVERRIDES)”
@echo “    EXTRA_ARGS : $(EXTRA_ARGS)”
$(CLI) train +training.epochs=$(EPOCHS) $(OVERRIDES) –device $(DEVICE) –outdir “$$OUTDIR” $(EXTRA_ARGS)
$(CLI) diagnose smoothness –outdir “$$OUTDIR” $(EXTRA_ARGS)
$(CLI) diagnose dashboard –outdir “$$OUTDIR” $(EXTRA_ARGS) || true
{ 
echo “Benchmark summary”; 
date; 
echo “python   : $$($(PYTHON) –version 2>&1)”; 
echo “poetry   : $$($(POETRY) –version 2>&1 || true)”; 
echo “cli      : $(CLI)”; 
echo “device   : $(DEVICE)”; 
echo “epochs   : $(EPOCHS)”; 
echo “overrides: $(OVERRIDES)”; 
command -v nvidia-smi >/dev/null 2>&1 && nvidia-smi || true; 
echo “”; 
echo “Artifacts in $$OUTDIR:”; 
ls -lh “$$OUTDIR” || true; 
} > “$$OUTDIR/summary.txt”
@echo “>>> Benchmark complete”
@echo “    Summary: $$OUTDIR/summary.txt”

benchmark-report:
@echo “>>> Aggregating benchmark summaries”
mkdir -p aggregated
{ 
echo “# SpectraMind V50 Benchmark Report”; 
echo “”; 
for f in $$(find benchmarks -type f -name summary.txt | sort); do 
echo “## $$f”; echo “”; cat “$$f”; echo “”; 
done; 
} > aggregated/report.md
@echo “>>> Aggregated: aggregated/report.md”

benchmark-clean:
@echo “>>> Removing local benchmark artifacts (benchmarks/ and aggregated/)”
rm -rf benchmarks aggregated

========= Kaggle Helpers =========

kaggle-run: init
@echo “>>> Running single-epoch GPU run (Kaggle-like)”
$(CLI) selftest –fast
$(CLI) train +training.epochs=1 –device gpu –outdir “$(OUT_DIR)”
$(CLI) predict –out-csv “$(PRED_DIR)/submission.csv”

kaggle-submit: kaggle-run
@echo “>>> Submitting to Kaggle competition”
kaggle competitions submit -c neurips-2025-ariel -f “$(PRED_DIR)/submission.csv” -m “SpectraMind V50 auto-submit”

========= Cleanup =========

clean:
@echo “>>> Cleaning outputs”
rm -rf “$(OUT_DIR)” “$(DIAG_DIR)” “$(PRED_DIR)” “$(SUBMIT_DIR)”

realclean: clean
@echo “>>> Cleaning caches”
rm -rf .pytest_cache .ruff_cache .mypy_cache .dvc/tmp .dvc/cache