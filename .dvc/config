[core]
    remote = storage
    autostage = true
    jobs = 8
    no_scm = false
    analytics = false
    hardlink_lock = true

[cache]
    # Prefer reflink (fast, copy-on-write) where supported; fall back safely
    type = "reflink,hardlink,copy"
    shared = group
    dir = .dvc/cache
    protected = true

['remote "storage"']
    url = s3://spectramind-v50-dvc-storage
    region = us-east-1
    endpointurl = https://s3.amazonaws.com
    # Credentials pulled from environment (kept out of VCS)
    access_key_id = ${DVC_AWS_KEY}
    secret_access_key = ${DVC_AWS_SECRET}
    # Helpful if bucket has multiple writers (CI, teammates)
    acl = bucket-owner-full-control

['remote "ci-mirror"']
    # Optional secondary S3 remote for CI artifacts / redundancy
    url = s3://spectramind-v50-dvc-ci
    region = us-east-1
    endpointurl = https://s3.amazonaws.com

['remote "local"']
    # Fast local cache/airâ€‘gap mirror (useful on dev machines)
    url = ../.dvc-storage
    type = local
    verify = true

['remote "gdrive"']
    # Optional Google Drive remote for collaborators
    # Replace <folder-id> and provide service account JSON via env var
    url = gdrive://<folder-id>
    gdrive_use_service_account = true
    gdrive_service_account_json_file_path = ${DVC_GDRIVE_SA_JSON}

[experiments]
    auto_push = true
    temp_dir = .dvc/tmp/experiments
    run_cache = true

[plots]
    template_dir = .dvc/plots/templates