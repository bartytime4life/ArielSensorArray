# .github/ISSUE_TEMPLATE/performance_issue.yml
# ==============================================================================
# SpectraMind V50 ‚Äî Performance Issue (GitHub Issue Form)
# Report slowdowns, regressions, high variance, or excessive resource use.
# Captures NASA-grade reproducibility signals: CLI commands, config hashes,
# environment details, metrics, and artifacts for diagnosis + triage.
# ==============================================================================

name: "‚ö° Performance Issue"
description: "Report slowdowns, regressions, high variance, or excessive resource use in SpectraMind V50"
labels: ["performance", "triage"]
assignees: []

body:
  - type: markdown
    attributes:
      value: |
        ## ‚ö° Performance Issue ‚Äî SpectraMind V50
        Help us diagnose and fix performance problems **quickly and reproducibly**.  
        Please provide **exact CLI commands**, **config hashes**, and **metrics** so we can replicate.

  - type: input
    id: summary
    attributes:
      label: "üìù Summary"
      description: "One-line description of the performance problem."
      placeholder: "Example: Training throughput halved on main after #1234"

  - type: textarea
    id: impact
    attributes:
      label: "üéØ Impact & Severity"
      description: "Who/what is affected? Is this blocking CI, Kaggle submissions, or reproducibility checks?"
      placeholder: "Describe impact (e.g., blocking leaderboard run, CI timeouts, resource overruns)."
    validations:
      required: true

  - type: dropdown
    id: severity
    attributes:
      label: "SEV Level"
      options:
        - "SEV-1 ‚Äî Blocking submissions/mission-critical"
        - "SEV-2 ‚Äî Major degradation, no workaround"
        - "SEV-3 ‚Äî Moderate, workaround exists"
        - "SEV-4 ‚Äî Minor/observational"
      default: 1

  - type: checkboxes
    id: symptoms
    attributes:
      label: "Observed Symptoms"
      options:
        - label: "Throughput drop (samples/sec, batches/sec)"
        - label: "Latency spike (per-step, per-epoch, inference)"
        - label: "OOM / memory growth / fragmentation"
        - label: "CPU/GPU underutilization"
        - label: "I/O bottleneck (dataset, DVC remote, Kaggle disk)"
        - label: "High variance / nondeterminism"
        - label: "Numerical instability (AMP/bfloat16)"
        - label: "Scheduler or dataloader stall"
        - label: "Other (explain below)"

  - type: textarea
    id: expected_actual
    attributes:
      label: "üìä Expected vs Actual"
      description: "Provide concrete numbers and units. Include baseline if known."
      placeholder: |
        Expected: ~1,200 it/s on A100 80GB (bs=64, AMP, DDP=8)
        Actual: ~580 it/s on same hardware
        Delta: -52%

  - type: textarea
    id: metrics_table
    attributes:
      label: "üìà Metrics Snapshot"
      description: "Paste a small table or bullet list of key metrics (utilization, memory, latency, throughput)."
      placeholder: |
        - GPU util: 46‚Äì58% (was 92‚Äì97%)
        - GPU mem: 42 GB peak (was ~39 GB)
        - Step time: 11.2 ms ‚Üí 21.7 ms
        - Dataloader wait: ~38% step time
        - Disk/Net: 220 MB/s read; DVC cache hits 88%

  - type: checkboxes
    id: regression
    attributes:
      label: "Regression?"
      description: "Is this worse than before?"
      options:
        - label: "Yes ‚Äî performance used to be better"
        - label: "No ‚Äî first time observed"
        - label: "Unsure"

  - type: input
    id: since_when
    attributes:
      label: "If regression: Since when?"
      description: "Commit SHA(s) / PR(s) / workflow run IDs / date."
      placeholder: "e.g., since 9a7b2f4 (#2345), CI run build-2025-08-20T11:24"

  - type: input
    id: code_version
    attributes:
      label: "üîí Code Version"
      description: "Git commit SHA (short/long) or tag."
      placeholder: "e.g., 9a7b2f4 or v50.3.1"
    validations:
      required: true

  - type: input
    id: config_hash
    attributes:
      label: "üß≠ Config Hash / Run Hash"
      description: "Hydra/DVC/MLflow run hash or the reported config hash in logs."
      placeholder: "e.g., run_hash_summary_v50: 7f31a2..."

  - type: textarea
    id: environment
    attributes:
      label: "üñ•Ô∏è Environment Details"
      description: "Exact hardware + software stack (CLI banner preferred)."
      placeholder: |
        OS: Ubuntu 24.04 LTS
        CUDA: 12.1, Driver: 550.xx
        Python: 3.12.x, PyTorch: 2.3.x, DDP: yes, AMP: yes
        GPU: 8√óRTX 5080 24GB
        Storage: NVMe local cache + DVC remote (lakeFS, S3)
        Kaggle: GPU runtime (Tesla T4/A100), 9hr constraint
        Docker/Poetry: image tag or poetry.lock hash
    validations:
      required: true

  - type: textarea
    id: workload
    attributes:
      label: "üß™ Workload Definition"
      description: "Be specific: dataset version, batch size, sequence length, model variant, training/inference mode."
      placeholder: |
        Dataset: ariel_v50_train@dvc:4c8e...
        Config: configs/train_v50.yaml + overrides
        Model: v50_mamba_gnn
        Batch size: 64 global, seq len: 135k (FGS1), 283 bins (AIRS)
        Mixed precision: fp16
        DDP: 8 GPUs, grad_accum=2
        Inference: single-GPU, bs=256

  - type: textarea
    id: repro
    attributes:
      label: "‚ôªÔ∏è Repro Steps (Exact CLI + Hydra overrides)"
      description: "List **exact** commands used. Prefer `spectramind` CLI with full Hydra overrides."
      placeholder: |
        spectramind train \
          +experiment_name=perf_regression_2025_08_25 \
          model=fgs1_mamba_v50 data=ariel_v50 \
          training.epochs=1 training.fast_dev_run=false \
          trainer.ddp=true trainer.devices=8 \
          training.batch_size=64 \
          hydra.run.dir=outputs/exp_perf_regression
        # Include CUDA_VISIBLE_DEVICES and note where slowdown first occurred.
    validations:
      required: true

  - type: textarea
    id: artifacts
    attributes:
      label: "üóÇÔ∏è Artifacts & Evidence"
      description: "Attach or link logs/reports to speed triage."
      placeholder: |
        - logs/v50_debug_log.md excerpt
        - profiler traces (nsys, torch.profiler, py-spy)
        - nvidia-smi dmon / DCGM metrics
        - MLflow run link
        - diagnostic_summary.json
        - CI run URL
        - Hydra composed config

  - type: textarea
    id: changes
    attributes:
      label: "üîÄ Recent Changes"
      description: "List code/config/dependency changes around the time it started."
      placeholder: |
        - Upgraded PyTorch 2.2 ‚Üí 2.3
        - Enabled torch.compile()
        - Adjusted dataloader workers 4 ‚Üí 16
        - New Hydra overrides for dataset sharding

  - type: checkboxes
    id: areas
    attributes:
      label: "Suspected Areas"
      options:
        - label: "Data loader / I/O / DVC"
        - label: "Distributed (DDP/FSDP/NCCL)"
        - label: "AMP / precision / torch.compile"
        - label: "CUDA kernels / CuDNN"
        - label: "Optimizer / scheduler"
        - label: "Model architecture (Mamba/SSM/GNN)"
        - label: "Checkpointing / logging overhead"
        - label: "Diagnostics (FFT/SHAP/symbolic overlays)"
        - label: "Other (describe below)"

  - type: textarea
    id: variance
    attributes:
      label: "üé≤ Variance / Determinism"
      description: "Is the slowdown consistent? Provide multiple trial results."
      placeholder: |
        5 trials per commit:
        - main@9a7b2f4: 1180 ¬± 22 it/s
        - main@c31de2a: 590 ¬± 19 it/s
        Seeds: 1337, 1338, 1339; cudnn.deterministic=true

  - type: checkboxes
    id: repro_scope
    attributes:
      label: "Where does it reproduce?"
      options:
        - label: "Locally (bare metal)"
        - label: "Docker (project image)"
        - label: "CI (GitHub Actions)"
        - label: "Kaggle (9hr runtime)"
        - label: "Specific GPU model(s)"
        - label: "Fresh clone (no cache)"
        - label: "Offline mode (no internet)"

  - type: textarea
    id: hypothesis
    attributes:
      label: "üß† Hypothesis / Notes"
      description: "Optional: suspected root cause, quick experiments tried."
      placeholder: "e.g., Dataset shuffling in DVC + NCCL backend causing stalls."

  - type: textarea
    id: acceptance
    attributes:
      label: "‚úÖ Acceptance Criteria"
      description: "Define ‚Äòdone‚Äô: specific metrics and thresholds."
      placeholder: |
        - Restore ‚â•1,150 it/s on A100 80GB (bs=64) with variance ‚â§ ¬±3%
        - GPU util ‚â•90% averaged over 1,000 steps
        - CI runtime < 45 min
        - Kaggle runtime ‚â§ 9h for 1,100 planets

  - type: checkboxes
    id: attachments
    attributes:
      label: "Pre-submit Checklist"
      options:
        - label: "Included exact CLI and Hydra overrides"
        - label: "Provided Git SHA and config/run hash"
        - label: "Attached profiler traces or logs"
        - label: "Specified hardware, drivers, and CUDA versions"
        - label: "Provided expected vs actual numbers with units"
        - label: "Linked to CI/MLflow/DVC artifacts"