# .github/ISSUE_TEMPLATE/bug_report.yml
# ==============================================================================
# SpectraMind V50 ‚Äî Bug Report (GitHub Issue Form)
# Purpose: capture every signal needed to reproduce, diagnose, and fix issues in a
# reproducible, NASA-grade way (CLI-first, Hydra-safe, DVC/lakeFS aware).
# ==============================================================================

name: "üêû Bug report"
description: Report a defect in SpectraMind V50 (pipeline, CLI, configs, tools, docs)
title: "[bug] <short summary>"
labels:
  - bug
  - needs-triage
projects: []
assignees: []

body:
  - type: markdown
    attributes:
      value: >
        Thanks for taking the time to report a bug. Please **fill out all required fields**.
        If possible, attach or link artifacts (logs, JSON manifests, HTML dashboards, small data)
        that make the issue reproducible. ‚ú®

  # --- Impact & scope ----------------------------------------------------------
  - type: dropdown
    id: area
    attributes:
      label: Affected area
      description: Where does this bug occur? (select all that apply)
      options:
        - CLI / Typer entrypoints
        - Training pipeline (train_v50.py / train_mae_v50.py / contrastive)
        - Inference / predict_v50.py
        - Diagnostics / dashboard (UMAP/t-SNE/FFT/SHAP/symbolic)
        - Symbolic logic / constraints / COREL / calibration
        - Data calibration / photometry / preprocessing
        - Configs / Hydra / overrides
        - Packaging / submission / validators
        - Tools / utilities / scripts
        - Docs / MkDocs / website
        - Other / Not sure
      multiple: true
    validations:
      required: true

  - type: dropdown
    id: where
    attributes:
      label: Execution environment
      description: Where did this happen?
      options:
        - Local (workstation/server)
        - GitHub Actions (CI)
        - Kaggle (GPU)
        - Kaggle (TPU)
        - Docker image
        - Other / Not sure
    validations:
      required: true

  - type: input
    id: version
    attributes:
      label: SpectraMind V50 version / commit
      description: Tag or commit SHA. If CI artifacts were used, include the run link/ID.
      placeholder: v50.4.0 (commit 9f1c2ab) ‚Ä¢ CI run https://github.com/<org>/<repo>/actions/runs/<id>
    validations:
      required: true

  - type: checkboxes
    id: regression
    attributes:
      label: Regression?
      options:
        - label: This worked in a previous version and recently broke.
        - label: I can point to the last known-good commit / tag.
    validations:
      required: false

  - type: input
    id: last_good
    attributes:
      label: Last known-good version (if regression)
      description: Tag/commit where this still worked.
      placeholder: v50.3.2 (commit a1b2c3d)
    validations:
      required: false

  - type: input
    id: config_hash
    attributes:
      label: Config hash / run hash
      description: From `v50_debug_log.md` / `run_hash_summary_v50.json` (if available).
      placeholder: run_hash=ab12cd34 / config_hash=fe98dc76
    validations:
      required: false

  # --- Reproducible scenario ---------------------------------------------------
  - type: textarea
    id: steps
    attributes:
      label: Steps to reproduce
      description: Minimal, copy-paste ready steps (CLI-first). Include Hydra overrides.
      placeholder: |
        1) poetry run spectramind selftest --fast
        2) poetry run spectramind train --config configs/v50/train.yaml +training.seed=1337
        3) poetry run spectramind diagnose dashboard --outdir outputs/diag
        4) Observe error...
      render: shell
    validations:
      required: true

  - type: textarea
    id: cli_cmd
    attributes:
      label: Exact CLI command(s) used
      description: Paste the exact command(s) (with Hydra overrides) that triggered the bug.
      placeholder: poetry run spectramind predict --config configs/v50/predict.yaml +predict.batch=16
      render: shell
    validations:
      required: true

  - type: textarea
    id: expected
    attributes:
      label: Expected behavior
      description: What should have happened (scientific/physical expectation if relevant)?
      placeholder: The command should complete and produce <artifact> with <property>.
    validations:
      required: true

  - type: textarea
    id: actual
    attributes:
      label: Actual behavior / error message
      description: Paste the full error (stack trace) or concise summary (last ~200 log lines).
      placeholder: |
        Traceback (most recent call last):
          ...
      render: shell
    validations:
      required: true

  # --- Environment -------------------------------------------------------------
  - type: textarea
    id: env
    attributes:
      label: Environment
      description: Paste runtime details (from CLI banner / `spectramind --version` when possible).
      placeholder: |
        OS: Ubuntu 24.04 / macOS 14 / Windows 11 WSL2
        Python: 3.12.x  ‚Ä¢ Poetry: 1.8.x
        CUDA: 12.1 / 12.4  ‚Ä¢ Driver: 550.xx / 555.xx
        GPU(s): RTX 5080 (24 GB) ‚Ä¢ VRAM free at start: ~22 GB
        PyTorch: 2.3.x+cu121 ‚Ä¢ Transformers: 4.xx
        DVC: 3.x  ‚Ä¢ lakeFS: (optional)
        Docker: ghcr.io/<org>/spectramind:<tag> (if applicable)
        Kaggle: (include environment and settings, if applicable)
    validations:
      required: true

  - type: checkboxes
    id: env_checks
    attributes:
      label: Environment checks
      description: Quick sanity checks before filing.
      options:
        - label: I ran `poetry install` successfully with the current `poetry.lock`.
          required: true
        - label: I ran `poetry run spectramind selftest` (fast or deep) and attached/posted the result.
        - label: If using DVC/lakeFS, I ran `dvc status -c` and verified the cache is coherent.
        - label: Large/binary files are tracked by Git LFS where applicable.

  # --- Inputs & artifacts ------------------------------------------------------
  - type: textarea
    id: configs
    attributes:
      label: Relevant config snippet(s)
      description: Paste minimal YAML or overrides (mask secrets).
      placeholder: |
        training:
          epochs: 1
          amp: true
        dataset:
          name: v50_sim
      render: yaml
    validations:
      required: false

  - type: textarea
    id: diagnostics
    attributes:
      label: Diagnostics / artifacts
      description: Link or attach minimal artifacts (logs, JSON summaries, HTML dashboard, PNGs).
      placeholder: |
        - logs/v50_debug_log.md (tail)
        - outputs/diagnostics/diagnostic_summary.json
        - outputs/dashboard_vN.html
        - constraint_violation_log.json
        - run_hash_summary_v50.json
        - selftest_report.md / selftest_report.json
    validations:
      required: false

  # --- CI / reproducibility ----------------------------------------------------
  - type: input
    id: ci_link
    attributes:
      label: CI run link (if applicable)
      description: Paste the failing GitHub Actions link (job URL).
      placeholder: https://github.com/<org>/<repo>/actions/runs/<id>
    validations:
      required: false

  - type: checkboxes
    id: reproducibility
    attributes:
      label: Reproducibility
      options:
        - label: Reproduces from a clean clone with only documented steps (no local hacks).
          required: true
        - label: Reproduces on `main` (latest).
        - label: Reproduces inside the published Docker image (if provided).

  # --- Security / data handling ------------------------------------------------
  - type: textarea
    id: security
    attributes:
      label: Security / data handling considerations
      description: If secrets, PII, or sensitive data could be involved, describe here (do **not** paste secrets).
      placeholder: e.g., stack trace logs token value; model weights path leaked; etc.
    validations:
      required: false

  # --- Severity & triage extras -----------------------------------------------
  - type: dropdown
    id: severity
    attributes:
      label: Severity (self-assessed)
      options:
        - S0 ‚Äî blocker (pipeline unusable / data loss risk)
        - S1 ‚Äî critical (core module broken, no workaround)
        - S2 ‚Äî major (primary feature broken, has workaround)
        - S3 ‚Äî minor (cosmetic / diagnostics / docs)
        - S4 ‚Äî trivial (typo / nit)
    validations:
      required: true

  - type: checkboxes
    id: extras
    attributes:
      label: Optional triage labels to suggest
      options:
        - label: area:cli
        - label: area:training
        - label: area:inference
        - label: area:diagnostics
        - label: area:symbolic
        - label: area:calibration
        - label: area:configs
        - label: area:submission
        - label: needs-investigation

  # --- Final confirmation ------------------------------------------------------
  - type: checkboxes
    id: confirmation
    attributes:
      label: Confirmation
      options:
        - label: I agree to follow this project's Security Policy and will not include secrets in this issue.
          required: true
        - label: I confirm the information above is accurate and sufficient to reproduce the bug.
          required: true