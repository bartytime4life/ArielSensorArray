# üõ∞Ô∏è SpectraMind V50 ‚Äî Pull Request Template (ArielSensorArray)

Fill out every section. If something doesn‚Äôt apply, write ‚ÄúN/A‚Äù and explain why.  
This template enforces **NASA-grade reproducibility, physics-informed modeling, CLI-first design, and symbolic/diagnostics rigor** for the **NeurIPS 2025 Ariel Data Challenge** [oai_citation:0‚Ä°SpectraMind V50 Technical Plan for the NeurIPS¬†2025 Ariel Data Challenge.pdf](file-service://file-6PdU5f5knreHjmSdSauj3w) [oai_citation:1‚Ä°SpectraMind V50 Project Analysis (NeurIPS¬†2025 Ariel Data Challenge).pdf](file-service://file-QRDy8Xn69XgxEjZgtZZ8FK).

---

## 1) Title & Issue Links
**PR Title (imperative):**

Closes:
- #ISSUE_ID
- (Optional) External link(s):

---

## 2) Summary (What & Why)
**What changed (concise overview):**

**Why (motivation/scientific rationale):**

Impact on:
- Œº/œÉ spectra accuracy
- GLL / calibration
- Runtime (Kaggle 9h limit [oai_citation:2‚Ä°SpectraMind V50 Technical Plan for the NeurIPS¬†2025 Ariel Data Challenge.pdf](file-service://file-6PdU5f5knreHjmSdSauj3w))
- Symbolic/physics integrity [oai_citation:3‚Ä°Cosmic Fingerprints .txt](file-service://file-HNCWW2WZZ9FkKvKZAfqMdw) [oai_citation:4‚Ä°Gravitational Lensing and Astronomical Observation: Modeling and Mitigation.pdf](file-service://file-HA6qQbdteZZaeRSStyD1Ha)
- Reproducibility / DVC / Hydra [oai_citation:5‚Ä°Hydra for AI Projects: A Comprehensive Guide.pdf](file-service://file-MpHwv9Z1E3qqzGXaQ3agpL)

Scope touched:
- [ ] Code
- [ ] Configs (Hydra)
- [ ] Data pipeline / calibration
- [ ] Diagnostics / dashboard
- [ ] Docs
- [ ] CI / infra
- [ ] Security / compliance
- [ ] Other:

---

## 3) Design & Reproducibility

### 3.1 CLI Invocation(s)
Paste **exact** commands.  
Use unified Typer CLI (`spectramind ‚Ä¶` [oai_citation:6‚Ä°Command Line Interfaces (CLI) Technical Reference (Master Coder Protocol).pdf](file-service://file-HzYPacwmdGzogMDYWAL7cp)).

```bash
spectramind selftest --deep
spectramind calibrate --config-name=config_v50
spectramind train --config-name=config_v50 +training.seed=1337
spectramind predict --out-csv outputs/submission.csv
spectramind diagnose dashboard --open-html

3.2 Hydra Config Diffs

Show minimal before‚Üíafter diffs or new files Ôøº.

# configs/model/v50.yaml
- decoder.head: "gaussian"
+ decoder.head: "gaussian_corel"
+ corel:
+   enable: true
+   edge_features: ["wavelength_dist", "molecule", "detector_region"]

3.3 Data & Artifacts (DVC)
	‚Ä¢	DVC stages updated in dvc.yaml: ‚òê Yes
	‚Ä¢	dvc repro passes: ‚òê Yes
	‚Ä¢	Large artifacts tracked in DVC (no binaries in Git): ‚òê Yes Ôøº

Stages touched: calibrate / train / predict / diagnose
New outputs: outputs/‚Ä¶ (size, purpose)

‚∏ª

4) Scientific Integrity & Diagnostics

4.1 Metrics (attach numbers)

Metric	Baseline (commit/hash)	This PR	Œî
Public GLL (val)			
Private GLL			
MAE (Œº)			
Calibration (z-score)			
Coverage@95% (œÉ)			
Runtime (planet avg)			

Seeds, dataset split, commands: paste exactly.

4.2 Plots / Reports
	‚Ä¢	Dashboard HTML: outputs/diagnostics/report_vX.html
	‚Ä¢	UMAP/t-SNE overlays Ôøº
	‚Ä¢	GLL per-bin heatmap
	‚Ä¢	FFT / smoothness plots Ôøº

Attach HTML or screenshots.

4.3 Symbolic / Physics Checks
	‚Ä¢	Symbolic loss trend: ‚òê stable ‚òê improved Ôøº
	‚Ä¢	Smoothness / priors respected
	‚Ä¢	Nonnegativity enforced
	‚Ä¢	No new symbolic rule violations

Explain degradations if any.

‚∏ª

5) Backward Compatibility & Risk

Breaking changes:
	‚Ä¢	CLI flags
	‚Ä¢	File/dir layout
	‚Ä¢	Config schema
	‚Ä¢	Model checkpoints

Migration notes: (one-command recipe)

Risk:
	‚Ä¢	Impact: Low / Medium / High
	‚Ä¢	Mitigation: tests, flags, rollout plan

‚∏ª

6) Tests & Validation
	‚Ä¢	Unit tests (pytest) added/updated: list paths Ôøº
	‚Ä¢	spectramind selftest --fast/--deep pass: ‚òê Yes
	‚Ä¢	Toy pipeline sanity (make ci-smoke): ‚òê Yes
	‚Ä¢	Repro run matches with same seed/config
	‚Ä¢	Determinism: ‚òê Yes

Paste trimmed logs or link artifacts.

‚∏ª

7) Performance & Runtime Budget

Target: ‚â§9h for ~1100 planets (Kaggle GPU limit Ôøº).
	‚Ä¢	Per-planet wall time acceptable
	‚Ä¢	Memory within container limit
	‚Ä¢	Vectorization respected
	‚Ä¢	--fast-dev-run documented

Numbers (machine, GPU, batch, etc.):

‚∏ª

8) Security & Compliance
	‚Ä¢	No secrets/keys in code/configs Ôøº
	‚Ä¢	Licenses respected; attributions updated
	‚Ä¢	No PII; only synthetic/competition data

‚∏ª

9) Docs
	‚Ä¢	README.md updated Ôøº
	‚Ä¢	Docstrings & type hints
	‚Ä¢	CLI --help accurate Ôøº
	‚Ä¢	Configs documented (inline comments)

‚∏ª

10) Checklist ‚Äî Author
	‚Ä¢	Verified CLI runs produce outputs
	‚Ä¢	Captured Hydra configs + seeds Ôøº
	‚Ä¢	Updated DVC, pushed artifacts Ôøº
	‚Ä¢	Added/updated tests; selftest passes
	‚Ä¢	Produced dashboard HTML/plots Ôøº
	‚Ä¢	Updated docs/help strings
	‚Ä¢	Passed pre-commit (ruff, black, isort, mypy) Ôøº
	‚Ä¢	Updated CHANGELOG.md (if applicable)

Author: @your-handle
Date: YYYY-MM-DD

‚∏ª

11) Checklist ‚Äî Reviewer
	‚Ä¢	Clear problem + rationale
	‚Ä¢	Reproducible configs + seeds
	‚Ä¢	Tests sufficient; failure modes covered
	‚Ä¢	Metrics credible; GLL/calibration not regressed
	‚Ä¢	Runtime/memory budget respected Ôøº
	‚Ä¢	Physics/symbolic rules respected Ôøº Ôøº
	‚Ä¢	No binary blobs in Git
	‚Ä¢	CI green (lint, diagnostics, smoke)

Reviewer: @handle ‚Äî Approve / Request changes / Comment

‚∏ª

12) Post-Merge Tasks (Owner)
	‚Ä¢	Kick CI pipeline on main Ôøº
	‚Ä¢	Tag run hash / update release notes
	‚Ä¢	Backfill dashboard / publish artifacts
	‚Ä¢	Notify stakeholders / update issue tracker

‚∏ª

Appendix A ‚Äî Bench Run Log

Paste CLI call ‚Üí Hydra config ‚Üí hash ‚Üí metrics.
Full logs ‚Üí logs/v50_debug_log.md.

Appendix B ‚Äî Config Snapshot

Paste exact composed Hydra config (OmegaConf.to_yaml) for main run Ôøº.

‚∏ª

Contributor Notes
	‚Ä¢	Use unified Typer CLI; no ad-hoc scripts Ôøº.
	‚Ä¢	Treat configs as code; capture composed Hydra config Ôøº.
	‚Ä¢	Version large data/models with DVC Ôøº.
	‚Ä¢	Diagnostics are first-class: produce dashboard HTML every run Ôøº.
	‚Ä¢	Physics & symbolic constraints are mandatory ‚Äî justify any deviation Ôøº Ôøº.

Do you want me to also generate a **matching `PULL_REQUEST_REVIEW_GUIDE.md`** for reviewers, with a structured checklist that mirrors this PR template? That would standardize review quality across the repo.