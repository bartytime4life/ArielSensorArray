```yaml
# .github/workflows/ci.yml
# ==============================================================================
# SpectraMind V50 — GitHub Actions CI (hardened, fast, reproducible)
# - Hygiene (pre-commit + mypy + pytest) on a Python matrix (3.11, 3.12)
# - Deterministic env via Poetry with caching (pip/poetry/.venv/pre-commit/mypy)
# - SVG optimization gate (SVGO v3) with auto-fix on main, fail-on-PR if dirty
# - Changes filter to avoid running heavy jobs for docs/assets-only changes
# - Optional DVC pull; CLI smoke (selftest + minimal diagnostics)
# - Optional predict artifact, scheduled/dispatch ablation, guarded Kaggle submit
# - Optional Docker(GPU) parity smoke with BuildKit cache
# - Concurrency, minimal permissions, explicit timeouts
# ==============================================================================

name: CI

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "**" ]
  workflow_dispatch:
    inputs:
      run_ablation_on_push:
        description: "Run fast ablation (ablate-ci) for this manual run?"
        required: false
        default: "false"
        type: choice
        options: ["false", "true"]
      submit_to_kaggle:
        description: "Submit predictions to Kaggle for this manual run?"
        required: false
        default: "false"
        type: choice
        options: ["false", "true"]
      extra_overrides:
        description: "Hydra overrides (e.g., +training.seed=1337 +training.epochs=1)"
        required: false
        type: string
  schedule:
    - cron: "0 12 * * 0"  # Sundays 12:00 UTC (06:00/07:00 America/Chicago)

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

permissions:
  contents: read

defaults:
  run:
    shell: bash -euxo pipefail

env:
  PYTHONUNBUFFERED: "1"
  PIP_DISABLE_PIP_VERSION_CHECK: "1"
  PIP_NO_PYTHON_VERSION_WARNING: "1"
  POETRY_VERSION: "1.8.3"
  DEFAULT_PY: "3.12"
  TRANSFORMERS_OFFLINE: "1"
  HF_HUB_OFFLINE: "1"
  HYDRA_FULL_ERROR: "1"
  # Deterministic CPU math
  OMP_NUM_THREADS: "1"
  MKL_NUM_THREADS: "1"
  OPENBLAS_NUM_THREADS: "1"
  NUMEXPR_NUM_THREADS: "1"
  # Flip to '1' once mypy is green to make it blocking in hygiene job
  STRICT_MYPY: "0"

# ------------------------------------------------------------------------------
# 0) Changes filter — decide if we need heavy jobs; always run on PRs/pushes
# ------------------------------------------------------------------------------
jobs:
  changes:
    name: Detect Changes
    runs-on: ubuntu-latest
    timeout-minutes: 5
    permissions:
      contents: read
    outputs:
      code: ${{ steps.filter.outputs.code }}
      svg: ${{ steps.filter.outputs.svg }}
      docs: ${{ steps.filter.outputs.docs }}
      assets: ${{ steps.filter.outputs.assets }}
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
      - uses: dorny/paths-filter@v3
        id: filter
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          filters: |
            code:
              - 'src/**'
              - 'tests/**'
              - 'pyproject.toml'
              - 'poetry.lock'
              - '**/*.py'
              - '.pre-commit-config.yaml'
              - '.mypy.ini'
              - '.flake8'
              - '.github/workflows/**'
              - '!docs/**'
              - '!assets/**'
            svg:
              - 'docs/**/*.svg'
              - 'assets/**/*.svg'
              - 'assets/diagrams/**/*.svg'
              - '.svgo.json'
            docs:
              - '**/*.md'
              - 'docs/**'
            assets:
              - 'assets/**'

  # ----------------------------------------------------------------------------
  # 0.5) SVG Optimize gate — fail PRs if SVGs not optimized; auto-fix on main
  # ----------------------------------------------------------------------------
  svg:
    name: SVG Optimize (gate)
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: changes
    if: |
      needs.changes.outputs.svg == 'true' ||
      github.event_name == 'workflow_dispatch' || github.event_name == 'schedule'
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v4

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: 20
          cache: 'npm'

      - name: Install SVGO (pinned)
        run: |
          npm init -y >/dev/null 2>&1
          npm install svgo@^3.3.2 --save-dev

      - name: Optimize SVGs in-place (if .svgo.json exists)
        run: |
          if [ -f ".svgo.json" ]; then
            npx svgo -c .svgo.json -f assets/diagrams -o assets/diagrams || true
            npx svgo -c .svgo.json -f docs -o docs || true
          else
            echo "No .svgo.json found; skipping."
          fi

      - name: Fail PR if changes required
        if: github.event_name == 'pull_request'
        run: |
          if [ -n "$(git status --porcelain)" ]; then
            echo "❌ SVGs are not optimized. Run 'make optimize-svg' locally (uses .svgo.json)."
            git --no-pager diff --stat
            exit 1
          fi

      - name: Auto-commit on main (optimize SVGs)
        if: github.ref == 'refs/heads/main'
        run: |
          if [ -n "$(git status --porcelain)" ]; then
            git config user.name  "github-actions[bot]"
            git config user.email "41898282+github-actions[bot]@users.noreply.github.com"
            git add assets/diagrams docs || true
            git commit -m "chore(svg): optimize SVGs via CI"
            git push
          else
            echo "SVGs already optimized."
          fi

  # ----------------------------------------------------------------------------
  # 1) Hygiene: lint/format/type/tests (matrix)
  # ----------------------------------------------------------------------------
  hygiene:
    name: Hygiene (pre-commit + mypy + pytest) • py${{ matrix.py }}
    runs-on: ubuntu-latest
    timeout-minutes: 35
    needs: [changes, svg]
    if: |
      (needs.changes.outputs.code == 'true') ||
      github.event_name == 'schedule' ||
      github.event_name == 'workflow_dispatch'
    strategy:
      fail-fast: false
      matrix:
        py: ["3.11", "3.12"]
    permissions:
      contents: read
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python ${{ matrix.py }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.py }}
          cache: "pip"

      - name: Install Poetry & pre-commit
        run: |
          python -m pip install --upgrade pip
          pip install "poetry==${POETRY_VERSION}" pre-commit

      - name: Configure Poetry (in-project venv)
        run: |
          poetry config virtualenvs.in-project true
          poetry config installer.max-workers 10

      - name: Cache deps (poetry/pip/venv/pre-commit/mypy)
        uses: actions/cache@v4
        with:
          path: |
            .venv
            ~/.cache/pip
            ~/.cache/pypoetry
            ~/.cache/pre-commit
            .mypy_cache
          key: cache-${{ runner.os }}-py${{ matrix.py }}-${{ hashFiles('**/poetry.lock') }}-${{ hashFiles('.pre-commit-config.yaml') }}
          restore-keys: |
            cache-${{ runner.os }}-py${{ matrix.py }}-
            cache-${{ runner.os }}-

      - name: Install deps (no-root)
        run: |
          poetry install --no-interaction --no-ansi --no-root

      - name: Run pre-commit (repo-wide hooks)
        run: |
          poetry run pre-commit run --all-files --show-diff-on-failure

      - name: Type check (mypy)
        continue-on-error: ${{ env.STRICT_MYPY != '1' }}
        run: |
          poetry run mypy --install-types --non-interactive --namespace-packages --pretty src

      - name: Unit & integration tests (pytest)
        run: |
          mkdir -p reports
          poetry run pytest -q --maxfail=1 --disable-warnings \
            --junitxml=reports/junit-${{ matrix.py }}.xml \
            --cov=src --cov-report=xml:reports/coverage-${{ matrix.py }}.xml

      - name: Upload hygiene artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: hygiene-py${{ matrix.py }}
          path: |
            reports/**
            logs/**
          if-no-files-found: ignore
          retention-days: 10

  # ----------------------------------------------------------------------------
  # 2) Build/Test/Smoke: reproducible env + CLI selftest + minimal diagnostics
  # ----------------------------------------------------------------------------
  smoke:
    name: Build • Smoke (Poetry + CLI)
    runs-on: ubuntu-latest
    timeout-minutes: 50
    needs: hygiene
    if: always()  # still collect diagnostics even if one hygiene shard fails
    permissions:
      contents: read
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python (${{ env.DEFAULT_PY }})
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.DEFAULT_PY }}
          cache: "pip"

      - name: Install Poetry
        run: |
          python -m pip install --upgrade pip
          pip install "poetry==${POETRY_VERSION}"

      - name: Configure Poetry (in-project venv)
        run: |
          poetry config virtualenvs.in-project true
          poetry config installer.max-workers 10

      - name: Cache deps (poetry/pip/venv)
        uses: actions/cache@v4
        with:
          path: |
            .venv
            ~/.cache/pip
            ~/.cache/pypoetry
          key: poetry-${{ runner.os }}-py${{ env.DEFAULT_PY }}-${{ hashFiles('**/poetry.lock') }}
          restore-keys: |
            poetry-${{ runner.os }}-py${{ env.DEFAULT_PY }}-
            poetry-${{ runner.os }}-

      - name: Install deps (no-root)
        run: |
          poetry install --no-interaction --no-ansi --no-root

      - name: DVC (optional) + pull (optional)
        run: |
          python -m pip install --upgrade "dvc[all]" || python -m pip install --upgrade dvc
          dvc --version || true
          dvc pull --run-cache --force || true

      - name: CLI selftest (fast)
        run: |
          poetry run spectramind selftest --fast

      - name: Minimal diagnostics
        run: |
          poetry run spectramind diagnose smoothness --outdir outputs/diagnostics-ci
          poetry run spectramind diagnose dashboard --no-umap --no-tsne --outdir outputs/diagnostics-ci || \
          poetry run spectramind diagnose dashboard --outdir outputs/diagnostics-ci || true

      - name: Upload smoke artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: smoke-artifacts
          path: |
            outputs/diagnostics-ci/**
            outputs/submission.csv
            outputs/diagrams/**
            logs/**
          if-no-files-found: ignore
          retention-days: 10

  # ----------------------------------------------------------------------------
  # 3) Predict (optional artifact; does not block)
  # ----------------------------------------------------------------------------
  predict:
    name: Predict (optional)
    runs-on: ubuntu-latest
    timeout-minutes: 25
    needs: smoke
    permissions:
      contents: read
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.DEFAULT_PY }}
          cache: "pip"
      - name: Install Poetry (thin)
        run: |
          python -m pip install --upgrade pip
          pip install "poetry==${POETRY_VERSION}"
          poetry config virtualenvs.in-project true
          poetry install --no-interaction --no-ansi --no-root
      - name: Predict
        run: |
          poetry run spectramind predict --out-csv outputs/predictions/submission.csv || true
      - name: Upload prediction
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: predictions
          path: |
            outputs/predictions/submission.csv
          if-no-files-found: ignore
          retention-days: 10

  # ----------------------------------------------------------------------------
  # 4) Ablation (scheduled/manual) — fast grid + leaderboard artifact
  # ----------------------------------------------------------------------------
  ablate:
    name: Ablation Leaderboard (scheduled/manual)
    runs-on: ubuntu-latest
    timeout-minutes: 75
    if: |
      github.event_name == 'schedule' ||
      (github.event_name == 'workflow_dispatch' && inputs.run_ablation_on_push == 'true')
    permissions:
      contents: read
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.DEFAULT_PY }}
          cache: "pip"
      - name: Install Poetry
        run: |
          python -m pip install --upgrade pip
          pip install "poetry==${POETRY_VERSION}"
          poetry config virtualenvs.in-project true
          poetry install --no-interaction --no-ansi --no-root
      - name: Run ablation (fast grid, light)
        run: |
          poetry run spectramind ablate -m ablate.sweeper=basic +ablate.search=v50_fast_grid ablation=ablation_light || true
      - name: Upload ablation artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ablation-leaderboard
          path: |
            outputs/ablate/leaderboard.csv
            outputs/ablate/**
          if-no-files-found: ignore
          retention-days: 21

  # ----------------------------------------------------------------------------
  # 5) Kaggle submit (manual/guarded; never on PRs)
  # ----------------------------------------------------------------------------
  kaggle-submit:
    name: Kaggle Submit (manual/guarded)
    needs: predict
    runs-on: ubuntu-latest
    timeout-minutes: 20
    if: |
      github.event_name == 'workflow_dispatch' &&
      inputs.submit_to_kaggle == 'true' &&
      github.event.pull_request == null
    env:
      KAGGLE_USERNAME: ${{ secrets.KAGGLE_USERNAME }}
      KAGGLE_KEY: ${{ secrets.KAGGLE_KEY }}
    permissions:
      contents: read
    steps:
      - name: Fail early if secrets missing
        run: |
          if [ -z "${KAGGLE_USERNAME}" ] || [ -z "${KAGGLE_KEY}" ]; then
            echo "::error::Kaggle credentials are not configured (KAGGLE_USERNAME/KAGGLE_KEY)."
            exit 1
          fi
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: ${{ env.DEFAULT_PY }}
          cache: "pip"
      - name: Install kaggle CLI & auth
        run: |
          python -m pip install --upgrade kaggle
          mkdir -p ~/.kaggle
          printf '{"username":"%s","key":"%s"}' "$KAGGLE_USERNAME" "$KAGGLE_KEY" > ~/.kaggle/kaggle.json
          chmod 600 ~/.kaggle/kaggle.json
          kaggle --version || true
      - name: Ensure submission exists
        run: |
          if [ ! -f "outputs/predictions/submission.csv" ] && [ -f "outputs/submission.csv" ]; then
            mkdir -p outputs/predictions
            cp outputs/submission.csv outputs/predictions/submission.csv
          fi
          test -f "outputs/predictions/submission.csv" || (echo "::error::No submission.csv found"; exit 1)
          ls -lh outputs/predictions/submission.csv
      - name: Submit to Kaggle (neurips-2025-ariel)
        run: |
          kaggle competitions submit \
            -c neurips-2025-ariel \
            -f outputs/predictions/submission.csv \
            -m "CI auto-submit: $GITHUB_SHA"

  # ----------------------------------------------------------------------------
  # 6) Dockerized GPU parity smoke (opt-in via repo/org var DOCKER_GPU=1)
  # ----------------------------------------------------------------------------
  docker-gpu:
    name: Docker GPU Smoke • BuildKit cache
    if: ${{ vars.DOCKER_GPU == '1' }}
    runs-on: ubuntu-latest
    timeout-minutes: 35
    env:
      BUILDKIT_CACHE_TO: /tmp/.buildx-cache-new
      BUILDKIT_CACHE_FROM: /tmp/.buildx-cache
      IMAGE_TAG: spectramindv50:ci
    permissions:
      contents: read
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with: { fetch-depth: 0 }

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Restore BuildKit cache
        uses: actions/cache@v4
        with:
          path: ${{ env.BUILDKIT_CACHE_FROM }}
          key: buildx-${{ runner.os }}-${{ hashFiles('Dockerfile', '**/pyproject.toml', '**/poetry.lock') }}
          restore-keys: |
            buildx-${{ runner.os }}-

      - name: Install Docker & NVIDIA runtime
        run: |
          sudo apt-get update -y
          sudo apt-get install -y docker.io
          sudo systemctl start docker
          distribution=$(. /etc/os-release;echo $ID$VERSION_ID) && \
          curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg && \
          curl -fsSL https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
            sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
            sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
          sudo apt-get update -y
          sudo apt-get install -y nvidia-container-toolkit
          sudo nvidia-ctk runtime configure --runtime=docker
          sudo systemctl restart docker

      - name: Build CUDA image (cached)
        uses: docker/build-push-action@v6
        with:
          context: .
          file: ./Dockerfile
          tags: ${{ env.IMAGE_TAG }}
          load: true
          cache-from: type=local,src=${{ env.BUILDKIT_CACHE_FROM }}
          cache-to: type=local,dest=${{ env.BUILDKIT_CACHE_TO }},mode=max

      - name: Save BuildKit cache
        if: always()
        uses: actions/cache@v4
        with:
          path: ${{ env.BUILDKIT_CACHE_TO }}
          key: buildx-${{ runner.os }}-${{ hashFiles('Dockerfile', '**/pyproject.toml', '**/poetry.lock') }}

      - name: Smoke inside container
        run: |
          docker run --rm --gpus all \
            -v "$PWD":/workspace -w /workspace \
            ${{ env.IMAGE_TAG }} \
            bash -lc 'which spectramind || true; spectramind selftest --fast || exit 1'
```
