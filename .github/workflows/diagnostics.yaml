# ==============================================================================
# SpectraMind V50 — Diagnostics Workflow
# Generates HTML dashboards & diagnostic artifacts (UMAP/t‑SNE*, GLL heatmaps,
# SHAP*, symbolic overlays). Defaults to a CI‑safe "light" run; you can supply
# extra Hydra overrides in workflow_dispatch. (*heavy diagnostics may be skipped)
#
# Artifacts:
#   - artifacts/diagnostics/py<ver>/  (per‑interpreter)
#   - outputs/diagnostics/             (mirrored into per‑interp artifact)
#   - aggregated/DIAGNOSTICS_INDEX.md  (merged index)
#
# Optional:
#   - DVC pull (safe no‑op if not configured)
#   - ablation leaderboard (fast grid) — manual or on schedule
# ==============================================================================

name: diagnostics

on:
  workflow_dispatch:
    inputs:
      extra_overrides:
        description: "Hydra overrides (e.g., +data.split=toy +diagnostics.light=true)"
        type: string
        required: false
        default: "+diagnostics.light=true +data.split=toy"
      run_ablation:
        description: "Also run fast ablation and attach leaderboard?"
        type: choice
        options: [ "false", "true" ]
        required: false
        default: "false"
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "**" ]
  schedule:
    # Weekly diagnostics snapshot (Sundays 07:00 UTC)
    - cron: "0 7 * * 0"

permissions:
  contents: read

concurrency:
  group: diagnostics-${{ github.ref }}
  cancel-in-progress: true

env:
  POETRY_VIRTUALENVS_IN_PROJECT: "true"
  POETRY_NO_INTERACTION: "1"
  PIP_DISABLE_PIP_VERSION_CHECK: "1"
  PIP_NO_PYTHON_VERSION_WARNING: "1"
  HYDRA_FULL_ERROR: "1"
  DEFAULT_OVERRIDES: "+diagnostics.light=true +data.split=toy"
  DEVICE: "cpu"
  POETRY_VERSION: "1.8.3"

jobs:
  build:
    name: Diagnostics • py${{ matrix.python-version }}
    runs-on: ubuntu-latest
    timeout-minutes: 60

    strategy:
      fail-fast: false
      matrix:
        python-version: ["3.10", "3.11", "3.12"]

    env:
      # per‑job computed paths
      DIAG_DIR: "outputs/diagnostics"
      ARTIFACT_DIR: "artifacts/diagnostics/py${{ matrix.python-version }}"

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python ${{ matrix.python-version }}
        id: setup-python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install pipx & Poetry
        uses: pipxproject/action-install-pipx@v1
      - run: pipx install poetry==${{ env.POETRY_VERSION }}

      - name: Cache Poetry & venv
        uses: actions/cache@v4
        with:
          path: |
            .venv
            ~/.cache/pypoetry
            ~/.cache/pip
          key: poetry-${{ runner.os }}-${{ matrix.python-version }}-${{ hashFiles('poetry.lock') }}
          restore-keys: |
            poetry-${{ runner.os }}-${{ matrix.python-version }}-

      - name: Install dependencies
        run: |
          poetry env use "${{ steps.setup-python.outputs.python-path }}"
          poetry install --no-interaction --no-root

      - name: Versions
        run: |
          python --version
          poetry --version
          poetry run python - <<'PY'
          import sys, platform, importlib, json
          info={"platform": platform.platform(), "python": sys.version.replace("\n"," ")}
          for m in ("torch","numpy","pandas","matplotlib"):
              try:
                  mod=importlib.import_module(m)
                  info[m]=getattr(mod,"__version__", "n/a")
              except Exception:
                  info[m]="not installed"
          print(json.dumps(info, indent=2))
          PY

      - name: Validate .env (safe no‑op if missing)
        run: |
          if [ -f scripts/validate_env.py ]; then
            poetry run python scripts/validate_env.py
          else
            echo "No scripts/validate_env.py — skipping."
          fi

      - name: Optional DVC pull
        run: |
          poetry run python - <<'PY'
          import subprocess, sys
          try:
              subprocess.check_call([sys.executable, "-m", "pip", "install", "-q", "dvc[all]"])
              subprocess.call(["dvc","--version"])
              subprocess.call(["dvc","pull","-q"])
          except Exception as e:
              print("DVC not configured or pull failed (ok for CI):", e)
          PY

      - name: Prepare artifact folders
        run: |
          mkdir -p "${ARTIFACT_DIR}" "${DIAG_DIR}"

      - name: Pipeline selftest (fast)
        run: |
          poetry run spectramind selftest --fast

      - name: Train minimal model for diagnostics (fast)
        run: |
          OVERRIDES="${DEFAULT_OVERRIDES} ${{ inputs.extra_overrides }}"
          echo "Using overrides: ${OVERRIDES}"
          poetry run spectramind train +training.epochs=1 ${OVERRIDES} --device ${DEVICE} --outdir "${ARTIFACT_DIR}"

      - name: Generate diagnostics — smoothness
        run: |
          poetry run spectramind diagnose smoothness --outdir "${ARTIFACT_DIR}"

      - name: Generate diagnostics — dashboard (HTML)
        run: |
          poetry run spectramind diagnose dashboard --no-umap --no-tsne --outdir "${ARTIFACT_DIR}" || \
          poetry run spectramind diagnose dashboard --outdir "${ARTIFACT_DIR}" || true

      - name: Copy common artifacts into per‑interp bundle
        run: |
          for p in \
            "${DIAG_DIR}"/*.html \
            "${DIAG_DIR}"/*.png \
            "${DIAG_DIR}"/*.svg \
            "${DIAG_DIR}"/*.json \
            "${DIAG_DIR}"/*.csv \
            "${ARTIFACT_DIR}"/*.html \
            "${ARTIFACT_DIR}"/*.png \
            "${ARTIFACT_DIR}"/*.svg \
            "${ARTIFACT_DIR}"/*.json \
            "${ARTIFACT_DIR}"/*.csv \
          ; do
            [ -f "$p" ] && cp -v "$p" "${ARTIFACT_DIR}/" || true
          done
          # Also capture debug & run hash if present
          [ -f logs/v50_debug_log.md ] && cp -v logs/v50_debug_log.md "${ARTIFACT_DIR}/" || true
          [ -f outputs/run_hash_summary_v50.json ] && cp -v outputs/run_hash_summary_v50.json "${ARTIFACT_DIR}/" || true

      - name: Summarize diagnostics run
        run: |
          {
            echo "SpectraMind V50 — Diagnostics Summary";
            date;
            echo "Python: ${{ matrix.python-version }}";
            echo "Device: ${DEVICE}";
            echo "Artifacts:";
            ls -lh "${ARTIFACT_DIR}" || true;
          } > "${ARTIFACT_DIR}/summary.txt"
          cat "${ARTIFACT_DIR}/summary.txt"

      - name: Upload diagnostics artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: diagnostics-py${{ matrix.python-version }}
          path: ${{ env.ARTIFACT_DIR }}
          if-no-files-found: warn
          retention-days: 21

  ablate:
    name: Ablation Leaderboard (scheduled/manual)
    needs: build
    runs-on: ubuntu-latest
    timeout-minutes: 45
    if: |
      github.event_name == 'schedule' ||
      (github.event_name == 'workflow_dispatch' && inputs.run_ablation == 'true')

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install Poetry
        run: |
          python -m pip install --upgrade pip
          pip install poetry==${{ env.POETRY_VERSION }}

      - name: Cache Poetry
        uses: actions/cache@v4
        with:
          path: |
            ~/.cache/pip
            ~/.cache/pypoetry
            .venv
          key: poetry-${{ runner.os }}-3.11-${{ hashFiles('**/poetry.lock') }}
          restore-keys: |
            poetry-${{ runner.os }}-3.11-

      - name: Install deps
        run: |
          poetry config virtualenvs.create true
          poetry install --no-root

      - name: Run ablation (fast grid) + post-process
        run: |
          make -f makefile.ci ablate-ci

      - name: Upload ablation artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: ablation-leaderboard
          path: |
            outputs/ablate/leaderboard.csv
            outputs/ablate/leaderboard.html
            outputs/ablate/**
          if-no-files-found: ignore
          retention-days: 30

  aggregate:
    name: Aggregate Diagnostics Index
    needs: [build]
    runs-on: ubuntu-latest
    if: always()
    steps:
      - name: Download diagnostics artifacts
        uses: actions/download-artifact@v4
        with:
          pattern: diagnostics-py*
          merge-multiple: true

      - name: Build aggregated index
        run: |
          mkdir -p aggregated
          {
            echo "# SpectraMind V50 — Diagnostics Index"
            echo ""
            echo "_Generated: $(date -u)_"
            echo ""
            find artifacts -type f -maxdepth 5 | sed 's/^/- /'
          } > aggregated/DIAGNOSTICS_INDEX.md
          echo "Created aggregated/DIAGNOSTICS_INDEX.md"
          head -n 50 aggregated/DIAGNOSTICS_INDEX.md || true

      - name: Upload aggregated index
        uses: actions/upload-artifact@v4
        with:
          name: diagnostics-aggregated
          path: aggregated/DIAGNOSTICS_INDEX.md
          if-no-files-found: warn
          retention-days: 30
