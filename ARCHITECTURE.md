ðŸš€ SpectraMind V50 â€” NeurIPS 2025 Ariel Data Challenge

ARCHITECTURE.md (root, upgraded)

Neuro-symbolic, physics-informed pipeline for ESA Arielâ€™s simulated data.
Design pillars: NASA-grade reproducibility, CLI-first automation, Hydra configs, DVC-tracked data, symbolic physics constraints, diagnostics by default, Kaggle-runtime discipline.

â¸»

0) TL;DR (5 commands)

spectramind test
spectramind calibrate data=nominal
spectramind train model=v50 optimizer=adamw trainer.gpus=1
spectramind diagnose dashboard --open
spectramind submit --selftest

Artifacts are stamped with config hash, git commit, DVC rev, and an env SBOM.

â¸»

1) System Overview

SpectraMind V50 predicts exoplanet transmission spectra â€” mean Î¼ and uncertainty Ïƒ over 283 wavelength bins â€” from raw FGS1 photometry and AIRS spectroscopy. The end-to-end pipeline is automated via Typer CLI (spectramind â€¦), configured with Hydra (YAML groups), and emits deterministic logs, manifests, and dashboards.

1.1 High-Level Dataflow

flowchart TD
  U[User] -->|spectramind ...| CLI[Typer CLI]
  CLI --> CFG["Hydra Compose<br/>configs/* + overrides"]
  CFG --> ORCH["Pipeline Orchestrator"]
  ORCH --> CAL["Calibration<br/>FGS1/AIRS preprocessing (DVC)"]
  CAL --> ENC["Encoders<br/>FGS1â†’Mamba SSM Â· AIRSâ†’GNN"]
  ENC --> DEC["Decoders â†’ Î¼ & Ïƒ"]
  DEC --> CALIB["Uncertainty Calibration<br/>Temp scaling Â· COREL Â· Conformal"]
  CALIB --> DIAG["Diagnostics & Explainability<br/>GLL Â· FFT Â· UMAP Â· t-SNE Â· SHAP Â· Symbolic"]
  DIAG --> BUNDLE["Submission Bundler<br/>selftest Â· manifest Â· zip"]
  BUNDLE --> KAG["Kaggle Leaderboard"]

  CFG -. "resolved_config.yaml + hash" .-> ART["Artifacts<br/>outputs/YYYY-MM-DD/HH-MM-SS"]
  CAL -. "DVC stages" .-> ART
  ENC -. "checkpoints / metrics" .-> ART
  DIAG -. "HTML / PNG / JSON" .-> ART
  BUNDLE -. "submission.zip + manifest" .-> ART


â¸»

2) Core Components (Contract-first)

2.1 CLI (Typer)

Subcommands: train, predict, calibrate, diagnose, submit, test, ablate, analyze-log, corel-train.
Global flags: --dry-run, --debug, --config-path, --version, --seed, --multirun.
Telemetry: appends human log to v50_debug_log.md and machine-log to events.jsonl.

2.2 Config (Hydra)

Groups: data/, model/, train/, diagnostics/, submit/, profiles/, runtime/.
Guarantees: every param has a default; the resolved config is persisted and hashed.

Minimal example:

# configs/model/v50.yaml
defaults:
  - _self_
  - data: nominal
  - train: standard
  - diagnostics: default
  - submit: kaggle

model:
  encoder:
    fgs1:
      name: mamba
      d_model: 256
      d_state: 64
      n_layers: 8
      dropout: 0.1
    airs:
      name: gnn_gat
      d_node: 192
      n_layers: 6
      heads: 4
      edge_features: [Î”Î», molecule_region, detector_segment]
  decoder:
    mu:
      hidden: [256, 256]
    sigma:
      hidden: [256]
      min_log_sigma: -4.0
loss:
  gll_weight: 1.0
  fft_smooth_weight: 0.1
  asymmetry_weight: 0.05
  nonneg_weight: 0.5

2.3 Data Management (DVC + optional lakeFS)
	â€¢	Raw â†’ calibrated cubes not committed to Git.
	â€¢	DVC tracks inputs/intermediates/ckpts; remotes: S3/GCS/SSH supported.
	â€¢	Every dashboard prints DVC rev + remote URL hint.

2.4 Modeling (FGS1 + AIRS + decoders)
	â€¢	FGS1 encoder: Mamba SSM for long photometric sequences; jitter augmentation; optional transit-shape conditioning.
	â€¢	AIRS encoder: GNN (e.g., GAT/NNConv) with edges by wavelength proximity, molecular region, detector segment; positional encodings in Î»; optional edge features.
	â€¢	Decoders: dual heads for Î¼ and Ïƒ; physics-aware regularization; symbolic fusion.
	â€¢	Loss: GLL + FFT smoothness + asymmetry + non-negativity + symbolic logic. Curriculum toggles by stage.

2.5 Uncertainty Calibration

Temperature scaling â†’ COREL bin-wise conformalization â†’ instance-level tuning.
Outputs: coverage curves, per-bin heatmaps, Î”coverage CSV.

2.6 Diagnostics & Explainability

GLL heatmaps; FFT/autocorr; UMAP/t-SNE latents; SHAP overlays; symbolic rule tables; calibration checks; unified HTML dashboard (diagnostic_report_vN.html).

2.7 CI/CD (GitHub Actions)

Lint + type check, unit & CLI tests, security scans, SBOM, docs/diagrams, container build, release assets (optional Kaggle packaging).

â¸»

3) Explicit I/O Contracts

3.1 Inputs
	â€¢	FGS1: float32 time series, shape [T, 1] (pre-bin); after binning â†’ [T_binned, 1], normalized.
	â€¢	AIRS: float32 spectral frames, shape [time, rows=32, cols=356]; pipeline reduces to wavelength features per planet.

3.2 Outputs
	â€¢	Î¼: float32[283] predicted mean spectrum.
	â€¢	Ïƒ: float32[283] predictive std (post-calibration).
	â€¢	Submission CSV: columns: planet_id,int, bin_id,int (0..282), mu,float, sigma,float.

Submission schema (JSON Schema gist):

{
  "type":"object",
  "properties":{
    "planet_id":{"type":"integer","minimum":0},
    "bin_id":{"type":"integer","minimum":0,"maximum":282},
    "mu":{"type":"number"},
    "sigma":{"type":"number","exclusiveMinimum":0}
  },
  "required":["planet_id","bin_id","mu","sigma"]
}


â¸»

4) Reproducibility Stack

flowchart TD
  H[Hydra YAMLs]-->R1[resolved_config.yaml + hash]
  D[DVC]-->R2[data/model lineage]
  M[MLflow opt.]-->R3[metrics/artifacts]
  L[CLI logs]-->R4[v50_debug_log.md + events.jsonl]
  E[Env locks]-->R5[Poetry/Docker SBOM]
  C[CI workflows]-->R6[status badges]
  R1-->G[Guaranteed Replay]
  R2-->G
  R4-->G
  R5-->G

Run hash bundle: run_hash_summary_v50.json includes {git_commit, config_hash, dvc_rev, docker_image, poetry_lock_hash, cuda/torch_versions}.

â¸»

5) Calibration & DVC Stages

Stage sketch (optional):

# dvc.yaml
stages:
  calibrate_fgs1:
    cmd: spectramind calibrate stage=fgs1
    deps: [data/raw/fgs1, configs/data/fgs1.yaml]
    outs: [data/cal/fgs1]
  calibrate_airs:
    cmd: spectramind calibrate stage=airs
    deps: [data/raw/airs, configs/data/airs.yaml]
    outs: [data/cal/airs]
  features:
    cmd: spectramind calibrate stage=features
    deps: [data/cal/fgs1, data/cal/airs, configs/data/features.yaml]
    outs: [data/features]

Kaggle constraint: â‰¤ 9 hours across ~1,100 planets on the provided GPU; stages degrade gracefully on CPU for CI smoke.

â¸»

6) Training & Ablation

flowchart TD
  A0["spectramind ablate"] --> A1["Hydra Multirun"]
  A1 --> A2["Ablation Engine (grid Â· random Â· smart)"]
  A2 --> A3["Runner: train â†’ diagnose"]
  A3 --> A4["Collector: metrics.json"]
  A4 --> A5["Leaderboard md/html/csv"]
  A5 -->|Top-N| A6["Bundle zip (+manifests)"]

Primary metrics: GLL (leaderboard), RMSE/MAE (dev), entropy, violation norms, FFT power, coverage deltas, runtime.

â¸»

7) Symbolic Logic & Physics Constraints
	â€¢	Smoothness / TV / FFT in wavelength space
	â€¢	Non-negativity on Î¼ and Ïƒ bounds
	â€¢	Molecular coherence per region (CHâ‚„, Hâ‚‚O, COâ‚‚ bands, etc.)
	â€¢	Photonic alignment: FGS1 transit shape guides AIRS alignment + augmentation
Violations are rendered as heatmaps/tables and fed into targeted re-training or calibration.

â¸»

8) Directory Layout (Top Level)

.
â”œâ”€ configs/              # Hydra groups: data/, model/, train/, diagnostics/, submit/, profiles/, runtime/
â”œâ”€ src/                  # Pipeline code: data/, models/, calibrate/, cli/, diagnostics/, utils/
â”œâ”€ tests/                # Unit + CLI tests (fast/deep); submission/shape/selftest
â”œâ”€ docs/                 # This file, READMEs, diagrams, GUI docs
â”œâ”€ artifacts/            # Versioned outputs: html/png/json, logs, leaderboards
â”œâ”€ .github/workflows/    # CI (lint/test/sbom/build/docs/release)
â”œâ”€ pyproject.toml        # Poetry; pinned deps; tool configs (ruff/mypy/pytest/etc.)
â”œâ”€ dvc.yaml              # Optional DVC stages for calibration/cache
â””â”€ v50_debug_log.md      # CLI call log (human-readable), plus events.jsonl


â¸»

9) Command Matrix

Purpose	Command	Notes
Smoke check	spectramind test	Fast/Deep modes; validates paths, shapes, config, submission template
Calibration	spectramind calibrate data=nominal	Writes DVC-tracked calibrated cubes and logs
Train	spectramind train model=v50 trainer.gpus=1	AMP, cosine LR, curriculum stages
Predict	spectramind predict ckpt=â€¦ outputs.dir=â€¦	Î¼, Ïƒ tensors + CSV/NPZ export
Diagnose	spectramind diagnose dashboard --open	UMAP/t-SNE/SHAP/FFT/calibration HTML dashboard
COREL	spectramind corel-train	Bin-wise conformal Ïƒ calibration and coverage plots
Ablate	spectramind ablate +grid=â€¦	Multirun w/ leaderboard (HTML/MD/CSV)
Submit	spectramind submit --selftest	Validates, packs submission.zip, writes manifest
Log Analysis	spectramind analyze-log --md --csv	Summarizes v50_debug_log.md with hash groups


â¸»

10) Artifacts & Manifests

Per-run: outputs/<date>/<time>/
	â€¢	resolved_config.yaml, run_hash_summary_v50.json
	â€¢	metrics.json, gll_heatmap.png, fft_*, umap.html, tsne.html
	â€¢	shap_overlay/*.png|json, symbolic/*.json|html
	â€¢	calibration/*.png|json, corel/*.csv
	â€¢	diagnostic_report_vN.html
	â€¢	submission/manifest.json, submission.zip

Global: v50_debug_log.md, events.jsonl

Example submission/manifest.json:

{
  "version": "v50.0.0",
  "git_commit": "abcd1234",
  "config_hash": "e3b0c44298...",
  "dvc_rev": "2f7c9a...",
  "docker_image": "ghcr.io/.../spectramind:v50",
  "generated_at": "2025-09-04T12:00:00Z",
  "files": ["submission.csv"],
  "metrics": {"gll_dev": -1.234, "coverage@95": 0.948}
}


â¸»

11) Runtime & Performance Targets
	â€¢	Kaggle GPU runtime: â‰¤ 9h (full pipeline, ~1,100 planets).
	â€¢	CPU CI smoke: â‰¤ 20 min (toy subset, reduced dims).
	â€¢	Memory: keep per-stage < 10 GB on GPU; streaming loaders for AIRS.
	â€¢	Determinism: PYTHONHASHSEED=0, single-threaded BLAS in CI (OMP/MKL/OPENBLAS=1), seeded dataloaders.

â¸»

12) Security, Ethics, Governance
	â€¢	No private data; source licensing respected.
	â€¢	SBOM generated in CI; pip-audit/trivy/CodeQL scans.
	â€¢	Reproducibility: all runs have config/env/data lineage.
	â€¢	Optional role-based API gateway for dashboards (no analytics logic server-side).

â¸»

13) Troubleshooting (Quick)
	â€¢	Hydra composition fails: check defaults: order; debug with --cfg job --package _global_.
	â€¢	DVC missing: dvc pull w/ remote creds; verify .dvc/config.
	â€¢	Submission invalid: spectramind submit --selftest to emit diff vs schema.
	â€¢	Empty dashboard: enable diagnostics; ensure generate_html_report.py paths.
	â€¢	CUDA wheels mismatch: set TORCH_WHL_INDEX or pin torch/vision/audio.

â¸»

14) Extensibility Hooks
	â€¢	Encoders: swap mamba/transformer for FGS1; gat/nnconv/rgcn for AIRS.
	â€¢	Symbolic engine: rule weights, soft/hard modes, per-rule loss maps, entropy overlays.
	â€¢	Calibration: plug new conformal/quantile methods; toggle molecule-region weighting.
	â€¢	Diagnostics: inject new plots into the HTML dashboard via generate_html_report.py.

â¸»

15) Compose & Container Notes

Compose (GPU):

version: "3.9"
services:
  smv50:
    image: spectramind:gpu
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
    volumes:
      - ./:/workspace
    command: ["spectramind","train","--config-name=config_v50.yaml"]

Docker build examples:

# GPU
docker build -t spectramind:gpu .
# CPU
docker build -t spectramind:cpu --build-arg BASE_IMAGE=python:3.11-slim .


â¸»

16) Glossary

FGS1: Fine Guidance Sensor photometry (time series).
AIRS: Ariel IR Spectrometer (wavelength Ã— time frames).
Î¼, Ïƒ: Predicted mean spectrum & predictive uncertainty.
GLL: Gaussian Log-Likelihood (leaderboard metric).
COREL: Conformal calibration for bin-wise Ïƒ coverage.

â¸»

17) Roadmap (select)
	â€¢	ðŸ’¡ AIRS edge-feature GNN (distance/molecule/segment) with attention export
	â€¢	ðŸ’¡ Symbolic influence maps (âˆ‚L/âˆ‚Î¼ per rule) integrated into dashboard
	â€¢	ðŸ’¡ Ablation leaderboard: HTML + Markdown with top-N ZIP export
	â€¢	ðŸ’¡ UMAP/t-SNE 3D with confidence-weighted opacity and planet links
	â€¢	ðŸ’¡ Config hash heatmaps from CLI logs for usage analytics

â¸»

End of ARCHITECTURE.md
