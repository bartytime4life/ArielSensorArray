{
"cells": \[
{
"cell\_type": "markdown",
"metadata": {},
"source": \[
"# SpectraMind V50 — Kaggle Inference Template (Hardened v2)\n",
"\n",
"End-to-end **inference → σ calibration → validate → package** on Kaggle with **Internet OFF**.\n",
"\n",
"### Attach these datasets (right sidebar → *Add Data*)\n",
"- `ADC2025-competition-data` *(or your exact competition input dataset)*\n",
"- `v50-weights` *(trained checkpoints / artifacts)*\n",
"- `v50-runtime` *(optional: code bundle as wheel or source tree)*\n",
"\n",
"### Runtime knobs\n",
"- Enable **GPU** (T4 / A10 / L4) • Internet **OFF** • Accelerator **ON**\n",
"- Run cells **top → bottom**. Errors are **fail-fast** with clear messages.\n",
"\n",
"> Tip: Pair with `assets/KAGGLE_GUIDE.md` in your repo for a self-documented workflow."
]
},
{
"cell\_type": "markdown",
"metadata": {},
"source": \[
"## 0) Environment sanity, offline guards, and canonical paths\n",
"- Adjust the dataset slugs below to match your attached datasets.\n",
"- We add strict offline/env flags, deterministic seeds, and print quick diagnostics."
]
},
{
"cell\_type": "code",
"execution\_count": null,
"metadata": {},
"outputs": \[],
"source": \[
"import os, sys, json, time, math, random, platform, subprocess, shlex, hashlib, textwrap\n",
"from pathlib import Path\n",
"\n",
"# --------------------- Kaggle paths (EDIT THESE SLUGS) ---------------------\n",
"# Change to your exact dataset names if different\n",
"IN\_COMP    = Path('/kaggle/input/adc2025-competition-data')  # competition input dataset\n",
"IN\_WEIGHTS = Path('/kaggle/input/v50-weights')               # trained weights/artifacts dataset\n",
"IN\_RUNTIME = Path('/kaggle/input/v50-runtime')               # optional: code bundle (wheel or source)\n",
"\n",
"# --------------------- Working/output roots ---------------------\n",
"ROOT    = Path('/kaggle/working').resolve()\n",
"OUTDIR  = ROOT / 'output'\n",
"LOGDIR  = ROOT / 'logs'\n",
"OUTDIR.mkdir(parents=True, exist\_ok=True)\n",
"LOGDIR.mkdir(parents=True, exist\_ok=True)\n",
"\n",
"# --------------------- Offline / safety flags ---------------------\n",
"os.environ.setdefault('PYTHONHASHSEED', '0')          # deterministic hashing\n",
"os.environ.setdefault('TOKENIZERS\_PARALLELISM', 'false')\n",
"os.environ.setdefault('TRANSFORMERS\_OFFLINE', '1')    # huggingface offline\n",
"os.environ.setdefault('HF\_HOME', str(ROOT / '.hf'))\n",
"os.environ.setdefault('WANDB\_MODE', 'disabled')\n",
"os.environ.setdefault('MPLBACKEND', 'Agg')\n",
"os.environ.setdefault('OMP\_NUM\_THREADS', '1')         # reproducible CPU math\n",
"os.environ.setdefault('MKL\_NUM\_THREADS', '1')\n",
"\n",
"print('Python  :', sys.version.split()\[0])\n",
"print('Platform:', platform.platform())\n",
"print('ROOT    :', str(ROOT))\n",
"\n",
"print('\nMounted datasets:')\n",
"print('  COMP   :', IN\_COMP.exists(), str(IN\_COMP))\n",
"print('  WEIGHTS:', IN\_WEIGHTS.exists(), str(IN\_WEIGHTS))\n",
"print('  RUNTIME:', IN\_RUNTIME.exists(), str(IN\_RUNTIME))\n",
"\n",
"# Attempt to show GPU presence\n",
"try:\n",
"    print('\nGPU via nvidia-smi:')\n",
"    subprocess.run(shlex.split('nvidia-smi'), check=False)\n",
"except Exception as e:\n",
"    print('nvidia-smi not available:', e)\n",
"\n",
"# Basic sanity: competition + weights must exist\n",
"missing = \[]\n",
"if not IN\_COMP.exists():\n",
"    missing.append(f'COMP dataset not found: {IN\_COMP}')\n",
"if not IN\_WEIGHTS.exists():\n",
"    missing.append(f'WEIGHTS dataset not found: {IN\_WEIGHTS}')\n",
"if missing:\n",
"    print('\n\n'.join(missing))\n",
"    raise SystemExit('Required dataset(s) missing — fix dataset slugs in the first cell or attach datasets.')\n",
"\n",
"# Utility: quick checksum (first file) to fingerprint artifacts\n",
"def sha256\_of(path: Path, bufsize=1024*1024) -> str:\n",
"    h = hashlib.sha256()\n",
"    with open(path, 'rb') as f:\n",
"        while True:\n",
"            b = f.read(bufsize)\n",
"            if not b: break\n",
"            h.update(b)\n",
"    return h.hexdigest()\n",
"\n",
"# Try to fingerprint the main checkpoint if present\n",
"ckpt\_guess = None\n",
"for pat in \['*.ckpt', '*.pt', '*.pth']:\n",
"    cand = list(IN\_WEIGHTS.glob(pat))\n",
"    if cand:\n",
"        ckpt\_guess = cand\[0]\n",
"        break\n",
"if ckpt\_guess is not None:\n",
"    try:\n",
"        print('\nArtifact fingerprint (sha256, first 12):', sha256\_of(ckpt\_guess)\[:12], '\n  →', ckpt\_guess.name)\n",
"    except Exception as e:\n",
"        print('Could not hash checkpoint:', e)\n",
"else:\n",
"    print('No obvious checkpoint file found in WEIGHTS dataset; the CLI may refer to a specific path.')"
]
},
{
"cell\_type": "markdown",
"metadata": {},
"source": \[
"## 1) Optional: install runtime code from wheel or add source to `PYTHONPATH`\n",
"- If `v50-runtime` contains a wheel (`*.whl`), we install it **offline** (`--no-index`, `--find-links`).\n",
"- Otherwise, we append the source directory to `sys.path`.\n",
"- If neither is attached, we assume the environment already has `spectramind` preinstalled."
]
},
{
"cell\_type": "code",
"execution\_count": null,
"metadata": {},
"outputs": \[],
"source": \[
"if IN\_RUNTIME.exists():\n",
"    wheel\_files = sorted(IN\_RUNTIME.glob('\*.whl'))\n",
"    if wheel\_files:\n",
"        whl = wheel\_files\[0]\n",
"        print('Installing wheel (offline):', whl.name)\n",
"        subprocess.check\_call(\[\n",
"            sys.executable, '-m', 'pip', 'install', '--no-index', '--find-links', str(IN\_RUNTIME), str(whl)\n",
"        ])\n",
"    else:\n",
"        # If shipping a source tree, append to path\n",
"        if str(IN\_RUNTIME) not in sys.path:\n",
"            sys.path.append(str(IN\_RUNTIME))\n",
"        print('Added to sys.path:', IN\_RUNTIME)\n",
"else:\n",
"    print('IN\_RUNTIME not attached — assuming spectramind is already available in the image/notebook.')\n",
"\n",
"# Quick import smoke to fail fast if module missing\n",
"try:\n",
"    import spectramind  # noqa: F401\n",
"    print('spectramind module import: OK')\n",
"except Exception as e:\n",
"    raise SystemExit('Could not import spectramind. Ensure v50-runtime is attached (wheel/source) or the image includes it.\n' + str(e))"
]
},
{
"cell\_type": "markdown",
"metadata": {},
"source": \[
"## 2) Self-test (fast): verify CLI, config, and shapes\n",
"Runs the project self-test to catch environment and path issues early. If this fails, fix datasets/paths first."
]
},
{
"cell\_type": "code",
"execution\_count": null,
"metadata": {},
"outputs": \[],
"source": \[
"cmd = 'python -m spectramind test --fast'\n",
"print('RUN:', cmd)\n",
"ret = subprocess.run(shlex.split(cmd), cwd=str(ROOT))\n",
"if ret.returncode != 0:\n",
"    raise SystemExit('Self-test failed — check dataset slugs, attached code/weights, and CLI availability.')\n",
"print('Self-test: OK')"
]
},
{
"cell\_type": "markdown",
"metadata": {},
"source": \[
"## 3) Predict μ and raw σ (Hydra overrides are Kaggle-aware)\n",
"- We pass canonical **Kaggle paths** via `+paths.*` overrides.\n",
"- If your weights checkpoint file has a specific name/path, set it below.\n",
"- Outputs are written to `output/` with Hydra logs/configs in `output/hydra/`."
]
},
{
"cell\_type": "code",
"execution\_count": null,
"metadata": {},
"outputs": \[],
"source": \[
"# Pick checkpoint path: prefer detected file, else a default path expected by your pipeline\n",
"CKPT\_PATH = str(ckpt\_guess) if 'ckpt\_guess' in globals() and ckpt\_guess is not None else str(IN\_WEIGHTS / 'model.ckpt')\n",
"print('Using checkpoint:', CKPT\_PATH)\n",
"\n",
"cmd = (\n",
"    'python -m spectramind predict '\n",
"    '+data.split=test '\n",
"    '+runtime.kaggle=true '\n",
"    f'+paths.input={IN\_COMP} '\n",
"    f'+paths.out={OUTDIR} '\n",
"    f'+model.ckpt={CKPT\_PATH} '\n",
")\n",
"print('RUN:', cmd)\n",
"ret = subprocess.run(shlex.split(cmd))\n",
"if ret.returncode != 0:\n",
"    raise SystemExit('Predict step failed — see logs above.')\n",
"print('Predict: OK → outputs in', OUTDIR)"
]
},
{
"cell\_type": "markdown",
"metadata": {},
"source": \[
"## 4) Calibrate σ (temperature scaling + COREL)\n",
"- Applies post-hoc uncertainty calibration for leaderboard-safe σ.\n",
"- Writes calibrated artifacts back into `output/` (e.g., `submission.csv` or calibrated tensors)."
]
},
{
"cell\_type": "code",
"execution\_count": null,
"metadata": {},
"outputs": \[],
"source": \[
"cmd = (\n",
"    'python -m spectramind calibrate-temp '\n",
"    '+calib.corel=true '\n",
"    f'+paths.out={OUTDIR} '\n",
")\n",
"print('RUN:', cmd)\n",
"ret = subprocess.run(shlex.split(cmd))\n",
"if ret.returncode != 0:\n",
"    raise SystemExit('Calibration step failed — see logs above.')\n",
"print('Calibration: OK')"
]
},
{
"cell\_type": "markdown",
"metadata": {},
"source": \[
"## 5) Validate and package (CSV/ZIP + report.html)\n",
"- Runs validator and bundles a submission zip per competition rules.\n",
"- If your competition requires **submission.csv** directly, we also surface it to `/kaggle/working/`."
]
},
{
"cell\_type": "code",
"execution\_count": null,
"metadata": {},
"outputs": \[],
"source": \[
"SUBMIT\_ZIP = ROOT / 'submission.zip'\n",
"cmd = (\n",
"    'python -m spectramind submit '\n",
"    f'+submit.bundle={SUBMIT\_ZIP} '\n",
"    '+report.html=true '\n",
")\n",
"print('RUN:', cmd)\n",
"ret = subprocess.run(shlex.split(cmd))\n",
"if ret.returncode != 0:\n",
"    raise SystemExit('Submit step failed — see logs above.')\n",
"print('Submission bundle:', SUBMIT\_ZIP, SUBMIT\_ZIP.exists())\n",
"\n",
"# If a submission.csv exists inside OUTDIR, copy it to ROOT for Kaggle UI convenience\n",
"import shutil\n",
"cand\_csv = None\n",
"for name in \['submission.csv', 'predictions.csv']:\n",
"    p = OUTDIR / name\n",
"    if p.exists():\n",
"        cand\_csv = p\n",
"        break\n",
"if cand\_csv:\n",
"    shutil.copy2(cand\_csv, ROOT / 'submission.csv')\n",
"    print('Surfaced CSV →', ROOT / 'submission.csv')\n",
"else:\n",
"    print('No submission.csv found in output/ (your pipeline may embed it in the zip only).')"
]
},
{
"cell\_type": "markdown",
"metadata": {},
"source": \[
"## 6) Artifact peek (Hydra configs, diagnostics, logs)\n",
"- Lists artifacts for quick audit.\n",
"- Displays the first 8 lines of `submission.csv` if present."
]
},
{
"cell\_type": "code",
"execution\_count": null,
"metadata": {},
"outputs": \[],
"source": \[
"# Listings\n",
"print('\n== output/ ==')\n",
"subprocess.run(\['bash', '-lc', 'ls -lah /kaggle/working/output || true'])\n",
"print('\n== output/hydra ==')\n",
"subprocess.run(\['bash', '-lc', 'ls -lah /kaggle/working/output/hydra || true'])\n",
"print('\n== logs ==')\n",
"subprocess.run(\['bash', '-lc', 'ls -lah /kaggle/working/logs || true'])\n",
"\n",
"# Show the first few lines of submission.csv, if present\n",
"csv\_path = ROOT / 'submission.csv'\n",
"if csv\_path.exists():\n",
"    print('\n== submission.csv (head) ==')\n",
"    try:\n",
"        with open(csv\_path, 'r', encoding='utf-8') as f:\n",
"            for i, line in enumerate(f):\n",
"                print(line.rstrip())\n",
"                if i >= 7: break\n",
"    except Exception as e:\n",
"        print('Could not read submission.csv:', e)\n",
"else:\n",
"    print('\nNo submission.csv at working root. If required by the competition, ensure your submit step emits it.')"
]
}
],
"metadata": {
"kernelspec": {
"display\_name": "Python 3",
"language": "python",
"name": "python3"
},
"language\_info": {
"name": "python",
"version": "3.10"
},
"colab": {
"name": "SpectraMind V50 — Kaggle Inference Template (Hardened v2)"
},
"accelerator": "GPU",
"tags": \[
"kaggle",
"offline",
"spectramind",
"ariel-2025",
"submission"
]
},
"nbformat": 4,
"nbformat\_minor": 5
}
